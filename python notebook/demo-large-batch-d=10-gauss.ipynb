{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2761e554",
   "metadata": {},
   "source": [
    "## data generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cacb334b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\lib\\site-packages\\numpy\\_distributor_init.py:32: UserWarning: loaded more than 1 DLL from .libs:\n",
      "D:\\Anaconda\\lib\\site-packages\\numpy\\.libs\\libopenblas.TXA6YQSD3GCQQC22GEQ54J2UDCXDXHWN.gfortran-win_amd64.dll\n",
      "D:\\Anaconda\\lib\\site-packages\\numpy\\.libs\\libopenblas.WCDJNK7YVMPZQ2ME2ZZHJJRJ3JIKNDB7.gfortran-win_amd64.dll\n",
      "  stacklevel=1)\n",
      "\n",
      "Bad key \"text.kerning_factor\" on line 4 in\n",
      "D:\\Anaconda\\lib\\site-packages\\matplotlib\\mpl-data\\stylelib\\_classic_test_patch.mplstyle.\n",
      "You probably need to get an updated matplotlibrc file from\n",
      "https://github.com/matplotlib/matplotlib/blob/v3.1.3/matplotlibrc.template\n",
      "or from the matplotlib source distribution\n",
      "Using backend: pytorch\n"
     ]
    }
   ],
   "source": [
    "from locally_connected import LocallyConnected\n",
    "from lbfgsb_scipy import LBFGSBScipy\n",
    "from trace_expm import trace_expm\n",
    "from sklearn.metrics import f1_score\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import scipy.sparse\n",
    "import GraphNOTEARS\n",
    "import notears_torch_version\n",
    "import lasso\n",
    "import dynotears\n",
    "import utils as ut\n",
    "import matplotlib.pyplot as plt\n",
    "import networkx as nx\n",
    "import dgl\n",
    "import random\n",
    "import utils as ut\n",
    "import dgl.function as fn\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from dgl import DGLGraph\n",
    "import pandas as pd\n",
    "#device = torch.device(\"cuda:0\")\n",
    "device = torch.device(\"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e45970cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_pre(n, d, s0, w_graph_type, p_graph_type, sem_type):\n",
    "    #binary W\n",
    "    w_true = ut.simulate_dag(d, s0, w_graph_type)\n",
    "    #weighted W\n",
    "    w_mat = ut.simulate_parameter(w_true)\n",
    "    w_test_mat=w_mat.copy()\n",
    "    #A\n",
    "    adj1 = ut.generate_adj(n) \n",
    "    #node to target\n",
    "    num_target=np.nonzero(w_mat[:,-1])[0]#4,14\n",
    "    n_suprious=-1.0\n",
    "    suprious_dict={}\n",
    "    #if no suprious variable existed\n",
    "    if len(num_target)==0:\n",
    "        return w_mat,w_mat, w_mat, w_mat,w_mat,w_mat,n_suprious\n",
    "    else:\n",
    "        #create the spurious variable\n",
    "        for i in range(len(num_target)):\n",
    "            suprious_list=np.nonzero(w_mat[num_target[i],:])[0]#12\n",
    "\n",
    "            for j in range(len(suprious_list)): \n",
    "                suprious=suprious_list[j]\n",
    "                #count the number of suprious variable\n",
    "                if suprious not in suprious_dict:\n",
    "                    suprious_dict[suprious]=1\n",
    "                    n_suprious+=1\n",
    "                    #remove other outgoing link\n",
    "                    w_mat[suprious,:]=0 #12,0\n",
    "                    w_test_mat[suprious,:]=0\n",
    "                    #print(suprious)\n",
    "                    #revert the link in the test\n",
    "                    if suprious!=d-1:\n",
    "                        w_test_mat[num_target[i],suprious]=-w_test_mat[num_target[i],suprious]\n",
    "                \n",
    "                \n",
    "    num_step = 5 #cannot work if num_step=1\n",
    "    #initial X0=X0W+B\n",
    "    Xbase = []\n",
    "    Xbase1 = ut.simulate_linear_sem(w_mat, n, sem_type, noise_scale=0.5)\n",
    "    #X1=X1W+AX0W+B\n",
    "    for i in range(num_step):\n",
    "        Xbase1 = ut.simulate_linear_sem_with_P(w_mat, w_mat, adj1@Xbase1, n, sem_type, noise_scale=1)\n",
    "        Xbase.append(Xbase1)\n",
    "        \n",
    "    #test data\n",
    "    Xbase_test = []\n",
    "    Xbase1_test = ut.simulate_linear_sem(w_test_mat, n, sem_type, noise_scale=0.5)\n",
    "    for i in range(num_step):\n",
    "        Xbase1_test = ut.simulate_linear_sem_with_P(w_test_mat, w_test_mat, adj1@Xbase1_test, n, sem_type, noise_scale=1)\n",
    "        Xbase_test.append(Xbase1_test)\n",
    "    \n",
    "    return Xbase,Xbase_test, adj1, w_true,w_mat,w_test_mat,n_suprious"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e865265d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_node_feature(Xlags,node_num):\n",
    "#     for num_lags in range(1):\n",
    "#         if num_lags==0:\n",
    "#             X_feature=Xlags[num_lags][node_num]\n",
    "#         else:\n",
    "#             X_feature=np.append(X_feature,Xlags[num_lags][node_num])##shape num_lags*5 (250)\n",
    "    X_feature=Xlags[-1][node_num]\n",
    "    return(X_feature)\n",
    "def to_binary(x):\n",
    "    if x>Xlags[-1][:,-1].mean():\n",
    "        return 1\n",
    "    else:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ab86e196",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_graph(valid_list,adj1,Xlags,n):\n",
    " ##node list for validation\n",
    "    labels=[]\n",
    "    G = nx.from_numpy_array(adj1)\n",
    "    for node_num in range(n):\n",
    "        G.nodes[node_num]['feature']=get_node_feature(Xlags,node_num)[:-1]\n",
    "\n",
    "        G.nodes[node_num]['label']=to_binary(get_node_feature(Xlags,node_num)[-1])\n",
    "\n",
    "        labels.append(G.nodes[node_num]['label'])\n",
    "        if node_num in valid_list:\n",
    "            G.nodes[node_num]['train_mask']=False\n",
    "            G.nodes[node_num]['valid_mask']=True\n",
    "        else:\n",
    "            G.nodes[node_num]['train_mask']=True\n",
    "            G.nodes[node_num]['valid_mask']=False\n",
    "    g = dgl.from_networkx(G, node_attrs=['feature','label','train_mask','valid_mask'])\n",
    "    return g"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1556b5a5",
   "metadata": {},
   "source": [
    "## GCN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "99b06103",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GCNLayer(nn.Module):\n",
    "    def __init__(self, in_feats, out_feats):\n",
    "        super(GCNLayer, self).__init__()\n",
    "        self.linear = nn.Linear(in_feats, out_feats)\n",
    "\n",
    "    def forward(self, g, feature):\n",
    "        # Creating a local scope so that all the stored ndata and edata\n",
    "        # (such as the `'h'` ndata below) are automatically popped out\n",
    "        # when the scope exits.\n",
    "        with g.local_scope():\n",
    "            g.ndata['h'] = feature\n",
    "            g.update_all(gcn_msg, gcn_reduce)\n",
    "            h = g.ndata['h']\n",
    "            return self.linear(h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "066f024f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.layer1 = GCNLayer(9, 4)\n",
    "        self.layer2 = GCNLayer(4, 2)\n",
    "\n",
    "    def forward(self, g, features):\n",
    "        x = F.relu(self.layer1(g, features))\n",
    "        x = self.layer2(g, x)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cf70bd42",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, g, features, labels, mask):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        logits = model(g, features)\n",
    "        logits = logits[mask]\n",
    "        labels = labels[mask]\n",
    "        _, indices = torch.max(logits, dim=1)\n",
    "        correct = torch.sum(indices == labels)\n",
    "        return correct.item() * 1.0 / len(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4ca3d404",
   "metadata": {},
   "outputs": [],
   "source": [
    "class atten_Net(nn.Module):\n",
    "    def __init__(self, in_feats, hid_feats, out_feats,n_node):\n",
    "        super(atten_Net, self).__init__()\n",
    "        self.layer1 = GCNLayer(in_feats, hid_feats)\n",
    "        self.layer2 = GCNLayer(hid_feats, out_feats)\n",
    "        self.att_mlp_1 = nn.Linear(n_node, hid_feats)\n",
    "        self.att_mlp_2 = nn.Linear(hid_feats, 2)\n",
    "        self.layer3 = GCNLayer(in_feats*2, hid_feats)\n",
    "        self.layer4 = GCNLayer(hid_feats, out_feats)\n",
    "\n",
    "    def forward(self, g, features,dag):\n",
    "        ##use mlp to get attention weights\n",
    "        node_att = F.relu(self.att_mlp_1(dag))\n",
    "        node_att = F.softmax(self.att_mlp_2(node_att), dim=-1)\n",
    "        node_weight_c = node_att[:, 0]\n",
    "        node_weight_o = node_att[:, 1]\n",
    "        ##attention on the causal/trival part\n",
    "        feature_c = node_weight_c.view(1, -1) * features\n",
    "        feature_o = node_weight_o.view(1, -1) * features\n",
    "        ## apply the mask on the features\n",
    "        xc = F.relu(self.layer1(g, feature_c))\n",
    "        xc = self.layer2(g, xc)\n",
    "        xc=F.log_softmax(xc, dim=-1)\n",
    "        \n",
    "        xo = F.relu(self.layer1(g, feature_o))\n",
    "        xo = self.layer2(g, xo)\n",
    "        xo=F.log_softmax(xo, dim=-1)\n",
    "        ##xco        \n",
    "        num = xc.shape[0]\n",
    "        l = [i for i in range(num)]\n",
    "        random.shuffle(l)\n",
    "        random_idx = torch.tensor(l)\n",
    "        xco = torch.cat((feature_c[random_idx], feature_o), dim=1)\n",
    "        xco = F.relu(self.layer3(g, xco))\n",
    "        xco = self.layer4(g, xco)\n",
    "        xco=F.log_softmax(xco, dim=-1)\n",
    "        \n",
    "        return xc,xo,xco"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7db3a7bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_new(model, g, features, labels, mask,dag):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        logits_c,logits_o,logits_co = model(g, features,dag)\n",
    "        logits = logits_o[mask]\n",
    "        labels = labels[mask]\n",
    "        _, indices = torch.max(logits, dim=1)\n",
    "        correct = torch.sum(indices == labels)\n",
    "        return correct.item() * 1.0 / len(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a08dbdd6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------the 0 iteration------------------\n",
      "finish data!\n",
      "finish fit graph!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\lib\\site-packages\\dgl\\backend\\pytorch\\tensor.py:40: UserWarning:\n",
      "\n",
      "Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at C:\\actions-runner\\_work\\pytorch\\pytorch\\builder\\windows\\pytorch\\torch\\csrc\\utils\\tensor_new.cpp:233.)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopped training at epoch 78\n",
      "GCN:train 0.8333333333333334 valid 0.55 test 0.5\n",
      "Early stopped training at epoch 56\n",
      "proposed:train 0.8333333333333334 valid 0.5 test 0.55 n_suprious 2.0\n",
      "-------------------the 1 iteration------------------\n",
      "-------------------the 1 iteration------------------\n",
      "-------------------the 1 iteration------------------\n",
      "-------------------the 1 iteration------------------\n",
      "-------------------the 1 iteration------------------\n",
      "-------------------the 1 iteration------------------\n",
      "-------------------the 1 iteration------------------\n",
      "finish data!\n",
      "finish fit graph!\n",
      "Early stopped training at epoch 64\n",
      "GCN:train 0.9666666666666667 valid 0.55 test 0.75\n",
      "Early stopped training at epoch 109\n",
      "proposed:train 0.9333333333333333 valid 0.7 test 0.65 n_suprious 1.0\n",
      "-------------------the 2 iteration------------------\n",
      "finish data!\n",
      "finish fit graph!\n",
      "Early stopped training at epoch 89\n",
      "GCN:train 0.9 valid 0.4 test 0.45\n",
      "Early stopped training at epoch 69\n",
      "proposed:train 0.8333333333333334 valid 0.45 test 0.55 n_suprious 4.0\n",
      "-------------------the 3 iteration------------------\n",
      "-------------------the 3 iteration------------------\n",
      "finish data!\n",
      "finish fit graph!\n",
      "Early stopped training at epoch 103\n",
      "GCN:train 0.8 valid 0.6 test 0.4\n",
      "Early stopped training at epoch 76\n",
      "proposed:train 0.7666666666666667 valid 0.55 test 0.3 n_suprious 2.0\n",
      "-------------------the 4 iteration------------------\n",
      "finish data!\n",
      "finish fit graph!\n",
      "Early stopped training at epoch 87\n",
      "GCN:train 0.9666666666666667 valid 0.55 test 0.6\n",
      "Early stopped training at epoch 65\n",
      "proposed:train 1.0 valid 0.45 test 0.55 n_suprious 3.0\n",
      "-------------------the 5 iteration------------------\n",
      "finish data!\n",
      "finish fit graph!\n",
      "Early stopped training at epoch 58\n",
      "GCN:train 0.8333333333333334 valid 0.5 test 0.55\n",
      "Early stopped training at epoch 87\n",
      "proposed:train 0.7 valid 0.7 test 0.55 n_suprious 2.0\n",
      "-------------------the 6 iteration------------------\n",
      "finish data!\n",
      "finish fit graph!\n",
      "Early stopped training at epoch 86\n",
      "GCN:train 1.0 valid 0.75 test 0.5\n",
      "Early stopped training at epoch 75\n",
      "proposed:train 1.0 valid 0.75 test 0.5 n_suprious 1.0\n",
      "-------------------the 7 iteration------------------\n",
      "-------------------the 7 iteration------------------\n",
      "finish data!\n",
      "finish fit graph!\n",
      "Early stopped training at epoch 60\n",
      "GCN:train 0.8 valid 0.6 test 0.75\n",
      "Early stopped training at epoch 72\n",
      "proposed:train 0.9333333333333333 valid 0.6 test 0.65 n_suprious 2.0\n",
      "-------------------the 8 iteration------------------\n",
      "finish data!\n",
      "finish fit graph!\n",
      "Early stopped training at epoch 82\n",
      "GCN:train 0.8 valid 0.4 test 0.55\n",
      "Early stopped training at epoch 83\n",
      "proposed:train 0.9666666666666667 valid 0.45 test 0.55 n_suprious 2.0\n",
      "-------------------the 9 iteration------------------\n",
      "-------------------the 9 iteration------------------\n",
      "finish data!\n",
      "finish fit graph!\n",
      "Early stopped training at epoch 77\n",
      "GCN:train 0.9666666666666667 valid 0.6 test 0.8\n",
      "Early stopped training at epoch 81\n",
      "proposed:train 0.9666666666666667 valid 0.65 test 0.45 n_suprious 2.0\n",
      "          train_acc  valid_acc  test_acc  n_suprious\n",
      "model                                               \n",
      "GCN        0.886667       0.55     0.585         2.1\n",
      "proposed   0.893333       0.58     0.530         2.1\n",
      "-------------------the 10 iteration------------------\n",
      "finish data!\n",
      "finish fit graph!\n",
      "Early stopped training at epoch 74\n",
      "GCN:train 0.6666666666666666 valid 0.45 test 0.5\n",
      "Early stopped training at epoch 61\n",
      "proposed:train 0.7 valid 0.45 test 0.5 n_suprious 2.0\n",
      "-------------------the 11 iteration------------------\n",
      "finish data!\n",
      "finish fit graph!\n",
      "Early stopped training at epoch 99\n",
      "GCN:train 0.8 valid 0.75 test 0.55\n",
      "Early stopped training at epoch 55\n",
      "proposed:train 0.8333333333333334 valid 0.65 test 0.45 n_suprious 3.0\n",
      "-------------------the 12 iteration------------------\n",
      "-------------------the 12 iteration------------------\n",
      "finish data!\n",
      "finish fit graph!\n",
      "Early stopped training at epoch 63\n",
      "GCN:train 0.8 valid 0.5 test 0.85\n",
      "Early stopped training at epoch 67\n",
      "proposed:train 0.8 valid 0.55 test 0.75 n_suprious 1.0\n",
      "-------------------the 13 iteration------------------\n",
      "-------------------the 13 iteration------------------\n",
      "-------------------the 13 iteration------------------\n",
      "-------------------the 13 iteration------------------\n",
      "finish data!\n",
      "finish fit graph!\n",
      "Early stopped training at epoch 73\n",
      "GCN:train 0.9 valid 0.55 test 0.5\n",
      "Early stopped training at epoch 76\n",
      "proposed:train 0.8666666666666667 valid 0.65 test 0.4 n_suprious 3.0\n",
      "-------------------the 14 iteration------------------\n",
      "finish data!\n",
      "finish fit graph!\n",
      "Early stopped training at epoch 90\n",
      "GCN:train 0.8666666666666667 valid 0.6 test 0.75\n",
      "Early stopped training at epoch 85\n",
      "proposed:train 0.9 valid 0.6 test 0.5 n_suprious 1.0\n",
      "-------------------the 15 iteration------------------\n",
      "finish data!\n",
      "finish fit graph!\n",
      "Early stopped training at epoch 58\n",
      "GCN:train 0.8666666666666667 valid 0.45 test 0.6\n",
      "Early stopped training at epoch 56\n",
      "proposed:train 0.9 valid 0.55 test 0.45 n_suprious 1.0\n",
      "-------------------the 16 iteration------------------\n",
      "finish data!\n",
      "finish fit graph!\n",
      "Early stopped training at epoch 134\n",
      "GCN:train 0.8333333333333334 valid 0.6 test 0.55\n",
      "Early stopped training at epoch 92\n",
      "proposed:train 0.8333333333333334 valid 0.5 test 0.55 n_suprious 3.0\n",
      "-------------------the 17 iteration------------------\n",
      "finish data!\n",
      "finish fit graph!\n",
      "Early stopped training at epoch 64\n",
      "GCN:train 0.8 valid 0.5 test 0.75\n",
      "Early stopped training at epoch 80\n",
      "proposed:train 0.7 valid 0.3 test 0.4 n_suprious 2.0\n",
      "-------------------the 18 iteration------------------\n",
      "-------------------the 18 iteration------------------\n",
      "finish data!\n",
      "finish fit graph!\n",
      "Early stopped training at epoch 66\n",
      "GCN:train 0.8666666666666667 valid 0.7 test 0.45\n",
      "Early stopped training at epoch 96\n",
      "proposed:train 1.0 valid 0.7 test 0.4 n_suprious 1.0\n",
      "-------------------the 19 iteration------------------\n",
      "-------------------the 19 iteration------------------\n",
      "finish data!\n",
      "finish fit graph!\n",
      "Early stopped training at epoch 94\n",
      "GCN:train 0.9333333333333333 valid 0.8 test 0.5\n",
      "Early stopped training at epoch 92\n",
      "proposed:train 1.0 valid 0.7 test 0.25 n_suprious 2.0\n",
      "          train_acc  valid_acc  test_acc  n_suprious\n",
      "model                                               \n",
      "GCN        0.860000     0.5700    0.5925         2.0\n",
      "proposed   0.873333     0.5725    0.4975         2.0\n",
      "-------------------the 20 iteration------------------\n",
      "-------------------the 20 iteration------------------\n",
      "-------------------the 20 iteration------------------\n",
      "-------------------the 20 iteration------------------\n",
      "-------------------the 20 iteration------------------\n",
      "finish data!\n",
      "finish fit graph!\n",
      "Early stopped training at epoch 58\n",
      "GCN:train 0.8 valid 0.4 test 0.45\n",
      "Early stopped training at epoch 58\n",
      "proposed:train 0.8 valid 0.45 test 0.25 n_suprious 1.0\n",
      "-------------------the 21 iteration------------------\n",
      "-------------------the 21 iteration------------------\n",
      "finish data!\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-10-b2fa13121f51>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     34\u001b[0m     \u001b[0madj1_torch\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0madj1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     35\u001b[0m     \u001b[0mmodel_1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mGraphNOTEARS\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodel_p1_MLP\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdims\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0md\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 36\u001b[1;33m     \u001b[0mW_est_1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mP1_est_1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mGraphNOTEARS\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlinear_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel_1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mXlags_torch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0madj1_torch\u001b[0m\u001b[1;33m,\u001b[0m  \u001b[0mlambda1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0.01\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlambda2\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0.01\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlambda3\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0.01\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     37\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"finish fit graph!\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     38\u001b[0m     \u001b[1;31m#g,g_test\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Desktop\\GraphNOTEARS-main\\GraphNOTEARS-main\\GraphNOTEARS_syn_p_1\\GraphNOTEARS.py\u001b[0m in \u001b[0;36mlinear_model\u001b[1;34m(model, Xlags, adj1, lambda1, lambda2, lambda3, max_iter, h_tol, rho_max)\u001b[0m\n\u001b[0;32m     87\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0m_\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmax_iter\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     88\u001b[0m         rho, alpha, h = dual_ascent_step(model, Xlags, adj1, lambda1, lambda2, lambda3,\n\u001b[1;32m---> 89\u001b[1;33m                                          rho, alpha, h, rho_max)\n\u001b[0m\u001b[0;32m     90\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mh\u001b[0m \u001b[1;33m<=\u001b[0m \u001b[0mh_tol\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mrho\u001b[0m \u001b[1;33m>=\u001b[0m \u001b[0mrho_max\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     91\u001b[0m             \u001b[1;32mbreak\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Desktop\\GraphNOTEARS-main\\GraphNOTEARS-main\\GraphNOTEARS_syn_p_1\\GraphNOTEARS.py\u001b[0m in \u001b[0;36mdual_ascent_step\u001b[1;34m(model, X_lags, adj1, lambda1, lambda2, lambda3, rho, alpha, h, rho_max)\u001b[0m\n\u001b[0;32m     65\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mprimal_obj\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     66\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 67\u001b[1;33m         \u001b[0moptimizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mclosure\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# NOTE: updates model in-place\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     68\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     69\u001b[0m             \u001b[0mh_new\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mh_func\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda\\lib\\site-packages\\torch\\optim\\optimizer.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    138\u001b[0m                 \u001b[0mprofile_name\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"Optimizer.step#{}.step\"\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    139\u001b[0m                 \u001b[1;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprofiler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrecord_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mprofile_name\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 140\u001b[1;33m                     \u001b[0mout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    141\u001b[0m                     \u001b[0mobj\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_optimizer_step_code\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    142\u001b[0m                     \u001b[1;32mreturn\u001b[0m \u001b[0mout\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Desktop\\GraphNOTEARS-main\\GraphNOTEARS-main\\GraphNOTEARS_syn_p_1\\lbfgsb_scipy.py\u001b[0m in \u001b[0;36mstep\u001b[1;34m(self, closure)\u001b[0m\n\u001b[0;32m     91\u001b[0m                             \u001b[0mmethod\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'L-BFGS-B'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     92\u001b[0m                             \u001b[0mjac\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 93\u001b[1;33m                             \u001b[0mbounds\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mbounds\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     94\u001b[0m                             )#options={'maxiter': 15}\n\u001b[0;32m     95\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda\\lib\\site-packages\\scipy\\optimize\\_minimize.py\u001b[0m in \u001b[0;36mminimize\u001b[1;34m(fun, x0, args, method, jac, hess, hessp, bounds, constraints, tol, callback, options)\u001b[0m\n\u001b[0;32m    618\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mmeth\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'l-bfgs-b'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    619\u001b[0m         return _minimize_lbfgsb(fun, x0, args, jac, bounds,\n\u001b[1;32m--> 620\u001b[1;33m                                 callback=callback, **options)\n\u001b[0m\u001b[0;32m    621\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mmeth\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'tnc'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    622\u001b[0m         return _minimize_tnc(fun, x0, args, jac, bounds, callback=callback,\n",
      "\u001b[1;32mD:\\Anaconda\\lib\\site-packages\\scipy\\optimize\\lbfgsb.py\u001b[0m in \u001b[0;36m_minimize_lbfgsb\u001b[1;34m(fun, x0, args, jac, bounds, disp, maxcor, ftol, gtol, eps, maxfun, maxiter, iprint, callback, maxls, finite_diff_rel_step, **unknown_options)\u001b[0m\n\u001b[0;32m    358\u001b[0m             \u001b[1;31m# until the completion of the current minimization iteration.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    359\u001b[0m             \u001b[1;31m# Overwrite f and g:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 360\u001b[1;33m             \u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfunc_and_grad\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    361\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0mtask_str\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstartswith\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mb'NEW_X'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    362\u001b[0m             \u001b[1;31m# new iteration\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda\\lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py\u001b[0m in \u001b[0;36mfun_and_grad\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m    258\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray_equal\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    259\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_update_x_impl\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 260\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_update_fun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    261\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_update_grad\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    262\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mg\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda\\lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py\u001b[0m in \u001b[0;36m_update_fun\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    224\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_update_fun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    225\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mf_updated\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 226\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_update_fun_impl\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    227\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mf_updated\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    228\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda\\lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py\u001b[0m in \u001b[0;36mupdate_fun\u001b[1;34m()\u001b[0m\n\u001b[0;32m    131\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    132\u001b[0m         \u001b[1;32mdef\u001b[0m \u001b[0mupdate_fun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 133\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfun_wrapped\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    134\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    135\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_update_fun_impl\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mupdate_fun\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda\\lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py\u001b[0m in \u001b[0;36mfun_wrapped\u001b[1;34m(x)\u001b[0m\n\u001b[0;32m    128\u001b[0m         \u001b[1;32mdef\u001b[0m \u001b[0mfun_wrapped\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    129\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnfev\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 130\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mfun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    131\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    132\u001b[0m         \u001b[1;32mdef\u001b[0m \u001b[0mupdate_fun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda\\lib\\site-packages\\scipy\\optimize\\optimize.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, x, *args)\u001b[0m\n\u001b[0;32m     72\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     73\u001b[0m         \u001b[1;34m\"\"\" returns the the function value \"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 74\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_compute_if_needed\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     75\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_value\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     76\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda\\lib\\site-packages\\scipy\\optimize\\optimize.py\u001b[0m in \u001b[0;36m_compute_if_needed\u001b[1;34m(self, x, *args)\u001b[0m\n\u001b[0;32m     66\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mall\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_value\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjac\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     67\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 68\u001b[1;33m             \u001b[0mfg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     69\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjac\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfg\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     70\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_value\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfg\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Desktop\\GraphNOTEARS-main\\GraphNOTEARS-main\\GraphNOTEARS_syn_p_1\\lbfgsb_scipy.py\u001b[0m in \u001b[0;36mwrapped_closure\u001b[1;34m(flat_params)\u001b[0m\n\u001b[0;32m     76\u001b[0m             \u001b[0mflat_params\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mflat_params\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_default_dtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     77\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_distribute_flat_params\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mflat_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 78\u001b[1;33m             \u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mclosure\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     79\u001b[0m             \u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mloss\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     80\u001b[0m             \u001b[0mflat_grad\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_gather_flat_grad\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Desktop\\GraphNOTEARS-main\\GraphNOTEARS-main\\GraphNOTEARS_syn_p_1\\GraphNOTEARS.py\u001b[0m in \u001b[0;36mclosure\u001b[1;34m()\u001b[0m\n\u001b[0;32m     57\u001b[0m             \u001b[0mX_hat\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_lags\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0madj1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     58\u001b[0m             \u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msquared_loss\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_hat\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_lags\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 59\u001b[1;33m             \u001b[0mh_val\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mh_func\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     60\u001b[0m             \u001b[0mdiag_loss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdiag_zero\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     61\u001b[0m             \u001b[0mpenalty1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0.5\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mrho\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mh_val\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mh_val\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0malpha\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mh_val\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Desktop\\GraphNOTEARS-main\\GraphNOTEARS-main\\GraphNOTEARS_syn_p_1\\GraphNOTEARS.py\u001b[0m in \u001b[0;36mh_func\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     31\u001b[0m         \u001b[1;34m\"\"\"Constrain 2-norm-squared of fc1 weights along m1 dim to be a DAG\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     32\u001b[0m         \u001b[0md\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdims\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 33\u001b[1;33m         \u001b[0mh\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrace_expm\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mw_est\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mw_est\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0md\u001b[0m  \u001b[1;31m# (Zheng et al. 2018)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     34\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mh\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     35\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Desktop\\GraphNOTEARS-main\\GraphNOTEARS-main\\GraphNOTEARS_syn_p_1\\trace_expm.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(ctx, input)\u001b[0m\n\u001b[0;32m      8\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mctx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m         \u001b[1;31m# detach so we can cast to NumPy\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 10\u001b[1;33m         \u001b[0mE\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mslin\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexpm\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     11\u001b[0m         \u001b[0mf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrace\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mE\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m         \u001b[0mE\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfrom_numpy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mE\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda\\lib\\site-packages\\scipy\\linalg\\matfuncs.py\u001b[0m in \u001b[0;36mexpm\u001b[1;34m(A)\u001b[0m\n\u001b[0;32m    253\u001b[0m     \u001b[1;31m# Input checking and conversion is provided by sparse.linalg.expm().\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    254\u001b[0m     \u001b[1;32mimport\u001b[0m \u001b[0mscipy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msparse\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlinalg\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 255\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mscipy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msparse\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlinalg\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexpm\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mA\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    256\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    257\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda\\lib\\site-packages\\scipy\\sparse\\linalg\\matfuncs.py\u001b[0m in \u001b[0;36mexpm\u001b[1;34m(A)\u001b[0m\n\u001b[0;32m    589\u001b[0m             [  0.        ,   0.        ,  20.08553692]])\n\u001b[0;32m    590\u001b[0m     \"\"\"\n\u001b[1;32m--> 591\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0m_expm\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mA\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0muse_exact_onenorm\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'auto'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    592\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    593\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda\\lib\\site-packages\\scipy\\sparse\\linalg\\matfuncs.py\u001b[0m in \u001b[0;36m_expm\u001b[1;34m(A, use_exact_onenorm)\u001b[0m\n\u001b[0;32m    638\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    639\u001b[0m     \u001b[1;31m# Try Pade order 3.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 640\u001b[1;33m     \u001b[0meta_1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mh\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0md4_loose\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mh\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0md6_loose\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    641\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0meta_1\u001b[0m \u001b[1;33m<\u001b[0m \u001b[1;36m1.495585217958292e-002\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0m_ell\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mh\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mA\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m3\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    642\u001b[0m         \u001b[0mU\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mV\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mh\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpade3\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda\\lib\\site-packages\\scipy\\sparse\\linalg\\matfuncs.py\u001b[0m in \u001b[0;36md4_loose\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    441\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0md4_loose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    442\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0muse_exact_onenorm\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 443\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0md4_tight\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    444\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_d4_exact\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    445\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_d4_exact\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda\\lib\\site-packages\\scipy\\sparse\\linalg\\matfuncs.py\u001b[0m in \u001b[0;36md4_tight\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    417\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0md4_tight\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    418\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_d4_exact\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 419\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_d4_exact\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_onenorm\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mA4\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m**\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m/\u001b[0m\u001b[1;36m4.\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    420\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_d4_exact\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    421\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda\\lib\\site-packages\\scipy\\sparse\\linalg\\matfuncs.py\u001b[0m in \u001b[0;36mA4\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    390\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_A4\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    391\u001b[0m             self._A4 = _smart_matrix_product(\n\u001b[1;32m--> 392\u001b[1;33m                     self.A2, self.A2, structure=self.structure)\n\u001b[0m\u001b[0;32m    393\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_A4\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    394\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda\\lib\\site-packages\\scipy\\sparse\\linalg\\matfuncs.py\u001b[0m in \u001b[0;36mA2\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    383\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_A2\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    384\u001b[0m             self._A2 = _smart_matrix_product(\n\u001b[1;32m--> 385\u001b[1;33m                     self.A, self.A, structure=self.structure)\n\u001b[0m\u001b[0;32m    386\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_A2\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    387\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda\\lib\\site-packages\\scipy\\sparse\\linalg\\matfuncs.py\u001b[0m in \u001b[0;36m_smart_matrix_product\u001b[1;34m(A, B, alpha, structure)\u001b[0m\n\u001b[0;32m    164\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    165\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0malpha\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 166\u001b[1;33m             \u001b[0mout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mA\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mB\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    167\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    168\u001b[0m             \u001b[0mout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0malpha\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mA\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mB\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "torch.set_default_dtype(torch.double)\n",
    "np.set_printoptions(precision=3)\n",
    "\n",
    "torch.manual_seed(12345)\n",
    "ut.set_random_seed(12345)\n",
    "\n",
    "n = 50 #number of people\n",
    "\n",
    "d = 10 #number of features\n",
    "\n",
    "w_graph_type = 'ER'\n",
    "p_graph_type = 'ER' \n",
    "sem_type = 'gauss'\n",
    "s0 =  d\n",
    "#params\n",
    "lr=0.01\n",
    "alpha=0.2\n",
    "beta=1\n",
    "gamma=0.2\n",
    "early_stop_thresh=50\n",
    "n_epoch=300\n",
    "output=pd.DataFrame(columns=[\"train_acc\",\"valid_acc\",\"test_acc\",\"model\",\"n_suprious\"])\n",
    "ith=0\n",
    "replicates=50\n",
    "while ith<2*replicates:\n",
    "    print(\"-------------------the\",ith//2,\"iteration------------------\")\n",
    "    #create data\n",
    "    Xlags,Xlags_test, adj1, w_true,w_mat,w_test_mat,n_suprious = data_pre(n, d, s0, w_graph_type,p_graph_type, sem_type)\n",
    "    if n_suprious<=0:\n",
    "        continue\n",
    "    Xlags_torch = torch.Tensor(np.array(Xlags))\n",
    "    print(\"finish data!\")\n",
    "    #fit the causal graph\n",
    "    adj1_torch = torch.Tensor(adj1)\n",
    "    model_1 = GraphNOTEARS.model_p1_MLP(dims=[d, n, 1], bias=True)\n",
    "    W_est_1, P1_est_1 = GraphNOTEARS.linear_model(model_1, Xlags_torch, adj1_torch,  lambda1 = 0.01, lambda2 = 0.01, lambda3 = 0.01)\n",
    "    print(\"finish fit graph!\")\n",
    "    #g,g_test\n",
    "    valid_list=random.sample(range(n), int(n*0.4))\n",
    "    g = create_graph(valid_list,adj1,Xlags,n)\n",
    "    g_test=create_graph(valid_list,adj1,Xlags_test,n)\n",
    "    #GCN\n",
    "    gcn_msg = fn.copy_u(u=\"h\", out=\"m\")\n",
    "    gcn_reduce = fn.sum(msg=\"m\", out=\"h\")\n",
    "\n",
    "    net = Net()\n",
    "\n",
    "    features = g.ndata['feature']\n",
    "    labels = g.ndata['label']\n",
    "    train_mask = g.ndata['train_mask']\n",
    "    valid_mask = g.ndata['valid_mask']\n",
    "    ###test\n",
    "    features_test = g_test.ndata['feature']\n",
    "    labels_test = g_test.ndata['label']\n",
    "    #parameters\n",
    "    optimizer = torch.optim.Adam(net.parameters(), lr=lr)\n",
    "\n",
    "    best_loss = 99998\n",
    "    best_epoch = -1\n",
    "    for epoch in range(n_epoch):\n",
    "        net.train()\n",
    "        logits = net(g, features)\n",
    "        logp = F.log_softmax(logits, dim=-1)\n",
    "        loss = F.nll_loss(logp[train_mask], labels[train_mask])\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        ##evaluate\n",
    "        net.eval()\n",
    "        train_acc = evaluate(net, g, features, labels, train_mask)\n",
    "        valid_acc = evaluate(net, g, features, labels, valid_mask)\n",
    "        test_acc = evaluate(net, g_test, features_test, labels_test, valid_mask)\n",
    "        valid_loss = F.nll_loss(logp[valid_mask], labels[valid_mask])\n",
    "        #early stop\n",
    "        if valid_loss < best_loss:\n",
    "            best_loss = valid_loss\n",
    "            best_epoch = epoch\n",
    "            #torch.save(net.state_dict(), \"GCN_demo_large.pth\")\n",
    "        elif epoch - best_epoch > early_stop_thresh:\n",
    "            print(\"Early stopped training at epoch %d\" % epoch)\n",
    "            break  # terminate the training loop\n",
    "    print(\"GCN:train\",train_acc,\"valid\",valid_acc,\"test\",test_acc)\n",
    "    output.loc[ith]=[train_acc,valid_acc,test_acc,\"GCN\",n_suprious]\n",
    "    ith+=1\n",
    "    ##proposed\n",
    "    model = atten_Net(in_feats=d-1, hid_feats=4, out_feats=2,n_node=d)\n",
    "\n",
    "    #params\n",
    "    best_loss = 99998\n",
    "    best_epoch = -1\n",
    "\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "    #scheduler = torch.optim.lr_scheduler.ExponentialLR(optimizer, gamma=0.9)\n",
    "    for epoch in range(n_epoch):\n",
    "        model.train()\n",
    "        xc_logits,xo_logits,xco_logits = model(g, features,torch.tensor(W_est_1[:-1,:]))\n",
    "        ##trivial part\n",
    "        uniform_target = torch.ones_like(xc_logits[train_mask], dtype=torch.float)/2\n",
    "        c_loss = F.kl_div(xc_logits[train_mask], uniform_target, reduction='batchmean')\n",
    "\n",
    "        o_loss = F.nll_loss(xo_logits[train_mask], labels[train_mask])\n",
    "        co_loss= F.nll_loss(xco_logits[train_mask], labels[train_mask])\n",
    "        loss = alpha * c_loss + beta * o_loss +gamma*co_loss\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        #scheduler.step()\n",
    "        ##evaluate\n",
    "        model.eval()\n",
    "        train_acc = evaluate_new(model, g, features, labels, train_mask,torch.tensor(W_est_1[:-1,:]))\n",
    "        valid_acc = evaluate_new(model, g, features, labels, valid_mask,torch.tensor(W_est_1[:-1,:]))\n",
    "        test_acc = evaluate_new(model, g_test, features_test, labels_test, valid_mask,torch.tensor(W_est_1[:-1,:]))\n",
    "        #valid loss\n",
    "        uniform_target = torch.ones_like(xc_logits[valid_mask], dtype=torch.float)/2\n",
    "        valid_c_loss = F.kl_div(xc_logits[valid_mask], uniform_target, reduction='batchmean')\n",
    "        valid_o_loss = F.nll_loss(xo_logits[valid_mask], labels[valid_mask])\n",
    "        valid_co_loss = F.nll_loss(xco_logits[valid_mask], labels[valid_mask])\n",
    "        valid_loss = alpha * valid_c_loss+beta *valid_o_loss+gamma*valid_co_loss\n",
    "        #test loss\n",
    "        test_xc_logits,test_xo_logits,test_xco_logits = model(g_test, features_test,torch.tensor(W_est_1[:-1,:]))\n",
    "        uniform_target = torch.ones_like(test_xo_logits[valid_mask], dtype=torch.float)/2\n",
    "        test_c_loss = F.kl_div(test_xc_logits[valid_mask], uniform_target, reduction='batchmean')\n",
    "        test_o_loss = F.nll_loss(test_xo_logits[valid_mask], labels_test[valid_mask])\n",
    "        test_co_loss = F.nll_loss(test_xco_logits[valid_mask], labels_test[valid_mask])\n",
    "        test_loss = alpha * test_c_loss + beta * test_o_loss+gamma*test_co_loss\n",
    "    #early stop     \n",
    "        if valid_loss < best_loss:\n",
    "            best_loss = valid_loss\n",
    "            best_epoch = epoch\n",
    "            #torch.save(model.state_dict(), \"attention_demo_large.pth\")\n",
    "        elif epoch - best_epoch > early_stop_thresh:\n",
    "            print(\"Early stopped training at epoch %d\" % epoch)\n",
    "            break  # terminate the training loop\n",
    "    print(\"proposed:train\",train_acc,\"valid\",valid_acc,\"test\",test_acc,\"n_suprious\",n_suprious)\n",
    "    output.loc[ith]=[train_acc,valid_acc,test_acc,\"proposed\",n_suprious]\n",
    "    ith+=1\n",
    "    if ith %20==0:\n",
    "        print(output.groupby(\"model\").mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "dbc1fcb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "output.to_csv(\"gauss,d=10,lr=0.01,alpha=0.2,beta=1,gamma=0.2,early_stop_thresh=50,n_epoch=300.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e42908e6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>train_acc</th>\n",
       "      <th>valid_acc</th>\n",
       "      <th>test_acc</th>\n",
       "      <th>n_suprious</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>model</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>GCN</th>\n",
       "      <td>0.857143</td>\n",
       "      <td>0.561905</td>\n",
       "      <td>0.585714</td>\n",
       "      <td>1.952381</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>proposed</th>\n",
       "      <td>0.869841</td>\n",
       "      <td>0.566667</td>\n",
       "      <td>0.485714</td>\n",
       "      <td>1.952381</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          train_acc  valid_acc  test_acc  n_suprious\n",
       "model                                               \n",
       "GCN        0.857143   0.561905  0.585714    1.952381\n",
       "proposed   0.869841   0.566667  0.485714    1.952381"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output.groupby(\"model\").mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "16efb753",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>train_acc</th>\n",
       "      <th>valid_acc</th>\n",
       "      <th>test_acc</th>\n",
       "      <th>n_suprious</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>model</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>GCN</th>\n",
       "      <td>0.134647</td>\n",
       "      <td>0.129209</td>\n",
       "      <td>0.137826</td>\n",
       "      <td>0.891914</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>proposed</th>\n",
       "      <td>0.115666</td>\n",
       "      <td>0.125962</td>\n",
       "      <td>0.139785</td>\n",
       "      <td>0.891914</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          train_acc  valid_acc  test_acc  n_suprious\n",
       "model                                               \n",
       "GCN        0.134647   0.129209  0.137826    0.891914\n",
       "proposed   0.115666   0.125962  0.139785    0.891914"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output.groupby(\"model\").std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fbbbd817",
   "metadata": {},
   "outputs": [],
   "source": [
    "diff_list=[]\n",
    "for i in range(50):\n",
    "    GCN=output.loc[i*2][\"test_acc\"]\n",
    "    proposed=output.loc[i*2+1][\"test_acc\"]\n",
    "    diff=proposed-GCN\n",
    "    diff_list.append(diff)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "f930a3a9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.01949153984476342"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "0.137826/np.sqrt(50)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
