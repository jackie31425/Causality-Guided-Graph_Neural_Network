{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2761e554",
   "metadata": {},
   "source": [
    "## data generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cacb334b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\lib\\site-packages\\numpy\\_distributor_init.py:32: UserWarning: loaded more than 1 DLL from .libs:\n",
      "D:\\Anaconda\\lib\\site-packages\\numpy\\.libs\\libopenblas.TXA6YQSD3GCQQC22GEQ54J2UDCXDXHWN.gfortran-win_amd64.dll\n",
      "D:\\Anaconda\\lib\\site-packages\\numpy\\.libs\\libopenblas.WCDJNK7YVMPZQ2ME2ZZHJJRJ3JIKNDB7.gfortran-win_amd64.dll\n",
      "  stacklevel=1)\n",
      "\n",
      "Bad key \"text.kerning_factor\" on line 4 in\n",
      "D:\\Anaconda\\lib\\site-packages\\matplotlib\\mpl-data\\stylelib\\_classic_test_patch.mplstyle.\n",
      "You probably need to get an updated matplotlibrc file from\n",
      "https://github.com/matplotlib/matplotlib/blob/v3.1.3/matplotlibrc.template\n",
      "or from the matplotlib source distribution\n",
      "Using backend: pytorch\n"
     ]
    }
   ],
   "source": [
    "from locally_connected import LocallyConnected\n",
    "from lbfgsb_scipy import LBFGSBScipy\n",
    "from trace_expm import trace_expm\n",
    "from sklearn.metrics import f1_score\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import scipy.sparse\n",
    "import GraphNOTEARS\n",
    "import notears_torch_version\n",
    "import lasso\n",
    "import dynotears\n",
    "import utils as ut\n",
    "import matplotlib.pyplot as plt\n",
    "import networkx as nx\n",
    "import dgl\n",
    "import random\n",
    "import utils as ut\n",
    "import dgl.function as fn\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from dgl import DGLGraph\n",
    "import pandas as pd\n",
    "#device = torch.device(\"cuda:0\")\n",
    "device = torch.device(\"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e45970cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_pre_new(n, d, s0, w_graph_type, p_graph_type, sem_type,ratio):\n",
    "    #binary W\n",
    "    w_true = ut.simulate_dag(d, s0, w_graph_type)\n",
    "    #weighted W\n",
    "    w_mat = ut.simulate_parameter(w_true)\n",
    "    w_test_mat=w_mat.copy()\n",
    "    #A\n",
    "    adj1 = ut.generate_adj(n) \n",
    "    #node to target\n",
    "    num_target=np.nonzero(w_mat[:,-1])[0]#4,14\n",
    "    n_suprious=-1.0\n",
    "    suprious_dict={}\n",
    "    #if no suprious variable existed\n",
    "    if len(num_target)==0:\n",
    "        return w_mat,w_mat, w_mat, w_mat,w_mat,w_mat,n_suprious,w_mat\n",
    "    else:\n",
    "        #create the spurious variable\n",
    "        for i in range(len(num_target)):\n",
    "            suprious_list=np.nonzero(w_mat[num_target[i],:])[0]#12\n",
    "\n",
    "            for j in range(len(suprious_list)): \n",
    "                suprious=suprious_list[j]\n",
    "                #count the number of suprious variable\n",
    "                if suprious not in suprious_dict:\n",
    "                    suprious_dict[suprious]=1\n",
    "                    n_suprious+=1\n",
    "                    #remove other outgoing link\n",
    "                    w_mat[suprious,:]=0 #12,0\n",
    "                    w_test_mat[suprious,:]=0\n",
    "                    #print(suprious)\n",
    "                    #revert the link in the test\n",
    "                    if suprious!=d-1:\n",
    "                        w_test_mat[num_target[i],suprious]=ratio*w_test_mat[num_target[i],suprious]\n",
    "                \n",
    "                \n",
    "    num_step = 5 #cannot work if num_step=1\n",
    "    #initial X0=X0W+B\n",
    "    Xbase = []\n",
    "    Xbase1 = ut.simulate_linear_sem(w_mat, n, sem_type, noise_scale=0.5)\n",
    "    #X1=X1W+AX0W+B\n",
    "    for i in range(num_step):\n",
    "        Xbase1 = ut.simulate_linear_sem_with_P(w_mat, w_mat, adj1@Xbase1, n, sem_type, noise_scale=1)\n",
    "        Xbase.append(Xbase1)\n",
    "        \n",
    "    #test data\n",
    "    Xbase_test = []\n",
    "    Xbase1_test = ut.simulate_linear_sem(w_test_mat, n, sem_type, noise_scale=0.5)\n",
    "    for i in range(num_step):\n",
    "        Xbase1_test = ut.simulate_linear_sem_with_P(w_test_mat, w_test_mat, adj1@Xbase1_test, n, sem_type, noise_scale=1)\n",
    "        Xbase_test.append(Xbase1_test)\n",
    "    \n",
    "    w_random = ut.simulate_dag(d, s0, w_graph_type)\n",
    "    return Xbase,Xbase_test, adj1, w_true,w_mat,w_test_mat,n_suprious,w_random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e865265d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_node_feature(Xlags,node_num):\n",
    "#     for num_lags in range(1):\n",
    "#         if num_lags==0:\n",
    "#             X_feature=Xlags[num_lags][node_num]\n",
    "#         else:\n",
    "#             X_feature=np.append(X_feature,Xlags[num_lags][node_num])##shape num_lags*5 (250)\n",
    "    X_feature=Xlags[-1][node_num]\n",
    "    return(X_feature)\n",
    "def to_binary(x):\n",
    "    if x>Xlags[-1][:,-1].mean():\n",
    "        return 1\n",
    "    else:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ab86e196",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_graph(valid_list,adj1,Xlags,n):\n",
    " ##node list for validation\n",
    "    labels=[]\n",
    "    G = nx.from_numpy_array(adj1)\n",
    "    for node_num in range(n):\n",
    "        G.nodes[node_num]['feature']=get_node_feature(Xlags,node_num)[:-1]\n",
    "\n",
    "        G.nodes[node_num]['label']=to_binary(get_node_feature(Xlags,node_num)[-1])\n",
    "\n",
    "        labels.append(G.nodes[node_num]['label'])\n",
    "        if node_num in valid_list:\n",
    "            G.nodes[node_num]['train_mask']=False\n",
    "            G.nodes[node_num]['valid_mask']=True\n",
    "        else:\n",
    "            G.nodes[node_num]['train_mask']=True\n",
    "            G.nodes[node_num]['valid_mask']=False\n",
    "    g = dgl.from_networkx(G, node_attrs=['feature','label','train_mask','valid_mask'])\n",
    "    return g"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1556b5a5",
   "metadata": {},
   "source": [
    "## GAT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "26c9a388",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GATLayer(nn.Module):\n",
    "    def __init__(self, g, in_dim, out_dim):\n",
    "        super(GATLayer, self).__init__()\n",
    "        self.g = g\n",
    "        # equation (1)\n",
    "        self.fc = nn.Linear(in_dim, out_dim, bias=False)\n",
    "        # equation (2)\n",
    "        self.attn_fc = nn.Linear(2 * out_dim, 1, bias=False)\n",
    "    \n",
    "    def edge_attention(self, edges):\n",
    "        # edge UDF for equation (2)\n",
    "        z2 = torch.cat([edges.src['z'], edges.dst['z']], dim=1)\n",
    "        a = self.attn_fc(z2)\n",
    "        return {'e' : F.leaky_relu(a)}\n",
    "    \n",
    "    def message_func(self, edges):\n",
    "        # message UDF for equation (3) & (4)\n",
    "        return {'z' : edges.src['z'], 'e' : edges.data['e']}\n",
    "    \n",
    "    def reduce_func(self, nodes):\n",
    "        # reduce UDF for equation (3) & (4)\n",
    "        # equation (3)\n",
    "        alpha = F.softmax(nodes.mailbox['e'], dim=1)\n",
    "        # equation (4)\n",
    "        h = torch.sum(alpha * nodes.mailbox['z'], dim=1)\n",
    "        return {'h' : h}\n",
    "    \n",
    "    def forward(self, h):\n",
    "        # equation (1)\n",
    "        z = self.fc(h)\n",
    "        self.g.ndata['z'] = z\n",
    "        # equation (2)\n",
    "        self.g.apply_edges(self.edge_attention)\n",
    "        # equation (3) & (4)\n",
    "        self.g.update_all(self.message_func, self.reduce_func)\n",
    "        return self.g.ndata.pop('h')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c0f7691c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiHeadGATLayer(nn.Module):\n",
    "    def __init__(self, g, in_dim, out_dim, num_heads, merge='cat'):\n",
    "        super(MultiHeadGATLayer, self).__init__()\n",
    "        self.heads = nn.ModuleList()\n",
    "        for i in range(num_heads):\n",
    "            self.heads.append(GATLayer(g, in_dim, out_dim))\n",
    "        self.merge = merge\n",
    "    \n",
    "    def forward(self, h):\n",
    "        head_outs = [attn_head(h) for attn_head in self.heads]\n",
    "        if self.merge == 'cat':\n",
    "            # concat on the output feature dimension (dim=1)\n",
    "            return torch.cat(head_outs, dim=1)\n",
    "        else:\n",
    "            # merge using average\n",
    "            return torch.mean(torch.stack(head_outs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d77925e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GAT(nn.Module):\n",
    "    def __init__(self, g, in_dim, hidden_dim, out_dim, num_heads):\n",
    "        super(GAT, self).__init__()\n",
    "        self.layer1 = MultiHeadGATLayer(g, in_dim, hidden_dim, num_heads)\n",
    "        # Be aware that the input dimension is hidden_dim*num_heads since\n",
    "        #   multiple head outputs are concatenated together. Also, only\n",
    "        #   one attention head in the output layer.\n",
    "        self.layer2 = MultiHeadGATLayer(g, hidden_dim * num_heads, out_dim, 1)\n",
    "    \n",
    "    def forward(self, h):\n",
    "        h = self.layer1(h)\n",
    "        h = F.elu(h)\n",
    "        h = self.layer2(h)\n",
    "        return h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cf70bd42",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, g, features, labels, mask):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        logits = model(features)\n",
    "        logits = logits[mask]\n",
    "        labels = labels[mask]\n",
    "        _, indices = torch.max(logits, dim=1)\n",
    "        correct = torch.sum(indices == labels)\n",
    "        return correct.item() * 1.0 / len(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4ca3d404",
   "metadata": {},
   "outputs": [],
   "source": [
    "class atten_Net(nn.Module):\n",
    "    def __init__(self,g, in_feats, hid_feats, out_feats,n_node,num_heads):\n",
    "        super(atten_Net, self).__init__()\n",
    "        self.layer1 = MultiHeadGATLayer(g, in_feats, hid_feats, num_heads)\n",
    "        self.layer2 = MultiHeadGATLayer(g, hid_feats * num_heads, out_feats, 1)\n",
    "        self.att_mlp_1 = nn.Linear(n_node, hid_feats)\n",
    "        self.att_mlp_2 = nn.Linear(hid_feats, 2)\n",
    "        self.layer3 = MultiHeadGATLayer(g, in_feats*2, hid_feats, num_heads)\n",
    "        self.layer4 = MultiHeadGATLayer(g, hid_feats * num_heads, out_feats, 1)\n",
    "\n",
    "    def forward(self, g, features,dag):\n",
    "        ##use mlp to get attention weights\n",
    "        node_att = F.relu(self.att_mlp_1(dag))\n",
    "        node_att = F.softmax(self.att_mlp_2(node_att), dim=-1)\n",
    "        node_weight_c = node_att[:, 0]\n",
    "        node_weight_o = node_att[:, 1]\n",
    "        ##attention on the causal/trival part\n",
    "        feature_c = node_weight_c.view(1, -1) * features\n",
    "        feature_o = node_weight_o.view(1, -1) * features\n",
    "        ## apply the mask on the features\n",
    "        xc = F.relu(self.layer1(feature_c))\n",
    "        xc = self.layer2(xc)\n",
    "        xc=F.log_softmax(xc, dim=-1)\n",
    "        \n",
    "        xo = F.relu(self.layer1(feature_o))\n",
    "        xo = self.layer2(xo)\n",
    "        xo=F.log_softmax(xo, dim=-1)\n",
    "        ##xco        \n",
    "        num = xc.shape[0]\n",
    "        l = [i for i in range(num)]\n",
    "        random.shuffle(l)\n",
    "        random_idx = torch.tensor(l)\n",
    "        xco = torch.cat((feature_c[random_idx], feature_o), dim=1)\n",
    "        xco = F.relu(self.layer3(xco))\n",
    "        xco = self.layer4(xco)\n",
    "        xco=F.log_softmax(xco, dim=-1)\n",
    "        \n",
    "        return xc,xo,xco"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7db3a7bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_new(model, g, features, labels, mask,dag):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        logits_c,logits_o,logits_co = model(g, features,dag)\n",
    "        logits = logits_o[mask]\n",
    "        labels = labels[mask]\n",
    "        _, indices = torch.max(logits, dim=1)\n",
    "        correct = torch.sum(indices == labels)\n",
    "        return correct.item() * 1.0 / len(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a08dbdd6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------the 0 iteration------------------\n",
      "finish data!\n",
      "Early stopped training at epoch 31\n",
      "proposed:train 0.7333333333333333 valid 0.5 test 0.5 n_suprious 2.0\n",
      "-------------------the 1 iteration------------------\n",
      "finish data!\n",
      "Early stopped training at epoch 64\n",
      "proposed:train 1.0 valid 0.8 test 0.55 n_suprious 2.0\n",
      "-------------------the 2 iteration------------------\n",
      "-------------------the 2 iteration------------------\n",
      "-------------------the 2 iteration------------------\n",
      "finish data!\n",
      "Early stopped training at epoch 66\n",
      "proposed:train 0.8 valid 0.45 test 0.35 n_suprious 2.0\n",
      "-------------------the 3 iteration------------------\n",
      "-------------------the 3 iteration------------------\n",
      "-------------------the 3 iteration------------------\n",
      "-------------------the 3 iteration------------------\n",
      "-------------------the 3 iteration------------------\n",
      "finish data!\n",
      "Early stopped training at epoch 62\n",
      "proposed:train 0.9 valid 0.55 test 0.75 n_suprious 1.0\n",
      "-------------------the 4 iteration------------------\n",
      "finish data!\n",
      "Early stopped training at epoch 80\n",
      "proposed:train 0.9333333333333333 valid 0.55 test 0.6 n_suprious 1.0\n",
      "-------------------the 5 iteration------------------\n",
      "-------------------the 5 iteration------------------\n",
      "finish data!\n",
      "Early stopped training at epoch 31\n",
      "proposed:train 0.6333333333333333 valid 0.35 test 0.45 n_suprious 4.0\n",
      "-------------------the 6 iteration------------------\n",
      "-------------------the 6 iteration------------------\n",
      "-------------------the 6 iteration------------------\n",
      "finish data!\n",
      "Early stopped training at epoch 47\n",
      "proposed:train 0.8333333333333334 valid 0.5 test 0.55 n_suprious 4.0\n",
      "-------------------the 7 iteration------------------\n",
      "-------------------the 7 iteration------------------\n",
      "-------------------the 7 iteration------------------\n",
      "finish data!\n",
      "Early stopped training at epoch 31\n",
      "proposed:train 0.8 valid 0.65 test 0.7 n_suprious 2.0\n",
      "-------------------the 8 iteration------------------\n",
      "-------------------the 8 iteration------------------\n",
      "-------------------the 8 iteration------------------\n",
      "-------------------the 8 iteration------------------\n",
      "-------------------the 8 iteration------------------\n",
      "finish data!\n",
      "Early stopped training at epoch 32\n",
      "proposed:train 0.7666666666666667 valid 0.3 test 0.5 n_suprious 1.0\n",
      "-------------------the 9 iteration------------------\n",
      "finish data!\n",
      "Early stopped training at epoch 79\n",
      "proposed:train 0.8333333333333334 valid 0.85 test 0.6 n_suprious 4.0\n",
      "          train_acc  valid_acc  test_acc  n_suprious\n",
      "model                                               \n",
      "proposed   0.823333       0.55     0.555         2.3\n",
      "-------------------the 10 iteration------------------\n",
      "finish data!\n",
      "Early stopped training at epoch 34\n",
      "proposed:train 0.8666666666666667 valid 0.6 test 0.65 n_suprious 2.0\n",
      "-------------------the 11 iteration------------------\n",
      "-------------------the 11 iteration------------------\n",
      "finish data!\n",
      "Early stopped training at epoch 31\n",
      "proposed:train 0.8 valid 0.35 test 0.6 n_suprious 3.0\n",
      "-------------------the 12 iteration------------------\n",
      "finish data!\n",
      "Early stopped training at epoch 69\n",
      "proposed:train 0.9 valid 0.6 test 0.85 n_suprious 3.0\n",
      "-------------------the 13 iteration------------------\n",
      "finish data!\n",
      "Early stopped training at epoch 96\n",
      "proposed:train 0.7666666666666667 valid 0.65 test 0.55 n_suprious 1.0\n",
      "-------------------the 14 iteration------------------\n",
      "finish data!\n",
      "Early stopped training at epoch 31\n",
      "proposed:train 0.6666666666666666 valid 0.4 test 0.5 n_suprious 2.0\n",
      "-------------------the 15 iteration------------------\n",
      "-------------------the 15 iteration------------------\n",
      "-------------------the 15 iteration------------------\n",
      "-------------------the 15 iteration------------------\n",
      "finish data!\n",
      "Early stopped training at epoch 37\n",
      "proposed:train 0.7 valid 0.5 test 0.5 n_suprious 2.0\n",
      "-------------------the 16 iteration------------------\n",
      "finish data!\n",
      "Early stopped training at epoch 36\n",
      "proposed:train 0.7333333333333333 valid 0.45 test 0.4 n_suprious 2.0\n",
      "-------------------the 17 iteration------------------\n",
      "-------------------the 17 iteration------------------\n",
      "-------------------the 17 iteration------------------\n",
      "-------------------the 17 iteration------------------\n",
      "finish data!\n",
      "Early stopped training at epoch 68\n",
      "proposed:train 0.9 valid 0.65 test 0.6 n_suprious 3.0\n",
      "-------------------the 18 iteration------------------\n",
      "finish data!\n",
      "Early stopped training at epoch 31\n",
      "proposed:train 0.6 valid 0.35 test 0.45 n_suprious 3.0\n",
      "-------------------the 19 iteration------------------\n",
      "finish data!\n",
      "Early stopped training at epoch 69\n",
      "proposed:train 0.8333333333333334 valid 0.4 test 0.35 n_suprious 1.0\n",
      "          train_acc  valid_acc  test_acc  n_suprious\n",
      "model                                               \n",
      "proposed        0.8     0.5225      0.55        2.25\n",
      "-------------------the 20 iteration------------------\n",
      "-------------------the 20 iteration------------------\n",
      "finish data!\n",
      "Early stopped training at epoch 33\n",
      "proposed:train 0.7333333333333333 valid 0.55 test 0.55 n_suprious 2.0\n",
      "-------------------the 21 iteration------------------\n",
      "-------------------the 21 iteration------------------\n",
      "finish data!\n",
      "Early stopped training at epoch 35\n",
      "proposed:train 0.7333333333333333 valid 0.45 test 0.45 n_suprious 3.0\n",
      "-------------------the 22 iteration------------------\n",
      "-------------------the 22 iteration------------------\n",
      "-------------------the 22 iteration------------------\n",
      "finish data!\n",
      "Early stopped training at epoch 53\n",
      "proposed:train 0.8666666666666667 valid 0.45 test 0.65 n_suprious 1.0\n",
      "-------------------the 23 iteration------------------\n",
      "finish data!\n",
      "Early stopped training at epoch 31\n",
      "proposed:train 0.7 valid 0.35 test 0.7 n_suprious 1.0\n",
      "-------------------the 24 iteration------------------\n",
      "-------------------the 24 iteration------------------\n",
      "finish data!\n",
      "Early stopped training at epoch 31\n",
      "proposed:train 0.6333333333333333 valid 0.25 test 0.45 n_suprious 1.0\n",
      "-------------------the 25 iteration------------------\n",
      "-------------------the 25 iteration------------------\n",
      "-------------------the 25 iteration------------------\n",
      "finish data!\n",
      "Early stopped training at epoch 31\n",
      "proposed:train 0.6666666666666666 valid 0.45 test 0.75 n_suprious 1.0\n",
      "-------------------the 26 iteration------------------\n",
      "finish data!\n",
      "Early stopped training at epoch 34\n",
      "proposed:train 0.7 valid 0.6 test 0.6 n_suprious 4.0\n",
      "-------------------the 27 iteration------------------\n",
      "-------------------the 27 iteration------------------\n",
      "finish data!\n",
      "Early stopped training at epoch 31\n",
      "proposed:train 0.8666666666666667 valid 0.35 test 0.35 n_suprious 1.0\n",
      "-------------------the 28 iteration------------------\n",
      "-------------------the 28 iteration------------------\n",
      "finish data!\n",
      "Early stopped training at epoch 57\n",
      "proposed:train 0.9 valid 0.65 test 0.45 n_suprious 1.0\n",
      "-------------------the 29 iteration------------------\n",
      "finish data!\n",
      "Early stopped training at epoch 33\n",
      "proposed:train 0.8 valid 0.55 test 0.7 n_suprious 1.0\n",
      "          train_acc  valid_acc  test_acc  n_suprious\n",
      "model                                               \n",
      "proposed   0.786667   0.503333     0.555    2.033333\n",
      "-------------------the 30 iteration------------------\n",
      "-------------------the 30 iteration------------------\n",
      "-------------------the 30 iteration------------------\n",
      "-------------------the 30 iteration------------------\n",
      "-------------------the 30 iteration------------------\n",
      "-------------------the 30 iteration------------------\n",
      "finish data!\n",
      "Early stopped training at epoch 66\n",
      "proposed:train 0.7333333333333333 valid 0.6 test 0.55 n_suprious 3.0\n",
      "-------------------the 31 iteration------------------\n",
      "finish data!\n",
      "Early stopped training at epoch 79\n",
      "proposed:train 0.9 valid 0.6 test 0.6 n_suprious 2.0\n",
      "-------------------the 32 iteration------------------\n",
      "finish data!\n",
      "Early stopped training at epoch 35\n",
      "proposed:train 0.6 valid 0.55 test 0.4 n_suprious 4.0\n",
      "-------------------the 33 iteration------------------\n",
      "-------------------the 33 iteration------------------\n",
      "-------------------the 33 iteration------------------\n",
      "-------------------the 33 iteration------------------\n",
      "finish data!\n",
      "Early stopped training at epoch 31\n",
      "proposed:train 0.6 valid 0.45 test 0.15 n_suprious 2.0\n",
      "-------------------the 34 iteration------------------\n",
      "-------------------the 34 iteration------------------\n",
      "-------------------the 34 iteration------------------\n",
      "finish data!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopped training at epoch 71\n",
      "proposed:train 0.9333333333333333 valid 0.65 test 0.6 n_suprious 1.0\n",
      "-------------------the 35 iteration------------------\n",
      "finish data!\n",
      "Early stopped training at epoch 38\n",
      "proposed:train 0.7333333333333333 valid 0.5 test 0.6 n_suprious 4.0\n",
      "-------------------the 36 iteration------------------\n",
      "-------------------the 36 iteration------------------\n",
      "-------------------the 36 iteration------------------\n",
      "finish data!\n",
      "Early stopped training at epoch 35\n",
      "proposed:train 0.6333333333333333 valid 0.6 test 0.6 n_suprious 3.0\n",
      "-------------------the 37 iteration------------------\n",
      "-------------------the 37 iteration------------------\n",
      "-------------------the 37 iteration------------------\n",
      "-------------------the 37 iteration------------------\n",
      "-------------------the 37 iteration------------------\n",
      "finish data!\n",
      "Early stopped training at epoch 68\n",
      "proposed:train 0.9 valid 0.55 test 0.4 n_suprious 1.0\n",
      "-------------------the 38 iteration------------------\n",
      "-------------------the 38 iteration------------------\n",
      "finish data!\n",
      "Early stopped training at epoch 35\n",
      "proposed:train 0.7666666666666667 valid 0.5 test 0.45 n_suprious 3.0\n",
      "-------------------the 39 iteration------------------\n",
      "-------------------the 39 iteration------------------\n",
      "-------------------the 39 iteration------------------\n",
      "-------------------the 39 iteration------------------\n",
      "-------------------the 39 iteration------------------\n",
      "finish data!\n",
      "Early stopped training at epoch 46\n",
      "proposed:train 0.8 valid 0.65 test 0.45 n_suprious 4.0\n",
      "          train_acc  valid_acc  test_acc  n_suprious\n",
      "model                                               \n",
      "proposed       0.78    0.51875   0.53625         2.2\n",
      "-------------------the 40 iteration------------------\n",
      "finish data!\n",
      "Early stopped training at epoch 31\n",
      "proposed:train 0.6666666666666666 valid 0.55 test 0.4 n_suprious 2.0\n",
      "-------------------the 41 iteration------------------\n",
      "finish data!\n",
      "Early stopped training at epoch 64\n",
      "proposed:train 0.9 valid 0.5 test 0.6 n_suprious 4.0\n",
      "-------------------the 42 iteration------------------\n",
      "finish data!\n",
      "Early stopped training at epoch 83\n",
      "proposed:train 0.8666666666666667 valid 0.55 test 0.55 n_suprious 1.0\n",
      "-------------------the 43 iteration------------------\n",
      "finish data!\n",
      "Early stopped training at epoch 50\n",
      "proposed:train 0.7666666666666667 valid 0.65 test 0.6 n_suprious 4.0\n",
      "-------------------the 44 iteration------------------\n",
      "-------------------the 44 iteration------------------\n",
      "finish data!\n",
      "Early stopped training at epoch 72\n",
      "proposed:train 0.9 valid 0.4 test 0.45 n_suprious 1.0\n",
      "-------------------the 45 iteration------------------\n",
      "finish data!\n",
      "Early stopped training at epoch 31\n",
      "proposed:train 0.6333333333333333 valid 0.5 test 0.55 n_suprious 2.0\n",
      "-------------------the 46 iteration------------------\n",
      "-------------------the 46 iteration------------------\n",
      "-------------------the 46 iteration------------------\n",
      "finish data!\n",
      "Early stopped training at epoch 74\n",
      "proposed:train 0.8666666666666667 valid 0.9 test 0.5 n_suprious 3.0\n",
      "-------------------the 47 iteration------------------\n",
      "finish data!\n",
      "Early stopped training at epoch 37\n",
      "proposed:train 0.7666666666666667 valid 0.6 test 0.45 n_suprious 1.0\n",
      "-------------------the 48 iteration------------------\n",
      "finish data!\n",
      "Early stopped training at epoch 70\n",
      "proposed:train 0.9333333333333333 valid 0.45 test 0.4 n_suprious 3.0\n",
      "-------------------the 49 iteration------------------\n",
      "-------------------the 49 iteration------------------\n",
      "-------------------the 49 iteration------------------\n",
      "finish data!\n",
      "Early stopped training at epoch 65\n",
      "proposed:train 0.6 valid 0.65 test 0.55 n_suprious 1.0\n",
      "          train_acc  valid_acc  test_acc  n_suprious\n",
      "model                                               \n",
      "proposed      0.782       0.53      0.53         2.2\n"
     ]
    }
   ],
   "source": [
    "torch.set_default_dtype(torch.double)\n",
    "np.set_printoptions(precision=3)\n",
    "\n",
    "torch.manual_seed(12345)\n",
    "ut.set_random_seed(12345)\n",
    "\n",
    "n = 50 #number of people\n",
    "\n",
    "d = 15 #number of features\n",
    "\n",
    "\n",
    "w_graph_type = 'ER'\n",
    "p_graph_type = 'ER' \n",
    "sem_type = 'exp'\n",
    "s0 =  d\n",
    "#params\n",
    "ratio=-0.3\n",
    "lr=0.005\n",
    "alpha=0.2\n",
    "beta=1\n",
    "gamma=0.2\n",
    "early_stop_thresh=30\n",
    "n_epoch=300\n",
    "output=pd.DataFrame(columns=[\"train_acc\",\"valid_acc\",\"test_acc\",\"model\",\"n_suprious\"])\n",
    "ith=0\n",
    "replicates=50\n",
    "while ith<2*replicates:\n",
    "    print(\"-------------------the\",ith//2,\"iteration------------------\")\n",
    "    #create data\n",
    "    Xlags,Xlags_test, adj1, w_true,w_mat,w_test_mat,n_suprious,w_random = data_pre_new(n, d, s0, w_graph_type,p_graph_type, sem_type,ratio)\n",
    "    if n_suprious<=0:\n",
    "        continue\n",
    "    Xlags_torch = torch.Tensor(np.array(Xlags))\n",
    "    print(\"finish data!\")\n",
    "    #fit the causal graph\n",
    "#     adj1_torch = torch.Tensor(adj1)\n",
    "#     model_1 = GraphNOTEARS.model_p1_MLP(dims=[d, n, 1], bias=True)\n",
    "#     W_est_1, P1_est_1 = GraphNOTEARS.linear_model(model_1, Xlags_torch, adj1_torch,  lambda1 = 0.01, lambda2 = 0.01, lambda3 = 0.01)\n",
    "#     print(\"finish fit graph!\")\n",
    "    #g,g_test\n",
    "    valid_list=random.sample(range(n), int(n*0.4))\n",
    "    g = create_graph(valid_list,adj1,Xlags,n)\n",
    "    g_test=create_graph(valid_list,adj1,Xlags_test,n)\n",
    "#     #GAT\n",
    "#     net = GAT(g, \n",
    "#           in_dim=d-1, \n",
    "#           hidden_dim=4, \n",
    "#           out_dim=2, \n",
    "#           num_heads=2)\n",
    "\n",
    "    features = g.ndata['feature']\n",
    "    labels = g.ndata['label']\n",
    "    train_mask = g.ndata['train_mask']\n",
    "    valid_mask = g.ndata['valid_mask']\n",
    "#     ###test\n",
    "    features_test = g_test.ndata['feature']\n",
    "    labels_test = g_test.ndata['label']\n",
    "#     #parameters\n",
    "#     optimizer = torch.optim.Adam(net.parameters(), lr=lr)\n",
    "\n",
    "#     best_loss = 99998\n",
    "#     best_epoch = -1\n",
    "#     for epoch in range(n_epoch):\n",
    "#         net.train()\n",
    "#         logits = net(features)\n",
    "        \n",
    "#         logp = F.log_softmax(logits, dim=-1)\n",
    "#         loss = F.nll_loss(logp[train_mask], labels[train_mask])\n",
    "\n",
    "#         optimizer.zero_grad()\n",
    "#         loss.backward()\n",
    "#         optimizer.step()\n",
    "#         ##evaluate\n",
    "#         net.eval()\n",
    "#         train_acc = evaluate(net, g, features, labels, train_mask)\n",
    "#         valid_acc = evaluate(net, g, features, labels, valid_mask)\n",
    "#         test_acc = evaluate(net, g_test, features_test, labels_test, valid_mask)\n",
    "#         valid_loss = F.nll_loss(logp[valid_mask], labels[valid_mask])\n",
    "#         #early stop\n",
    "#         if valid_loss < best_loss:\n",
    "#             best_loss = valid_loss\n",
    "#             best_epoch = epoch\n",
    "#             #torch.save(net.state_dict(), \"GCN_demo_large.pth\")\n",
    "#         elif epoch - best_epoch > early_stop_thresh:\n",
    "#             print(\"Early stopped training at epoch %d\" % epoch)\n",
    "#             break  # terminate the training loop\n",
    "#     print(\"GCN:train\",train_acc,\"valid\",valid_acc,\"test\",test_acc)\n",
    "#     output.loc[ith]=[train_acc,valid_acc,test_acc,\"GCN\",n_suprious]\n",
    "    ith+=1\n",
    "    ##proposed\n",
    "    model = atten_Net(g,num_heads=2,in_feats=d-1, hid_feats=8, out_feats=2,n_node=d)\n",
    "\n",
    "    #params\n",
    "    best_loss = 99998\n",
    "    best_epoch = -1\n",
    "\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "    #scheduler = torch.optim.lr_scheduler.ExponentialLR(optimizer, gamma=0.9)\n",
    "    for epoch in range(n_epoch):\n",
    "        model.train()\n",
    "        xc_logits,xo_logits,xco_logits = model(g, features,torch.tensor(w_random[:-1,:]))\n",
    "        ##trivial part\n",
    "        uniform_target = torch.ones_like(xc_logits[train_mask], dtype=torch.double)/2\n",
    "        c_loss = F.kl_div(xc_logits[train_mask], uniform_target, reduction='batchmean')\n",
    "\n",
    "        o_loss = F.nll_loss(xo_logits[train_mask], labels[train_mask])\n",
    "        co_loss= F.nll_loss(xco_logits[train_mask], labels[train_mask])\n",
    "        loss = alpha * c_loss + beta * o_loss +gamma*co_loss\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        #scheduler.step()\n",
    "        ##evaluate\n",
    "        model.eval()\n",
    "        train_acc = evaluate_new(model, g, features, labels, train_mask,torch.tensor(w_random[:-1,:]))\n",
    "        valid_acc = evaluate_new(model, g, features, labels, valid_mask,torch.tensor(w_random[:-1,:]))\n",
    "        test_acc = evaluate_new(model, g_test, features_test, labels_test, valid_mask,torch.tensor(w_random[:-1,:]))\n",
    "        #valid loss\n",
    "        uniform_target = torch.ones_like(xc_logits[valid_mask], dtype=torch.double)/2\n",
    "        valid_c_loss = F.kl_div(xc_logits[valid_mask], uniform_target, reduction='batchmean')\n",
    "        valid_o_loss = F.nll_loss(xo_logits[valid_mask], labels[valid_mask])\n",
    "        valid_co_loss = F.nll_loss(xco_logits[valid_mask], labels[valid_mask])\n",
    "        valid_loss = alpha * valid_c_loss+beta *valid_o_loss+gamma*valid_co_loss\n",
    "        #test loss\n",
    "        test_xc_logits,test_xo_logits,test_xco_logits = model(g_test, features_test,torch.tensor(w_random[:-1,:]))\n",
    "        uniform_target = torch.ones_like(test_xo_logits[valid_mask], dtype=torch.double)/2\n",
    "        test_c_loss = F.kl_div(test_xc_logits[valid_mask], uniform_target, reduction='batchmean')\n",
    "        test_o_loss = F.nll_loss(test_xo_logits[valid_mask], labels_test[valid_mask])\n",
    "        test_co_loss = F.nll_loss(test_xco_logits[valid_mask], labels_test[valid_mask])\n",
    "        test_loss = alpha * test_c_loss + beta * test_o_loss+gamma*test_co_loss\n",
    "    #early stop     \n",
    "        if valid_loss < best_loss:\n",
    "            best_loss = valid_loss\n",
    "            best_epoch = epoch\n",
    "            #torch.save(model.state_dict(), \"attention_demo_large.pth\")\n",
    "        elif epoch - best_epoch > early_stop_thresh:\n",
    "            print(\"Early stopped training at epoch %d\" % epoch)\n",
    "            break  # terminate the training loop\n",
    "    print(\"proposed:train\",train_acc,\"valid\",valid_acc,\"test\",test_acc,\"n_suprious\",n_suprious)\n",
    "    output.loc[ith]=[train_acc,valid_acc,test_acc,\"proposed\",n_suprious]\n",
    "    ith+=1\n",
    "    if ith %20==0:\n",
    "        print(output.groupby(\"model\").mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "dbc1fcb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "output.to_csv(\"random,gat,d=15,lr=0.005,alpha=0.2,beta=1,gamma=0.2,early_stop_thresh=30,n_epoch=300,ratio=-0.3.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e42908e6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>train_acc</th>\n",
       "      <th>valid_acc</th>\n",
       "      <th>test_acc</th>\n",
       "      <th>n_suprious</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>model</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>proposed</th>\n",
       "      <td>0.782</td>\n",
       "      <td>0.53</td>\n",
       "      <td>0.53</td>\n",
       "      <td>2.2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          train_acc  valid_acc  test_acc  n_suprious\n",
       "model                                               \n",
       "proposed      0.782       0.53      0.53         2.2"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output.groupby(\"model\").mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "16efb753",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>train_acc</th>\n",
       "      <th>valid_acc</th>\n",
       "      <th>test_acc</th>\n",
       "      <th>n_suprious</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>model</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>proposed</th>\n",
       "      <td>0.015244</td>\n",
       "      <td>0.018736</td>\n",
       "      <td>0.017613</td>\n",
       "      <td>0.159079</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          train_acc  valid_acc  test_acc  n_suprious\n",
       "model                                               \n",
       "proposed   0.015244   0.018736  0.017613    0.159079"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output.groupby(\"model\").std()/np.sqrt(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "fbbbd817",
   "metadata": {},
   "outputs": [],
   "source": [
    "diff_list=[]\n",
    "for i in range(50):\n",
    "    GCN=output.loc[i*2][\"test_acc\"]\n",
    "    proposed=output.loc[i*2+1][\"test_acc\"]\n",
    "    diff=proposed-GCN\n",
    "    diff_list.append(diff)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f930a3a9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.01584103037620975"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "0.112013/np.sqrt(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71a1e9e8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
