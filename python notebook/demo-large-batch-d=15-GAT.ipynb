{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2761e554",
   "metadata": {},
   "source": [
    "## data generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cacb334b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\lib\\site-packages\\numpy\\_distributor_init.py:32: UserWarning: loaded more than 1 DLL from .libs:\n",
      "D:\\Anaconda\\lib\\site-packages\\numpy\\.libs\\libopenblas.TXA6YQSD3GCQQC22GEQ54J2UDCXDXHWN.gfortran-win_amd64.dll\n",
      "D:\\Anaconda\\lib\\site-packages\\numpy\\.libs\\libopenblas.WCDJNK7YVMPZQ2ME2ZZHJJRJ3JIKNDB7.gfortran-win_amd64.dll\n",
      "  stacklevel=1)\n",
      "\n",
      "Bad key \"text.kerning_factor\" on line 4 in\n",
      "D:\\Anaconda\\lib\\site-packages\\matplotlib\\mpl-data\\stylelib\\_classic_test_patch.mplstyle.\n",
      "You probably need to get an updated matplotlibrc file from\n",
      "https://github.com/matplotlib/matplotlib/blob/v3.1.3/matplotlibrc.template\n",
      "or from the matplotlib source distribution\n",
      "Using backend: pytorch\n"
     ]
    }
   ],
   "source": [
    "from locally_connected import LocallyConnected\n",
    "from lbfgsb_scipy import LBFGSBScipy\n",
    "from trace_expm import trace_expm\n",
    "from sklearn.metrics import f1_score\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import scipy.sparse\n",
    "import GraphNOTEARS\n",
    "import notears_torch_version\n",
    "import lasso\n",
    "import dynotears\n",
    "import utils as ut\n",
    "import matplotlib.pyplot as plt\n",
    "import networkx as nx\n",
    "import dgl\n",
    "import random\n",
    "import utils as ut\n",
    "import dgl.function as fn\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from dgl import DGLGraph\n",
    "import pandas as pd\n",
    "#device = torch.device(\"cuda:0\")\n",
    "device = torch.device(\"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e45970cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_pre(n, d, s0, w_graph_type, p_graph_type, sem_type):\n",
    "    #binary W\n",
    "    w_true = ut.simulate_dag(d, s0, w_graph_type)\n",
    "    #weighted W\n",
    "    w_mat = ut.simulate_parameter(w_true)\n",
    "    w_test_mat=w_mat.copy()\n",
    "    #A\n",
    "    adj1 = ut.generate_adj(n) \n",
    "    #node to target\n",
    "    num_target=np.nonzero(w_mat[:,-1])[0]#4,14\n",
    "    n_suprious=-1.0\n",
    "    suprious_dict={}\n",
    "    #if no suprious variable existed\n",
    "    if len(num_target)==0:\n",
    "        return w_mat,w_mat, w_mat, w_mat,w_mat,w_mat,n_suprious\n",
    "    else:\n",
    "        #create the spurious variable\n",
    "        for i in range(len(num_target)):\n",
    "            suprious_list=np.nonzero(w_mat[num_target[i],:])[0]#12\n",
    "\n",
    "            for j in range(len(suprious_list)): \n",
    "                suprious=suprious_list[j]\n",
    "                #count the number of suprious variable\n",
    "                if suprious not in suprious_dict:\n",
    "                    suprious_dict[suprious]=1\n",
    "                    n_suprious+=1\n",
    "                    #remove other outgoing link\n",
    "                    w_mat[suprious,:]=0 #12,0\n",
    "                    w_test_mat[suprious,:]=0\n",
    "                    #print(suprious)\n",
    "                    #revert the link in the test\n",
    "                    if suprious!=d-1:\n",
    "                        w_test_mat[num_target[i],suprious]=-w_test_mat[num_target[i],suprious]\n",
    "                \n",
    "                \n",
    "    num_step = 5 #cannot work if num_step=1\n",
    "    #initial X0=X0W+B\n",
    "    Xbase = []\n",
    "    Xbase1 = ut.simulate_linear_sem(w_mat, n, sem_type, noise_scale=0.5)\n",
    "    #X1=X1W+AX0W+B\n",
    "    for i in range(num_step):\n",
    "        Xbase1 = ut.simulate_linear_sem_with_P(w_mat, w_mat, adj1@Xbase1, n, sem_type, noise_scale=1)\n",
    "        Xbase.append(Xbase1)\n",
    "        \n",
    "    #test data\n",
    "    Xbase_test = []\n",
    "    Xbase1_test = ut.simulate_linear_sem(w_test_mat, n, sem_type, noise_scale=0.5)\n",
    "    for i in range(num_step):\n",
    "        Xbase1_test = ut.simulate_linear_sem_with_P(w_test_mat, w_test_mat, adj1@Xbase1_test, n, sem_type, noise_scale=1)\n",
    "        Xbase_test.append(Xbase1_test)\n",
    "    \n",
    "    return Xbase,Xbase_test, adj1, w_true,w_mat,w_test_mat,n_suprious"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e865265d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_node_feature(Xlags,node_num):\n",
    "#     for num_lags in range(1):\n",
    "#         if num_lags==0:\n",
    "#             X_feature=Xlags[num_lags][node_num]\n",
    "#         else:\n",
    "#             X_feature=np.append(X_feature,Xlags[num_lags][node_num])##shape num_lags*5 (250)\n",
    "    X_feature=Xlags[-1][node_num]\n",
    "    return(X_feature)\n",
    "def to_binary(x):\n",
    "    if x>Xlags[-1][:,-1].mean():\n",
    "        return 1\n",
    "    else:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ab86e196",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_graph(valid_list,adj1,Xlags,n):\n",
    " ##node list for validation\n",
    "    labels=[]\n",
    "    G = nx.from_numpy_array(adj1)\n",
    "    for node_num in range(n):\n",
    "        G.nodes[node_num]['feature']=get_node_feature(Xlags,node_num)[:-1]\n",
    "\n",
    "        G.nodes[node_num]['label']=to_binary(get_node_feature(Xlags,node_num)[-1])\n",
    "\n",
    "        labels.append(G.nodes[node_num]['label'])\n",
    "        if node_num in valid_list:\n",
    "            G.nodes[node_num]['train_mask']=False\n",
    "            G.nodes[node_num]['valid_mask']=True\n",
    "        else:\n",
    "            G.nodes[node_num]['train_mask']=True\n",
    "            G.nodes[node_num]['valid_mask']=False\n",
    "    g = dgl.from_networkx(G, node_attrs=['feature','label','train_mask','valid_mask'])\n",
    "    return g"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1556b5a5",
   "metadata": {},
   "source": [
    "## GAT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2045ae0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GATLayer(nn.Module):\n",
    "    def __init__(self, g, in_dim, out_dim):\n",
    "        super(GATLayer, self).__init__()\n",
    "        self.g = g\n",
    "        # equation (1)\n",
    "        self.fc = nn.Linear(in_dim, out_dim, bias=False)\n",
    "        # equation (2)\n",
    "        self.attn_fc = nn.Linear(2 * out_dim, 1, bias=False)\n",
    "    \n",
    "    def edge_attention(self, edges):\n",
    "        # edge UDF for equation (2)\n",
    "        z2 = torch.cat([edges.src['z'], edges.dst['z']], dim=1)\n",
    "        a = self.attn_fc(z2)\n",
    "        return {'e' : F.leaky_relu(a)}\n",
    "    \n",
    "    def message_func(self, edges):\n",
    "        # message UDF for equation (3) & (4)\n",
    "        return {'z' : edges.src['z'], 'e' : edges.data['e']}\n",
    "    \n",
    "    def reduce_func(self, nodes):\n",
    "        # reduce UDF for equation (3) & (4)\n",
    "        # equation (3)\n",
    "        alpha = F.softmax(nodes.mailbox['e'], dim=1)\n",
    "        # equation (4)\n",
    "        h = torch.sum(alpha * nodes.mailbox['z'], dim=1)\n",
    "        return {'h' : h}\n",
    "    \n",
    "    def forward(self, h):\n",
    "        # equation (1)\n",
    "        z = self.fc(h)\n",
    "        self.g.ndata['z'] = z\n",
    "        # equation (2)\n",
    "        self.g.apply_edges(self.edge_attention)\n",
    "        # equation (3) & (4)\n",
    "        self.g.update_all(self.message_func, self.reduce_func)\n",
    "        return self.g.ndata.pop('h')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3024b7d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiHeadGATLayer(nn.Module):\n",
    "    def __init__(self, g, in_dim, out_dim, num_heads, merge='cat'):\n",
    "        super(MultiHeadGATLayer, self).__init__()\n",
    "        self.heads = nn.ModuleList()\n",
    "        for i in range(num_heads):\n",
    "            self.heads.append(GATLayer(g, in_dim, out_dim))\n",
    "        self.merge = merge\n",
    "    \n",
    "    def forward(self, h):\n",
    "        head_outs = [attn_head(h) for attn_head in self.heads]\n",
    "        if self.merge == 'cat':\n",
    "            # concat on the output feature dimension (dim=1)\n",
    "            return torch.cat(head_outs, dim=1)\n",
    "        else:\n",
    "            # merge using average\n",
    "            return torch.mean(torch.stack(head_outs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "035c37ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GAT(nn.Module):\n",
    "    def __init__(self, g, in_dim, hidden_dim, out_dim, num_heads):\n",
    "        super(GAT, self).__init__()\n",
    "        self.layer1 = MultiHeadGATLayer(g, in_dim, hidden_dim, num_heads)\n",
    "        # Be aware that the input dimension is hidden_dim*num_heads since\n",
    "        #   multiple head outputs are concatenated together. Also, only\n",
    "        #   one attention head in the output layer.\n",
    "        self.layer2 = MultiHeadGATLayer(g, hidden_dim * num_heads, out_dim, 1)\n",
    "    \n",
    "    def forward(self, h):\n",
    "        h = self.layer1(h)\n",
    "        h = F.elu(h)\n",
    "        h = self.layer2(h)\n",
    "        return h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cf70bd42",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, g, features, labels, mask):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        logits = model(features)\n",
    "        logits = logits[mask]\n",
    "        labels = labels[mask]\n",
    "        _, indices = torch.max(logits, dim=1)\n",
    "        correct = torch.sum(indices == labels)\n",
    "        return correct.item() * 1.0 / len(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4ca3d404",
   "metadata": {},
   "outputs": [],
   "source": [
    "class atten_Net(nn.Module):\n",
    "    def __init__(self,g, in_feats, hid_feats, out_feats,n_node,num_heads):\n",
    "        super(atten_Net, self).__init__()\n",
    "        self.layer1 = MultiHeadGATLayer(g, in_feats, hid_feats, num_heads)\n",
    "        self.layer2 = MultiHeadGATLayer(g, hid_feats * num_heads, out_feats, 1)\n",
    "        self.att_mlp_1 = nn.Linear(n_node, hid_feats)\n",
    "        self.att_mlp_2 = nn.Linear(hid_feats, 2)\n",
    "        self.layer3 = MultiHeadGATLayer(g, in_feats*2, hid_feats, num_heads)\n",
    "        self.layer4 = MultiHeadGATLayer(g, hid_feats * num_heads, out_feats, 1)\n",
    "\n",
    "    def forward(self, g, features,dag):\n",
    "        ##use mlp to get attention weights\n",
    "        node_att = F.relu(self.att_mlp_1(dag))\n",
    "        node_att = F.softmax(self.att_mlp_2(node_att), dim=-1)\n",
    "        node_weight_c = node_att[:, 0]\n",
    "        node_weight_o = node_att[:, 1]\n",
    "        ##attention on the causal/trival part\n",
    "        feature_c = node_weight_c.view(1, -1) * features\n",
    "        feature_o = node_weight_o.view(1, -1) * features\n",
    "        ## apply the mask on the features\n",
    "        xc = F.relu(self.layer1(feature_c))\n",
    "        xc = self.layer2(xc)\n",
    "        xc=F.log_softmax(xc, dim=-1)\n",
    "        \n",
    "        xo = F.relu(self.layer1(feature_o))\n",
    "        xo = self.layer2(xo)\n",
    "        xo=F.log_softmax(xo, dim=-1)\n",
    "        ##xco        \n",
    "        num = xc.shape[0]\n",
    "        l = [i for i in range(num)]\n",
    "        random.shuffle(l)\n",
    "        random_idx = torch.tensor(l)\n",
    "        xco = torch.cat((feature_c[random_idx], feature_o), dim=1)\n",
    "        xco = F.relu(self.layer3(xco))\n",
    "        xco = self.layer4(xco)\n",
    "        xco=F.log_softmax(xco, dim=-1)\n",
    "        \n",
    "        return xc,xo,xco"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7db3a7bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_new(model, g, features, labels, mask,dag):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        logits_c,logits_o,logits_co = model(g, features,dag)\n",
    "        logits = logits_o[mask]\n",
    "        labels = labels[mask]\n",
    "        _, indices = torch.max(logits, dim=1)\n",
    "        correct = torch.sum(indices == labels)\n",
    "        return correct.item() * 1.0 / len(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a08dbdd6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------the 0 iteration------------------\n",
      "finish data!\n",
      "finish fit graph!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\lib\\site-packages\\dgl\\backend\\pytorch\\tensor.py:40: UserWarning:\n",
      "\n",
      "Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at C:\\actions-runner\\_work\\pytorch\\pytorch\\builder\\windows\\pytorch\\torch\\csrc\\utils\\tensor_new.cpp:233.)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopped training at epoch 35\n",
      "GAT:train 0.6333333333333333 valid 0.6 test 0.6\n",
      "Early stopped training at epoch 34\n",
      "proposed:train 0.6333333333333333 valid 0.6 test 0.6 n_suprious 2.0\n",
      "-------------------the 1 iteration------------------\n",
      "finish data!\n",
      "finish fit graph!\n",
      "Early stopped training at epoch 119\n",
      "GAT:train 0.9 valid 0.6 test 0.4\n",
      "Early stopped training at epoch 123\n",
      "proposed:train 0.5666666666666667 valid 0.5 test 0.45 n_suprious 1.0\n",
      "-------------------the 2 iteration------------------\n",
      "-------------------the 2 iteration------------------\n",
      "finish data!\n",
      "finish fit graph!\n",
      "Early stopped training at epoch 105\n",
      "GAT:train 0.9333333333333333 valid 0.65 test 0.45\n",
      "Early stopped training at epoch 36\n",
      "proposed:train 0.7 valid 0.55 test 0.4 n_suprious 3.0\n",
      "-------------------the 3 iteration------------------\n",
      "finish data!\n",
      "finish fit graph!\n",
      "Early stopped training at epoch 74\n",
      "GAT:train 0.7666666666666667 valid 0.5 test 0.5\n",
      "Early stopped training at epoch 52\n",
      "proposed:train 0.6333333333333333 valid 0.5 test 0.5 n_suprious 1.0\n",
      "-------------------the 4 iteration------------------\n",
      "finish data!\n",
      "finish fit graph!\n",
      "Early stopped training at epoch 36\n",
      "GAT:train 0.7666666666666667 valid 0.3 test 0.85\n",
      "Early stopped training at epoch 32\n",
      "proposed:train 0.6 valid 0.25 test 0.85 n_suprious 2.0\n",
      "-------------------the 5 iteration------------------\n",
      "-------------------the 5 iteration------------------\n",
      "finish data!\n",
      "finish fit graph!\n",
      "Early stopped training at epoch 34\n",
      "GAT:train 0.5666666666666667 valid 0.4 test 0.55\n",
      "Early stopped training at epoch 44\n",
      "proposed:train 0.5666666666666667 valid 0.4 test 0.45 n_suprious 2.0\n",
      "-------------------the 6 iteration------------------\n",
      "finish data!\n",
      "finish fit graph!\n",
      "Early stopped training at epoch 59\n",
      "GAT:train 0.8333333333333334 valid 0.55 test 0.7\n",
      "Early stopped training at epoch 72\n",
      "proposed:train 0.9 valid 0.6 test 0.7 n_suprious 5.0\n",
      "-------------------the 7 iteration------------------\n",
      "-------------------the 7 iteration------------------\n",
      "-------------------the 7 iteration------------------\n",
      "finish data!\n",
      "finish fit graph!\n",
      "Early stopped training at epoch 31\n",
      "GAT:train 0.6333333333333333 valid 0.55 test 0.45\n",
      "Early stopped training at epoch 36\n",
      "proposed:train 0.6 valid 0.5 test 0.45 n_suprious 3.0\n",
      "-------------------the 8 iteration------------------\n",
      "finish data!\n",
      "finish fit graph!\n",
      "Early stopped training at epoch 102\n",
      "GAT:train 0.9 valid 0.6 test 0.45\n",
      "Early stopped training at epoch 130\n",
      "proposed:train 0.6 valid 0.6 test 0.35 n_suprious 1.0\n",
      "-------------------the 9 iteration------------------\n",
      "-------------------the 9 iteration------------------\n",
      "finish data!\n",
      "finish fit graph!\n",
      "Early stopped training at epoch 74\n",
      "GAT:train 0.9333333333333333 valid 0.55 test 0.7\n",
      "Early stopped training at epoch 32\n",
      "proposed:train 0.7666666666666667 valid 0.6 test 0.7 n_suprious 3.0\n",
      "          train_acc  valid_acc  test_acc  n_suprious\n",
      "model                                               \n",
      "GCN        0.786667       0.53     0.565         2.3\n",
      "proposed   0.656667       0.51     0.545         2.3\n",
      "-------------------the 10 iteration------------------\n",
      "-------------------the 10 iteration------------------\n",
      "finish data!\n",
      "finish fit graph!\n",
      "Early stopped training at epoch 35\n",
      "GAT:train 0.6 valid 0.5 test 0.55\n",
      "Early stopped training at epoch 31\n",
      "proposed:train 0.6 valid 0.45 test 0.6 n_suprious 3.0\n",
      "-------------------the 11 iteration------------------\n",
      "finish data!\n",
      "finish fit graph!\n",
      "Early stopped training at epoch 41\n",
      "GAT:train 0.6 valid 0.5 test 0.6\n",
      "Early stopped training at epoch 31\n",
      "proposed:train 0.7666666666666667 valid 0.45 test 0.55 n_suprious 2.0\n",
      "-------------------the 12 iteration------------------\n",
      "finish data!\n",
      "finish fit graph!\n",
      "Early stopped training at epoch 50\n",
      "GAT:train 0.8 valid 0.6 test 0.65\n",
      "Early stopped training at epoch 31\n",
      "proposed:train 0.7333333333333333 valid 0.55 test 0.55 n_suprious 3.0\n",
      "-------------------the 13 iteration------------------\n",
      "finish data!\n",
      "finish fit graph!\n",
      "Early stopped training at epoch 88\n",
      "GAT:train 0.9333333333333333 valid 0.6 test 0.45\n",
      "Early stopped training at epoch 79\n",
      "proposed:train 0.7666666666666667 valid 0.6 test 0.65 n_suprious 1.0\n",
      "-------------------the 14 iteration------------------\n",
      "finish data!\n",
      "finish fit graph!\n",
      "Early stopped training at epoch 32\n",
      "GAT:train 0.7 valid 0.45 test 0.3\n",
      "Early stopped training at epoch 31\n",
      "proposed:train 0.7 valid 0.45 test 0.25 n_suprious 1.0\n",
      "-------------------the 15 iteration------------------\n",
      "-------------------the 15 iteration------------------\n",
      "finish data!\n",
      "finish fit graph!\n",
      "Early stopped training at epoch 73\n",
      "GAT:train 0.9 valid 0.8 test 0.55\n",
      "Early stopped training at epoch 87\n",
      "proposed:train 0.9 valid 0.6 test 0.55 n_suprious 2.0\n",
      "-------------------the 16 iteration------------------\n",
      "-------------------the 16 iteration------------------\n",
      "finish data!\n",
      "finish fit graph!\n",
      "Early stopped training at epoch 110\n",
      "GAT:train 0.7666666666666667 valid 0.55 test 0.65\n",
      "Early stopped training at epoch 137\n",
      "proposed:train 0.9333333333333333 valid 0.7 test 0.55 n_suprious 3.0\n",
      "-------------------the 17 iteration------------------\n",
      "finish data!\n",
      "finish fit graph!\n",
      "Early stopped training at epoch 47\n",
      "GAT:train 0.8666666666666667 valid 0.45 test 0.85\n",
      "Early stopped training at epoch 31\n",
      "proposed:train 0.6 valid 0.35 test 0.85 n_suprious 5.0\n",
      "-------------------the 18 iteration------------------\n",
      "-------------------the 18 iteration------------------\n",
      "finish data!\n",
      "finish fit graph!\n",
      "Early stopped training at epoch 46\n",
      "GAT:train 0.8666666666666667 valid 0.55 test 0.5\n",
      "Early stopped training at epoch 31\n",
      "proposed:train 0.5333333333333333 valid 0.4 test 0.5 n_suprious 2.0\n",
      "-------------------the 19 iteration------------------\n",
      "-------------------the 19 iteration------------------\n",
      "finish data!\n",
      "finish fit graph!\n",
      "Early stopped training at epoch 32\n",
      "GAT:train 0.5666666666666667 valid 0.6 test 0.65\n",
      "Early stopped training at epoch 35\n",
      "proposed:train 0.5666666666666667 valid 0.35 test 0.65 n_suprious 1.0\n",
      "          train_acc  valid_acc  test_acc  n_suprious\n",
      "model                                               \n",
      "GCN        0.773333      0.545    0.5700         2.3\n",
      "proposed   0.683333      0.500    0.5575         2.3\n",
      "-------------------the 20 iteration------------------\n",
      "finish data!\n",
      "finish fit graph!\n",
      "Early stopped training at epoch 32\n",
      "GAT:train 0.6666666666666666 valid 0.4 test 0.35\n",
      "Early stopped training at epoch 35\n",
      "proposed:train 0.7 valid 0.45 test 0.35 n_suprious 2.0\n",
      "-------------------the 21 iteration------------------\n",
      "-------------------the 21 iteration------------------\n",
      "finish data!\n",
      "finish fit graph!\n",
      "Early stopped training at epoch 31\n",
      "GAT:train 0.6333333333333333 valid 0.3 test 0.2\n",
      "Early stopped training at epoch 31\n",
      "proposed:train 0.6333333333333333 valid 0.3 test 0.45 n_suprious 2.0\n",
      "-------------------the 22 iteration------------------\n",
      "-------------------the 22 iteration------------------\n",
      "finish data!\n",
      "finish fit graph!\n",
      "Early stopped training at epoch 39\n",
      "GAT:train 0.7333333333333333 valid 0.65 test 0.8\n",
      "Early stopped training at epoch 76\n",
      "proposed:train 0.9 valid 0.6 test 0.8 n_suprious 3.0\n",
      "-------------------the 23 iteration------------------\n",
      "finish data!\n",
      "finish fit graph!\n",
      "Early stopped training at epoch 75\n",
      "GAT:train 0.9 valid 0.55 test 0.55\n",
      "Early stopped training at epoch 102\n",
      "proposed:train 0.8666666666666667 valid 0.4 test 0.55 n_suprious 3.0\n",
      "-------------------the 24 iteration------------------\n",
      "-------------------the 24 iteration------------------\n",
      "finish data!\n",
      "finish fit graph!\n",
      "Early stopped training at epoch 34\n",
      "GAT:train 0.6333333333333333 valid 0.5 test 0.5\n",
      "Early stopped training at epoch 31\n",
      "proposed:train 0.6333333333333333 valid 0.5 test 0.45 n_suprious 4.0\n",
      "-------------------the 25 iteration------------------\n",
      "finish data!\n",
      "finish fit graph!\n",
      "Early stopped training at epoch 74\n",
      "GAT:train 0.9333333333333333 valid 0.75 test 0.7\n",
      "Early stopped training at epoch 120\n",
      "proposed:train 0.9666666666666667 valid 0.85 test 0.65 n_suprious 3.0\n",
      "-------------------the 26 iteration------------------\n",
      "finish data!\n",
      "finish fit graph!\n",
      "Early stopped training at epoch 31\n",
      "GAT:train 0.8 valid 0.5 test 0.5\n",
      "Early stopped training at epoch 31\n",
      "proposed:train 0.7666666666666667 valid 0.55 test 0.6 n_suprious 2.0\n",
      "-------------------the 27 iteration------------------\n",
      "-------------------the 27 iteration------------------\n",
      "finish data!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finish fit graph!\n",
      "Early stopped training at epoch 76\n",
      "GAT:train 0.8 valid 0.55 test 0.7\n",
      "Early stopped training at epoch 63\n",
      "proposed:train 0.9 valid 0.5 test 0.85 n_suprious 1.0\n",
      "-------------------the 28 iteration------------------\n",
      "-------------------the 28 iteration------------------\n",
      "finish data!\n",
      "finish fit graph!\n",
      "Early stopped training at epoch 31\n",
      "GAT:train 0.6 valid 0.35 test 0.55\n",
      "Early stopped training at epoch 39\n",
      "proposed:train 0.6 valid 0.45 test 0.6 n_suprious 1.0\n",
      "-------------------the 29 iteration------------------\n",
      "-------------------the 29 iteration------------------\n",
      "finish data!\n",
      "finish fit graph!\n",
      "Early stopped training at epoch 187\n",
      "GAT:train 0.9666666666666667 valid 0.85 test 0.5\n",
      "Early stopped training at epoch 90\n",
      "proposed:train 0.9 valid 0.75 test 0.5 n_suprious 2.0\n",
      "          train_acc  valid_acc  test_acc  n_suprious\n",
      "model                                               \n",
      "GCN        0.771111   0.543333  0.558333         2.3\n",
      "proposed   0.717778   0.511667  0.565000         2.3\n",
      "-------------------the 30 iteration------------------\n",
      "finish data!\n",
      "finish fit graph!\n",
      "Early stopped training at epoch 33\n",
      "GAT:train 0.6333333333333333 valid 0.6 test 0.65\n",
      "Early stopped training at epoch 69\n",
      "proposed:train 0.8333333333333334 valid 0.6 test 0.55 n_suprious 1.0\n",
      "-------------------the 31 iteration------------------\n",
      "finish data!\n",
      "finish fit graph!\n",
      "Early stopped training at epoch 40\n",
      "GAT:train 0.6333333333333333 valid 0.5 test 0.7\n",
      "Early stopped training at epoch 32\n",
      "proposed:train 0.6333333333333333 valid 0.55 test 0.7 n_suprious 2.0\n",
      "-------------------the 32 iteration------------------\n",
      "-------------------the 32 iteration------------------\n",
      "finish data!\n",
      "finish fit graph!\n",
      "Early stopped training at epoch 71\n",
      "GAT:train 0.8333333333333334 valid 0.65 test 0.55\n",
      "Early stopped training at epoch 49\n",
      "proposed:train 0.7 valid 0.6 test 0.6 n_suprious 3.0\n",
      "-------------------the 33 iteration------------------\n",
      "finish data!\n",
      "finish fit graph!\n",
      "Early stopped training at epoch 116\n",
      "GAT:train 0.8333333333333334 valid 0.65 test 0.5\n",
      "Early stopped training at epoch 90\n",
      "proposed:train 0.8666666666666667 valid 0.45 test 0.45 n_suprious 2.0\n",
      "-------------------the 34 iteration------------------\n",
      "-------------------the 34 iteration------------------\n",
      "-------------------the 34 iteration------------------\n",
      "finish data!\n",
      "finish fit graph!\n",
      "Early stopped training at epoch 61\n",
      "GAT:train 0.8333333333333334 valid 0.6 test 0.5\n",
      "Early stopped training at epoch 81\n",
      "proposed:train 0.7 valid 0.65 test 0.5 n_suprious 3.0\n",
      "-------------------the 35 iteration------------------\n",
      "-------------------the 35 iteration------------------\n",
      "finish data!\n",
      "finish fit graph!\n",
      "Early stopped training at epoch 34\n",
      "GAT:train 0.5666666666666667 valid 0.55 test 0.4\n",
      "Early stopped training at epoch 93\n",
      "proposed:train 0.7666666666666667 valid 0.5 test 0.3 n_suprious 2.0\n",
      "-------------------the 36 iteration------------------\n",
      "finish data!\n",
      "finish fit graph!\n",
      "Early stopped training at epoch 49\n",
      "GAT:train 0.6666666666666666 valid 0.55 test 0.25\n",
      "Early stopped training at epoch 33\n",
      "proposed:train 0.6333333333333333 valid 0.5 test 0.25 n_suprious 2.0\n",
      "-------------------the 37 iteration------------------\n",
      "finish data!\n",
      "finish fit graph!\n",
      "Early stopped training at epoch 64\n",
      "GAT:train 0.8333333333333334 valid 0.65 test 0.35\n",
      "Early stopped training at epoch 79\n",
      "proposed:train 0.8666666666666667 valid 0.7 test 0.35 n_suprious 2.0\n",
      "-------------------the 38 iteration------------------\n",
      "finish data!\n",
      "finish fit graph!\n",
      "Early stopped training at epoch 33\n",
      "GAT:train 0.5666666666666667 valid 0.6 test 0.4\n",
      "Early stopped training at epoch 32\n",
      "proposed:train 0.5333333333333333 valid 0.6 test 0.6 n_suprious 1.0\n",
      "-------------------the 39 iteration------------------\n",
      "-------------------the 39 iteration------------------\n",
      "finish data!\n",
      "finish fit graph!\n",
      "Early stopped training at epoch 31\n",
      "GAT:train 0.6 valid 0.75 test 0.65\n",
      "Early stopped training at epoch 39\n",
      "proposed:train 0.6 valid 0.75 test 0.65 n_suprious 1.0\n",
      "          train_acc  valid_acc  test_acc  n_suprious\n",
      "model                                               \n",
      "GCN        0.753333    0.56000    0.5425         2.2\n",
      "proposed   0.716667    0.53125    0.5475         2.2\n",
      "-------------------the 40 iteration------------------\n",
      "-------------------the 40 iteration------------------\n",
      "finish data!\n",
      "finish fit graph!\n",
      "Early stopped training at epoch 42\n",
      "GAT:train 0.8666666666666667 valid 0.7 test 0.65\n",
      "Early stopped training at epoch 101\n",
      "proposed:train 0.9666666666666667 valid 0.55 test 0.55 n_suprious 3.0\n",
      "-------------------the 41 iteration------------------\n",
      "-------------------the 41 iteration------------------\n",
      "-------------------the 41 iteration------------------\n",
      "-------------------the 41 iteration------------------\n",
      "finish data!\n",
      "finish fit graph!\n",
      "Early stopped training at epoch 31\n",
      "GAT:train 0.7333333333333333 valid 0.4 test 0.55\n",
      "Early stopped training at epoch 31\n",
      "proposed:train 0.7 valid 0.4 test 0.7 n_suprious 1.0\n",
      "-------------------the 42 iteration------------------\n",
      "-------------------the 42 iteration------------------\n",
      "-------------------the 42 iteration------------------\n",
      "finish data!\n",
      "finish fit graph!\n",
      "Early stopped training at epoch 33\n",
      "GAT:train 0.6 valid 0.5 test 0.6\n",
      "Early stopped training at epoch 32\n",
      "proposed:train 0.6 valid 0.45 test 0.6 n_suprious 3.0\n",
      "-------------------the 43 iteration------------------\n",
      "finish data!\n",
      "finish fit graph!\n",
      "Early stopped training at epoch 32\n",
      "GAT:train 0.7666666666666667 valid 0.4 test 0.4\n",
      "Early stopped training at epoch 45\n",
      "proposed:train 0.6333333333333333 valid 0.45 test 0.45 n_suprious 2.0\n",
      "-------------------the 44 iteration------------------\n",
      "finish data!\n",
      "finish fit graph!\n",
      "Early stopped training at epoch 110\n",
      "GAT:train 0.9666666666666667 valid 0.7 test 0.4\n",
      "Early stopped training at epoch 136\n",
      "proposed:train 1.0 valid 0.75 test 0.4 n_suprious 1.0\n",
      "-------------------the 45 iteration------------------\n",
      "-------------------the 45 iteration------------------\n",
      "finish data!\n",
      "finish fit graph!\n",
      "Early stopped training at epoch 31\n",
      "GAT:train 0.6666666666666666 valid 0.3 test 0.5\n",
      "Early stopped training at epoch 44\n",
      "proposed:train 0.5333333333333333 valid 0.35 test 0.55 n_suprious 3.0\n",
      "-------------------the 46 iteration------------------\n",
      "finish data!\n",
      "finish fit graph!\n",
      "Early stopped training at epoch 60\n",
      "GAT:train 0.5666666666666667 valid 0.5 test 0.6\n",
      "Early stopped training at epoch 55\n",
      "proposed:train 0.8 valid 0.55 test 0.6 n_suprious 1.0\n",
      "-------------------the 47 iteration------------------\n",
      "finish data!\n",
      "finish fit graph!\n",
      "Early stopped training at epoch 31\n",
      "GAT:train 0.7666666666666667 valid 0.4 test 0.5\n",
      "Early stopped training at epoch 33\n",
      "proposed:train 0.6333333333333333 valid 0.45 test 0.5 n_suprious 2.0\n",
      "-------------------the 48 iteration------------------\n",
      "-------------------the 48 iteration------------------\n",
      "-------------------the 48 iteration------------------\n",
      "-------------------the 48 iteration------------------\n",
      "finish data!\n",
      "finish fit graph!\n",
      "Early stopped training at epoch 32\n",
      "GAT:train 0.5666666666666667 valid 0.35 test 0.35\n",
      "Early stopped training at epoch 31\n",
      "proposed:train 0.5666666666666667 valid 0.4 test 0.6 n_suprious 2.0\n",
      "-------------------the 49 iteration------------------\n",
      "-------------------the 49 iteration------------------\n",
      "finish data!\n",
      "finish fit graph!\n",
      "Early stopped training at epoch 31\n",
      "GAT:train 0.7666666666666667 valid 0.35 test 0.35\n",
      "Early stopped training at epoch 31\n",
      "proposed:train 0.6333333333333333 valid 0.4 test 0.65 n_suprious 3.0\n",
      "          train_acc  valid_acc  test_acc  n_suprious\n",
      "model                                               \n",
      "GCN        0.748000       0.54     0.532        2.18\n",
      "proposed   0.714667       0.52     0.550        2.18\n"
     ]
    }
   ],
   "source": [
    "torch.set_default_dtype(torch.double)\n",
    "np.set_printoptions(precision=3)\n",
    "\n",
    "torch.manual_seed(12345)\n",
    "ut.set_random_seed(12345)\n",
    "\n",
    "n = 50 #number of people\n",
    "\n",
    "d = 15 #number of features\n",
    "\n",
    "w_graph_type = 'ER'\n",
    "p_graph_type = 'ER' \n",
    "sem_type = 'exp'\n",
    "s0 =  d\n",
    "#params\n",
    "lr=0.005\n",
    "alpha=0.2\n",
    "beta=1\n",
    "gamma=0.2\n",
    "early_stop_thresh=30\n",
    "n_epoch=300\n",
    "output=pd.DataFrame(columns=[\"train_acc\",\"valid_acc\",\"test_acc\",\"model\",\"n_suprious\"])\n",
    "ith=0\n",
    "replicates=50\n",
    "while ith<2*replicates:\n",
    "    print(\"-------------------the\",ith//2,\"iteration------------------\")\n",
    "    #create data\n",
    "    Xlags,Xlags_test, adj1, w_true,w_mat,w_test_mat,n_suprious = data_pre(n, d, s0, w_graph_type,p_graph_type, sem_type)\n",
    "    if n_suprious<=0:\n",
    "        continue\n",
    "    Xlags_torch = torch.Tensor(np.array(Xlags))\n",
    "    print(\"finish data!\")\n",
    "    #fit the causal graph\n",
    "    adj1_torch = torch.Tensor(adj1)\n",
    "    model_1 = GraphNOTEARS.model_p1_MLP(dims=[d, n, 1], bias=True)\n",
    "    W_est_1, P1_est_1 = GraphNOTEARS.linear_model(model_1, Xlags_torch, adj1_torch,  lambda1 = 0.01, lambda2 = 0.01, lambda3 = 0.01)\n",
    "    print(\"finish fit graph!\")\n",
    "    #g,g_test\n",
    "    valid_list=random.sample(range(n), int(n*0.4))\n",
    "    g = create_graph(valid_list,adj1,Xlags,n)\n",
    "    g_test=create_graph(valid_list,adj1,Xlags_test,n)\n",
    "    #GAT\n",
    "    net = GAT(g, \n",
    "          in_dim=d-1, \n",
    "          hidden_dim=4, \n",
    "          out_dim=2, \n",
    "          num_heads=2)\n",
    "\n",
    "    features = g.ndata['feature']\n",
    "    labels = g.ndata['label']\n",
    "    train_mask = g.ndata['train_mask']\n",
    "    valid_mask = g.ndata['valid_mask']\n",
    "    ###test\n",
    "    features_test = g_test.ndata['feature']\n",
    "    labels_test = g_test.ndata['label']\n",
    "    #parameters\n",
    "    optimizer = torch.optim.Adam(net.parameters(), lr=lr)\n",
    "\n",
    "    best_loss = 99998\n",
    "    best_epoch = -1\n",
    "    for epoch in range(n_epoch):\n",
    "        net.train()\n",
    "        logits = net(features)\n",
    "        \n",
    "        logp = F.log_softmax(logits, dim=-1)\n",
    "        loss = F.nll_loss(logp[train_mask], labels[train_mask])\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        ##evaluate\n",
    "        net.eval()\n",
    "        train_acc = evaluate(net, g, features, labels, train_mask)\n",
    "        valid_acc = evaluate(net, g, features, labels, valid_mask)\n",
    "        test_acc = evaluate(net, g_test, features_test, labels_test, valid_mask)\n",
    "        valid_loss = F.nll_loss(logp[valid_mask], labels[valid_mask])\n",
    "        #early stop\n",
    "        if valid_loss < best_loss:\n",
    "            best_loss = valid_loss\n",
    "            best_epoch = epoch\n",
    "            #torch.save(net.state_dict(), \"GCN_demo_large.pth\")\n",
    "        elif epoch - best_epoch > early_stop_thresh:\n",
    "            print(\"Early stopped training at epoch %d\" % epoch)\n",
    "            break  # terminate the training loop\n",
    "    print(\"GAT:train\",train_acc,\"valid\",valid_acc,\"test\",test_acc)\n",
    "    output.loc[ith]=[train_acc,valid_acc,test_acc,\"GCN\",n_suprious]\n",
    "    ith+=1\n",
    "    ##proposed\n",
    "    model = atten_Net(g,num_heads=2,in_feats=d-1, hid_feats=4, out_feats=2,n_node=d)\n",
    "\n",
    "    #params\n",
    "    best_loss = 99998\n",
    "    best_epoch = -1\n",
    "\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "    #scheduler = torch.optim.lr_scheduler.ExponentialLR(optimizer, gamma=0.9)\n",
    "    for epoch in range(n_epoch):\n",
    "        model.train()\n",
    "        xc_logits,xo_logits,xco_logits = model(g, features,torch.tensor(W_est_1[:-1,:]))\n",
    "        ##trivial part\n",
    "        uniform_target = torch.ones_like(xc_logits[train_mask], dtype=torch.float)/2\n",
    "        c_loss = F.kl_div(xc_logits[train_mask], uniform_target, reduction='batchmean')\n",
    "\n",
    "        o_loss = F.nll_loss(xo_logits[train_mask], labels[train_mask])\n",
    "        co_loss= F.nll_loss(xco_logits[train_mask], labels[train_mask])\n",
    "        loss = alpha * c_loss + beta * o_loss +gamma*co_loss\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        #scheduler.step()\n",
    "        ##evaluate\n",
    "        model.eval()\n",
    "        train_acc = evaluate_new(model, g, features, labels, train_mask,torch.tensor(W_est_1[:-1,:]))\n",
    "        valid_acc = evaluate_new(model, g, features, labels, valid_mask,torch.tensor(W_est_1[:-1,:]))\n",
    "        test_acc = evaluate_new(model, g_test, features_test, labels_test, valid_mask,torch.tensor(W_est_1[:-1,:]))\n",
    "        #valid loss\n",
    "        uniform_target = torch.ones_like(xc_logits[valid_mask], dtype=torch.float)/2\n",
    "        valid_c_loss = F.kl_div(xc_logits[valid_mask], uniform_target, reduction='batchmean')\n",
    "        valid_o_loss = F.nll_loss(xo_logits[valid_mask], labels[valid_mask])\n",
    "        valid_co_loss = F.nll_loss(xco_logits[valid_mask], labels[valid_mask])\n",
    "        valid_loss = alpha * valid_c_loss+beta *valid_o_loss+gamma*valid_co_loss\n",
    "        #test loss\n",
    "        test_xc_logits,test_xo_logits,test_xco_logits = model(g_test, features_test,torch.tensor(W_est_1[:-1,:]))\n",
    "        uniform_target = torch.ones_like(test_xo_logits[valid_mask], dtype=torch.float)/2\n",
    "        test_c_loss = F.kl_div(test_xc_logits[valid_mask], uniform_target, reduction='batchmean')\n",
    "        test_o_loss = F.nll_loss(test_xo_logits[valid_mask], labels_test[valid_mask])\n",
    "        test_co_loss = F.nll_loss(test_xco_logits[valid_mask], labels_test[valid_mask])\n",
    "        test_loss = alpha * test_c_loss + beta * test_o_loss+gamma*test_co_loss\n",
    "    #early stop     \n",
    "        if valid_loss < best_loss:\n",
    "            best_loss = valid_loss\n",
    "            best_epoch = epoch\n",
    "            #torch.save(model.state_dict(), \"attention_demo_large.pth\")\n",
    "        elif epoch - best_epoch > early_stop_thresh:\n",
    "            print(\"Early stopped training at epoch %d\" % epoch)\n",
    "            break  # terminate the training loop\n",
    "    print(\"proposed:train\",train_acc,\"valid\",valid_acc,\"test\",test_acc,\"n_suprious\",n_suprious)\n",
    "    output.loc[ith]=[train_acc,valid_acc,test_acc,\"proposed\",n_suprious]\n",
    "    ith+=1\n",
    "    if ith %20==0:\n",
    "        print(output.groupby(\"model\").mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "dbc1fcb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "output.to_csv(\"gat,d=15,lr=0.005,alpha=0.2,beta=1,gamma=0.2,early_stop_thresh=30,n_epoch=300.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "0739a2b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr=0.005\n",
    "alpha=0.2\n",
    "beta=1\n",
    "gamma=0.2\n",
    "early_stop_thresh=30\n",
    "n_epoch=300"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "9f6c68a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopped training at epoch 39\n",
      "GAT:train 0.5666666666666667 valid 0.5 test 0.35\n"
     ]
    }
   ],
   "source": [
    "#GAT\n",
    "net = GAT(g, \n",
    "      in_dim=d-1, \n",
    "      hidden_dim=4, \n",
    "      out_dim=2, \n",
    "      num_heads=2)\n",
    "\n",
    "features = g.ndata['feature']\n",
    "labels = g.ndata['label']\n",
    "train_mask = g.ndata['train_mask']\n",
    "valid_mask = g.ndata['valid_mask']\n",
    "###test\n",
    "features_test = g_test.ndata['feature']\n",
    "labels_test = g_test.ndata['label']\n",
    "train_acc_list=[]\n",
    "valid_acc_list=[]\n",
    "test_acc_list=[]\n",
    "#parameters\n",
    "optimizer = torch.optim.Adam(net.parameters(), lr=lr)\n",
    "\n",
    "best_loss = 99998\n",
    "best_epoch = -1\n",
    "for epoch in range(n_epoch):\n",
    "    net.train()\n",
    "    logits = net(features)\n",
    "\n",
    "    logp = F.log_softmax(logits, dim=-1)\n",
    "    loss = F.nll_loss(logp[train_mask], labels[train_mask])\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    ##evaluate\n",
    "    net.eval()\n",
    "    train_acc = evaluate(net, g, features, labels, train_mask)\n",
    "    valid_acc = evaluate(net, g, features, labels, valid_mask)\n",
    "    test_acc = evaluate(net, g_test, features_test, labels_test, valid_mask)\n",
    "    valid_loss = F.nll_loss(logp[valid_mask], labels[valid_mask])\n",
    "    train_acc_list.append(train_acc)\n",
    "    valid_acc_list.append(valid_acc)\n",
    "    test_acc_list.append(test_acc)\n",
    "    #early stop\n",
    "    if valid_loss < best_loss:\n",
    "        best_loss = valid_loss\n",
    "        best_epoch = epoch\n",
    "        #torch.save(net.state_dict(), \"GCN_demo_large.pth\")\n",
    "    elif epoch - best_epoch > early_stop_thresh:\n",
    "        print(\"Early stopped training at epoch %d\" % epoch)\n",
    "        break  # terminate the training loop\n",
    "\n",
    "print(\"GAT:train\",train_acc,\"valid\",valid_acc,\"test\",test_acc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "1e6cafa2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopped training at epoch 32\n",
      "proposed:train 0.6 valid 0.5 test 0.7 n_suprious 1.0\n"
     ]
    }
   ],
   "source": [
    "model = atten_Net(g,num_heads=2,in_feats=d-1, hid_feats=4, out_feats=2,n_node=d)\n",
    "\n",
    "#params\n",
    "best_loss = 99998\n",
    "best_epoch = -1\n",
    "train_acc_list=[]\n",
    "valid_acc_list=[]\n",
    "test_acc_list=[]\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "#scheduler = torch.optim.lr_scheduler.ExponentialLR(optimizer, gamma=0.9)\n",
    "for epoch in range(n_epoch):\n",
    "    model.train()\n",
    "    xc_logits,xo_logits,xco_logits = model(g, features,torch.tensor(W_est_1[:-1,:]))\n",
    "    ##trivial part\n",
    "    uniform_target = torch.ones_like(xc_logits[train_mask], dtype=torch.float)/2\n",
    "    c_loss = F.kl_div(xc_logits[train_mask], uniform_target, reduction='batchmean')\n",
    "\n",
    "    o_loss = F.nll_loss(xo_logits[train_mask], labels[train_mask])\n",
    "    co_loss= F.nll_loss(xco_logits[train_mask], labels[train_mask])\n",
    "    loss = alpha * c_loss + beta * o_loss +gamma*co_loss\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    #scheduler.step()\n",
    "    ##evaluate\n",
    "    model.eval()\n",
    "    train_acc = evaluate_new(model, g, features, labels, train_mask,torch.tensor(W_est_1[:-1,:]))\n",
    "    valid_acc = evaluate_new(model, g, features, labels, valid_mask,torch.tensor(W_est_1[:-1,:]))\n",
    "    test_acc = evaluate_new(model, g_test, features_test, labels_test, valid_mask,torch.tensor(W_est_1[:-1,:]))\n",
    "    #valid loss\n",
    "    uniform_target = torch.ones_like(xc_logits[valid_mask], dtype=torch.float)/2\n",
    "    valid_c_loss = F.kl_div(xc_logits[valid_mask], uniform_target, reduction='batchmean')\n",
    "    valid_o_loss = F.nll_loss(xo_logits[valid_mask], labels[valid_mask])\n",
    "    valid_co_loss = F.nll_loss(xco_logits[valid_mask], labels[valid_mask])\n",
    "    valid_loss = alpha * valid_c_loss+beta *valid_o_loss+gamma*valid_co_loss\n",
    "    #test loss\n",
    "    test_xc_logits,test_xo_logits,test_xco_logits = model(g_test, features_test,torch.tensor(W_est_1[:-1,:]))\n",
    "    uniform_target = torch.ones_like(test_xo_logits[valid_mask], dtype=torch.float)/2\n",
    "    test_c_loss = F.kl_div(test_xc_logits[valid_mask], uniform_target, reduction='batchmean')\n",
    "    test_o_loss = F.nll_loss(test_xo_logits[valid_mask], labels_test[valid_mask])\n",
    "    test_co_loss = F.nll_loss(test_xco_logits[valid_mask], labels_test[valid_mask])\n",
    "    test_loss = alpha * test_c_loss + beta * test_o_loss+gamma*test_co_loss\n",
    "    train_acc_list.append(train_acc)\n",
    "    valid_acc_list.append(valid_acc)\n",
    "    test_acc_list.append(test_acc)\n",
    "    #early stop     \n",
    "    if valid_loss < best_loss:\n",
    "        best_loss = valid_loss\n",
    "        best_epoch = epoch\n",
    "        #torch.save(model.state_dict(), \"attention_demo_large.pth\")\n",
    "    elif epoch - best_epoch > early_stop_thresh:\n",
    "        print(\"Early stopped training at epoch %d\" % epoch)\n",
    "        break  # terminate the training loop\n",
    "print(\"proposed:train\",train_acc,\"valid\",valid_acc,\"test\",test_acc,\"n_suprious\",n_suprious)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "ccead608",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "#history = model1.fit(train_x, train_y,validation_split = 0.1, epochs=50, batch_size=4)\n",
    "plt.plot(train_acc_list)\n",
    "plt.plot(valid_acc_list)\n",
    "plt.plot(test_acc_list)\n",
    "#plt.plot(loss_list)\n",
    "#plt.plot(loss_list)\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'val','test','loss'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e42908e6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>train_acc</th>\n",
       "      <th>valid_acc</th>\n",
       "      <th>test_acc</th>\n",
       "      <th>n_suprious</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>model</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>GCN</th>\n",
       "      <td>0.688000</td>\n",
       "      <td>0.567</td>\n",
       "      <td>0.528</td>\n",
       "      <td>1.98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>proposed</th>\n",
       "      <td>0.693333</td>\n",
       "      <td>0.551</td>\n",
       "      <td>0.549</td>\n",
       "      <td>1.98</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          train_acc  valid_acc  test_acc  n_suprious\n",
       "model                                               \n",
       "GCN        0.688000      0.567     0.528        1.98\n",
       "proposed   0.693333      0.551     0.549        1.98"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output.groupby(\"model\").mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "16efb753",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>train_acc</th>\n",
       "      <th>valid_acc</th>\n",
       "      <th>test_acc</th>\n",
       "      <th>n_suprious</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>model</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>GCN</th>\n",
       "      <td>0.134647</td>\n",
       "      <td>0.129209</td>\n",
       "      <td>0.137826</td>\n",
       "      <td>0.891914</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>proposed</th>\n",
       "      <td>0.115666</td>\n",
       "      <td>0.125962</td>\n",
       "      <td>0.139785</td>\n",
       "      <td>0.891914</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          train_acc  valid_acc  test_acc  n_suprious\n",
       "model                                               \n",
       "GCN        0.134647   0.129209  0.137826    0.891914\n",
       "proposed   0.115666   0.125962  0.139785    0.891914"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output.groupby(\"model\").std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fbbbd817",
   "metadata": {},
   "outputs": [],
   "source": [
    "diff_list=[]\n",
    "for i in range(50):\n",
    "    GCN=output.loc[i*2][\"test_acc\"]\n",
    "    proposed=output.loc[i*2+1][\"test_acc\"]\n",
    "    diff=proposed-GCN\n",
    "    diff_list.append(diff)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "f930a3a9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.01949153984476342"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "0.137826/np.sqrt(50)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
