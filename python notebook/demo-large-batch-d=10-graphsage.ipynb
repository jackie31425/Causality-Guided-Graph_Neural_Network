{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2761e554",
   "metadata": {},
   "source": [
    "## data generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cacb334b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\lib\\site-packages\\numpy\\_distributor_init.py:32: UserWarning: loaded more than 1 DLL from .libs:\n",
      "D:\\Anaconda\\lib\\site-packages\\numpy\\.libs\\libopenblas.TXA6YQSD3GCQQC22GEQ54J2UDCXDXHWN.gfortran-win_amd64.dll\n",
      "D:\\Anaconda\\lib\\site-packages\\numpy\\.libs\\libopenblas.WCDJNK7YVMPZQ2ME2ZZHJJRJ3JIKNDB7.gfortran-win_amd64.dll\n",
      "  stacklevel=1)\n",
      "\n",
      "Bad key \"text.kerning_factor\" on line 4 in\n",
      "D:\\Anaconda\\lib\\site-packages\\matplotlib\\mpl-data\\stylelib\\_classic_test_patch.mplstyle.\n",
      "You probably need to get an updated matplotlibrc file from\n",
      "https://github.com/matplotlib/matplotlib/blob/v3.1.3/matplotlibrc.template\n",
      "or from the matplotlib source distribution\n",
      "Using backend: pytorch\n"
     ]
    }
   ],
   "source": [
    "from locally_connected import LocallyConnected\n",
    "from lbfgsb_scipy import LBFGSBScipy\n",
    "from trace_expm import trace_expm\n",
    "from sklearn.metrics import f1_score\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import scipy.sparse\n",
    "import GraphNOTEARS\n",
    "import notears_torch_version\n",
    "import lasso\n",
    "import dynotears\n",
    "import utils as ut\n",
    "import matplotlib.pyplot as plt\n",
    "import networkx as nx\n",
    "import dgl\n",
    "import random\n",
    "import utils as ut\n",
    "import dgl.function as fn\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from dgl import DGLGraph\n",
    "import pandas as pd\n",
    "#device = torch.device(\"cuda:0\")\n",
    "device = torch.device(\"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e45970cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_pre(n, d, s0, w_graph_type, p_graph_type, sem_type):\n",
    "    #binary W\n",
    "    w_true = ut.simulate_dag(d, s0, w_graph_type)\n",
    "    #weighted W\n",
    "    w_mat = ut.simulate_parameter(w_true)\n",
    "    w_test_mat=w_mat.copy()\n",
    "    #A\n",
    "    adj1 = ut.generate_adj(n) \n",
    "    #node to target\n",
    "    num_target=np.nonzero(w_mat[:,-1])[0]#4,14\n",
    "    n_suprious=-1.0\n",
    "    suprious_dict={}\n",
    "    #if no suprious variable existed\n",
    "    if len(num_target)==0:\n",
    "        return w_mat,w_mat, w_mat, w_mat,w_mat,w_mat,n_suprious\n",
    "    else:\n",
    "        #create the spurious variable\n",
    "        for i in range(len(num_target)):\n",
    "            suprious_list=np.nonzero(w_mat[num_target[i],:])[0]#12\n",
    "\n",
    "            for j in range(len(suprious_list)): \n",
    "                suprious=suprious_list[j]\n",
    "                #count the number of suprious variable\n",
    "                if suprious not in suprious_dict:\n",
    "                    suprious_dict[suprious]=1\n",
    "                    n_suprious+=1\n",
    "                    #remove other outgoing link\n",
    "                    w_mat[suprious,:]=0 #12,0\n",
    "                    w_test_mat[suprious,:]=0\n",
    "                    #print(suprious)\n",
    "                    #revert the link in the test\n",
    "                    if suprious!=d-1:\n",
    "                        w_test_mat[num_target[i],suprious]=-w_test_mat[num_target[i],suprious]\n",
    "                \n",
    "                \n",
    "    num_step = 5 #cannot work if num_step=1\n",
    "    #initial X0=X0W+B\n",
    "    Xbase = []\n",
    "    Xbase1 = ut.simulate_linear_sem(w_mat, n, sem_type, noise_scale=0.5)\n",
    "    #X1=X1W+AX0W+B\n",
    "    for i in range(num_step):\n",
    "        Xbase1 = ut.simulate_linear_sem_with_P(w_mat, w_mat, adj1@Xbase1, n, sem_type, noise_scale=1)\n",
    "        Xbase.append(Xbase1)\n",
    "        \n",
    "    #test data\n",
    "    Xbase_test = []\n",
    "    Xbase1_test = ut.simulate_linear_sem(w_test_mat, n, sem_type, noise_scale=0.5)\n",
    "    for i in range(num_step):\n",
    "        Xbase1_test = ut.simulate_linear_sem_with_P(w_test_mat, w_test_mat, adj1@Xbase1_test, n, sem_type, noise_scale=1)\n",
    "        Xbase_test.append(Xbase1_test)\n",
    "    \n",
    "    return Xbase,Xbase_test, adj1, w_true,w_mat,w_test_mat,n_suprious"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "610eebc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.set_default_dtype(torch.double)\n",
    "np.set_printoptions(precision=3)\n",
    "\n",
    "torch.manual_seed(12345)\n",
    "ut.set_random_seed(12345)\n",
    "\n",
    "n = 50 #number of people\n",
    "\n",
    "d = 5 #number of features\n",
    "\n",
    "w_graph_type = 'ER'\n",
    "p_graph_type = 'ER' \n",
    "sem_type = 'exp'\n",
    "s0 =  d\n",
    "output=pd.DataFrame(columns=[\"train_acc\",\"valid_acc\",\"test_acc\",\"model\",\"n_suprious\"])\n",
    "ith=0\n",
    "replicates=100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e93cb6b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "Xlags,Xlags_test, adj1, w_true,w_mat,w_test_mat,n_suprious = data_pre(n, d, s0, w_graph_type,p_graph_type, sem_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c7e13e9d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1.0"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_suprious"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c8626720",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 288x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "##True W\n",
    "import matplotlib.pyplot as plt\n",
    "plt.matshow(w_mat,cmap = 'bwr', vmin = -1, vmax = 1)\n",
    "plt.colorbar()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fec25326",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAQoAAAD3CAYAAADlsBq6AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjMsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+AADFEAAASQElEQVR4nO3df9BcVX3H8fcn4aeIRUz4ZYiP0zJoqgXtww+HzigINESE0mk7pBWV4mTqwAwwTi3WGbXjP46OP+pIoREjOCqUFqgM8isoTGormCcpBNKEktJ0DMmQhCokTZEJfPvH3g3L033uPfvs2bt3N5/XzE529/76LpAv555z7vkqIjAzKzNn2AGYWfM5UZhZJScKM6vkRGFmlZwozKySE4WZVXKiMGsgSSskbZf0xAzbJenrkjZJWifp3R3bFkt6sth2TY54nCjMmulGYHHJ9vOAE4rXMuA6AElzgWuL7YuApZIW9RuME4VZA0XEKuC/S3a5EPhOtDwMHCHpWOBUYFNEPB0RLwG3FPv2xYnCbDS9Gfh5x+ctxXczfd+XA/o9gZnBYil2Ju67BtYDL3Z8tTwilvd4SXX5Lkq+74sThVkGO4GpOWkNdL3yyosRMdnnJbcAx3d8XgBsBQ6a4fu++NbDLJc5c9JeedwJfLgY/TgdeD4itgGrgRMkvVXSQcDFxb59cYvCLAcpZxJA0s3A+4B5krYAnwUOBIiI64G7gSXAJmAPcGmxba+kK4D7gLnAiohY33c8fszcrH+Tc+fG1CGHJO2rPXvWZLj1qJVbFGa5ZGxRNE0jf9kgZpb1EUvpDLmaYzle0oOSNkhaL+nKIcdziKSfSXqsiOevhhlPm6S5kv5V0l21XrjePopaNS7qQc0s68ONlM+Qq9Ne4BMR8XbgdODyIf+z+RVwVkScBJwMLC461obtSmBDrVds91E4UdRmIDPLZithhlxtImJbRKwt3u+i9Zeh78k0fcQTEbG7+Hhg8Rpqp5ekBcAHgBtqv7gTRa0GMrNs3EiaAN4FPDLkOOZKehTYDqyMiKHGA3wN+CTwSq1XdYuidgOZWTZOJL0euA24KiJeGGYsEfFyRJxMa2LPqZLeMaxYJJ0PbI+INUMJYIwTRRNHPWaacWaApANpJYnvRcTtw46nLSJ+KekhWv05w+r4PQO4QNIS4BDgDZK+GxEfGviVJTigiX+d8mhiehvIzLJxIEnAt4ANEfGVBsQzX9IRxftDgbOBjcOKJyI+FRELImKC1n83P64lSbSNcYuicVFHxF6gPbNsA3Brjplls1XMkPspcKKkLZIuG1YstP6PeQlwlqRHi9eSIcZzLPCgpHW0EvzKiKh3SLIpxryPwjMzzTKYPPjgmDruuKR9tXmzZ2aa7bdGtLWQwonCLIfMD4U1jROFWS5OFGZWysOjwyFp2bBj6OR4yjUpnqHFMsajHk2OujH/4RUcT7kmxVN/LGM+PDq+bSWzuo1oEkgxkHkU8+bNi4mJib7OsWPHDubPn58noAwcT7kmxZMrls2bN7Nz585uzx79P5OHHRZTb3tb0nm1dq3nUQBMTEwwtXr1IE5tVpvJU07p7YAxblGM7y8zq1vGPoqqVd4k/XnHNP4nJL0s6chi22ZJjxfbpnL8NPdRmOWQcXi0Y5W3c2g9Tb1a0p0R8W/tfSLiS8CXiv0/CFwdEZ0LLJ0ZkVyTqJJbFGY55B316HWVt6XAzRl+xYycKMxySU8U8yRNdbymD+cmr/Im6XW01gC5rePrAO6XtCbXnBLfepjlkt6ZubNi1KOXVd4+CPzztNuOMyJiq6SjgJWSNhZrv86aWxRmOeS99ehllbeLmXbbERFbiz+3A3fQupXpixOFWS75EkXSKm+Sfg14L/CDju8Ok3R4+z1wLhmWJvSth1kOGUc9ZqofKunPiu3XF7teBNwfEf/TcfjRwB2tVRM5APh+RNzbb0xOFGa5ZJxwFRF30ypE3Pnd9dM+30irQFXnd08DJ2ULpOBEYZaDF64xsyROFGZWasxbFEm/rEnVxc0aa39ejyJl3rnZfm/MWxQptx775p0DSGrPO3eiMOs0xmtmpvyybvPOTxtMOGYjyi2KtHnnxcMnywAWLlzYZ1hmI2iME0XKL0uadx4RyyNiMiImm7IkmlltvLjuq/POgWdozTv/44FGZTaKRjQJpKhMFDPNOx94ZGajZn9OFNB93rmZdXBnpplVGvOSguP7y8zq5haFmVVyojCzUu6jMLMkThRmVsotCjNLMsaJYnx/mVmd2sOjKa+k01XWHn2fpOc76o9+JvXY2XCLwiyXTC2KHtaA+aeIOH+Wx/bELQqzHIZbezTXsTNyojDLpf7ao++R9JikeyT9Zo/H9sS3Hma51Ft7dC3wlojYLWkJ8I/ACYnH9swtCrMcaq49GhEvRMTu4v3dwIGS5qUcOxtOFGa51Fh7VNIxKuoGSjqV1t/l51KOnQ3fepjlUH/t0T8APi5pL/C/wMUREcBA1o9xojDLpcbaoxHxDeAbqcf2y4nCLAdP4TazJE4UZlbKLQozS+JEYWalvGammSVxi8LMSrmPwsySOFGYWSUnCjMr5VsPM0syxomi8pdJWiFpu6Qn6gjIbCRlXjOzaVJS4I3A4gHHYTba8q5H0TiV6S0iVkmaGHwoZiNuRJNAimztoGLdv2UACxcuzHVas9Exxoki2y+LiOURMRkRk/Pnz891WrPRsL/fephZohFNAimcKMxyGPN5FCnDozcDPwVOlLRF0mWDD8tsBI3x8GjKqMfSOgIxG2mZWxSSFgN/TWuB3Bsi4gvTtv8J8BfFx93AxyPisWLbZmAX8DKwt6KGSJLRTG9mTVRv7dH/BN4bEb+QdB6wHDitY/uZEbEzS0A4UZjlkbdFsa9+aOvUatcP3ZcoIuJfOvZ/mFahn4EZ394Xs7rVX3u07TLgno7PAdwvaU2Xc8+KWxRmudRbe7S1o3QmrUTxOx1fnxERWyUdBayUtDEiVqUG141bFGY51Fx7tHVJ/RZwA3BhRDzX/j4ithZ/bgfuoHUr0xcnCrMc8j49mlJ7dCFwO3BJRPx7x/eHSTq8/R44F+j7yW/fepjlkqkzM7H26GeANwF/U9Qqbg+DHg3cUXx3APD9iLi335icKMxyqbf26MeAj3U57mngpGyBFJwozHIY8yncThRmuThRmFkptyjMLIkTRY82b4aPfnQgp56NS+fcNOwQXuPbK7rOnTHgdxd3m2s0HE891cPOrj1qZkncojCzUu6jMLMkThRmVsmJwsxK+dbDzCp51MPMkrhFYWaVnCjMrJT7KMwsiROFmZVyi8LMkjhRmFkpD4+aWZIxblGkFCk+XtKDkjZIWi/pyjoCMxspeZfrR9JiSU9K2iTpmi7bJenrxfZ1kt6deuxspES9F/hERLwdOB24XNKiHBc3GyuZEkVH7dHzgEXA0i5/584DTihey4Dreji2959WtUNEbIuItcX7XcAGysubme1/8rYo9tUejYiXgHbt0U4XAt+JloeBIyQdm3hsz3q6qZI0AbwLeKTLtmXtWoo7Xnyx37jMRk+9tUdn2qfXuqVJkjszJb0euA24KiJemL49IpbTKr3O5Lx5XuvN9jvRtWRoVzlqj860T3Ld0l4kJQpJB9JKEt+LiNv7vajZuImAvXuznS6l9uhM+xyUcGzPUkY9BHwL2BARX+n3gmbj6pVX0l4JKmuPFp8/XIx+nA48HxHbEo/tWUqL4gzgEuBxSY8W3/1lUfLMzGi1KBKTQMK5kmqP3g0sATYBe4BLy47tN6bKRBERP6H7fY+ZdciVKCCp9mgAl6ce2y/PzDTLJGeiaBonCrMMct56NJEThVkmThRmVirz8GjjOFGYZeBbDzNL4kRhZpWcKMyslG89zCyJE4WZlXKLwsySeHi0V7t2wapVAzn1bHz7aS+PMSruu7c5/64mT0nf1y0KM0viRGFmpdyiMLMkThRmVsmJwsxK+aEwM6vkPgozSzLOiWJ8q6qa1SzjKtylJB0paaWkp4o/39hlnxlrBkv6nKRnJD1avJZUXdOJwiyD9q1HHYkCuAb4UUScAPyo+DxdVc3gr0bEycWrciFeJwqzTGpMFBcCNxXvbwJ+b/oOuWsGO1GYZdBji6Kq9miVo4tiPxR/HlW28ww1g6+QtE7Sim63LtO5M9Mskx6GR6tqjyLpAeCYLps+3UtMM9QMvg74PK2apJ8Hvgz8adl5nCjMMsg9PBoRZ8+0TdKzko6NiG2SjgW2z7Bf15rBEfFsxz7fBO6qise3HmaZ1NhHcSfwkeL9R4AfTN+hrGZwkVzaLgKeqLqgE4VZBjWPenwBOEfSU8A5xWckHSepPYLRrhl8Vpdh0C9KelzSOuBM4OqqC1beekg6BFgFHFzs/w8R8dkef5jZ2KtrwlVEPAe8v8v3W2kVLi6tGRwRl/R6zZQ+il8BZ0XE7uKe5yeS7omIh3u9mNk4G+eZmSnVzAPYXXw8sHg1Zxkiswbwsx6ApLnAGuA3gGsj4pEu+ywDlgEsnDs3Z4xmjTfuT48mdWZGxMsRcTKwADhV0ju67LM8IiYjYnK+E4Xth2rszKxdT6MeEfFL4CFg8UCiMRth+3WikDRf0hHF+0OBs4GNgw7MbJTUPDxau5Q+imOBm4p+ijnArRFROZPLbH8zqkkgRcqoxzpaD5SY2Qw86mFmSZwozKzUuA+POlGYZeIWhZmVch+FmSVxojCzUm5RmFkSJwozq+REYWalPDxqZpXcR2FmSZwoevXOd8Lq1QM5tVlT1ZUoJB0J/B0wAWwG/igiftFlv83ALuBlYG+7lkjq8Z28CrdZBg2sPdp2ZlFftLPgUC/HA04UZtk0qfZo7uPdR2GWQY+jHvMkTXV8Xh4Ry3u43Gtqj0qaqfZoAPdLCuBvO66Revw+ThRmmfTQWqir9ugZEbG1SAQrJW2MiFU9HL+PE4VZBk2sPVoUBCIitku6AziVVjGvpOM7uY/CLJOG1R49TNLh7ffAubxaY7Ty+OmcKMwyaGDt0aNpVfV7DPgZ8MOIuLfs+DK+9TDLpGG1R58GTurl+DJOFGaZeGammZXyQ2FmVskPhZlZEicKM6vkRGFmpXzrUShqj04Bz0TE+YMLyWw0OVG0XAlsAN4woFjMRta4tyiSZmZKWgB8ALhhsOGYja69e9Neoyi1RfE14JPA4QOMxWxk7fctCknnA9sjYk3FfsskTUma2rFjR7YAzUZFjc961C7l1uMM4IJi/b1bgLMkfXf6ThGxPCImI2Jy/vz5mcM0a7aaHwqrXWWiiIhPRcSCiJgALgZ+HBEfGnhkZiNmnBOF51GYZTKqSSBFT4kiIh4CHhpIJGYjbNw7M92iMMvAT4+aWRK3KMys1LjfenjNTLNM6hr1kHSkpJWSnir+fGOXfU6U9GjH6wVJVxXbPifpmY5tS6qu6URhlkmTSgpGxJNFKcGTgd8G9gB3dOzy1fb2iLh7+vHTOVGYZVDzhKteSwK+H/iPiPiv2V7QicIskxoTxWtKAgJVJQEvBm6e9t0VktZJWtHt1mU6JwqzDNrDo4lPj85rPxdVvJZNP5+kByQ90eV1YS9xSToIuAD4+46vrwN+HTgZ2AZ8ueo8HvUwyyRn7dEcJQUL5wFrI+LZjnPvey/pm8BdVQG7RWGWQc19FL2UBFzKtNuOIrm0XcSrpQZn5ERhlknDSgoi6XXF9tunHf9FSY9LWgecCVxddUHfephlUOeEq5SSgsXnPcCbuux3Sa/XHEiiWLNmzU7NmTProZjCPGBnjngycTzlmhRPrlje0svO4zwzcyCJIiL6XrlG0lRVh0+dHE+5JsUzrFicKMyslJ8eNbNK4/5QWJMTxfJhBzCN4ynXpHiGEss4JwpFxLBjMBt5hx46GRMTU0n7btyoNU3pz0nV5BaF2cjwrYeZJXGiMLNSHvUwsyRuUZhZKfdRmFkSJwozK+UWhZklcaIws0pOFGZWysOjZlbJfRRmlsSJwswqjXOi8OK6ZhnUuQq3pD+UtF7SK5JmfApV0mJJT0raJOmaju8ra5dO50RhlkmNq3A/Afw+sGqmHSTNBa6lVddjEbBU0qJic2Xt0umcKMwyqLNFEREbIuLJit1OBTZFxNMR8RJwC62apdB77VL3UZjl0rDh0TcDP+/4vAU4rXj/mtqlkqpqlzpRmOWx5j7QvMSdD5HUuRzW8oh4zfJ9kh4Ajuly7Kcjoqwy2L5TdPlu1svZOVGYZRARizOfb8bao4m2AMd3fF4AbC3e91K7FHAfhdm4Wg2cIOmtRUXzi2nVLIXeapcCThRmI0fSRZK2AO8BfijpvuL7fbVHI2IvcAVwH7ABuDUi1hen6Fq7tPSaXoXbzKq4RWFmlZwozKySE4WZVXKiMLNKThRmVsmJwswqOVGYWSUnCjOr9H+x8ogcVWzG4wAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 288x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "##True W\n",
    "import matplotlib.pyplot as plt\n",
    "plt.matshow(w_test_mat,cmap = 'bwr', vmin = -1, vmax = 1)\n",
    "plt.colorbar()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "a11f2675",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.2204410486384874"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Xlags[-1][:,-1].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "138579a0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.202, 0.981, 1.061, 0.768, 0.22 ])"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Xlags[-1].mean(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "d4685911",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.2204410486384874"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Xlags[-1][:].mean(axis=0)[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e865265d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_node_feature(Xlags,node_num):\n",
    "#     for num_lags in range(1):\n",
    "#         if num_lags==0:\n",
    "#             X_feature=Xlags[num_lags][node_num]\n",
    "#         else:\n",
    "#             X_feature=np.append(X_feature,Xlags[num_lags][node_num])##shape num_lags*5 (250)\n",
    "    X_feature=Xlags[-1][node_num]\n",
    "    return(X_feature)\n",
    "def to_binary(x):\n",
    "    if x>Xlags[-1][:,-1].mean():\n",
    "        return 1\n",
    "    else:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ab86e196",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_graph(valid_list,adj1,Xlags,n):\n",
    " ##node list for validation\n",
    "    labels=[]\n",
    "    G = nx.from_numpy_array(adj1)\n",
    "    for node_num in range(n):\n",
    "        G.nodes[node_num]['feature']=get_node_feature(Xlags,node_num)[:-1]\n",
    "\n",
    "        G.nodes[node_num]['label']=to_binary(get_node_feature(Xlags,node_num)[-1])\n",
    "\n",
    "        labels.append(G.nodes[node_num]['label'])\n",
    "        if node_num in valid_list:\n",
    "            G.nodes[node_num]['train_mask']=False\n",
    "            G.nodes[node_num]['valid_mask']=True\n",
    "        else:\n",
    "            G.nodes[node_num]['train_mask']=True\n",
    "            G.nodes[node_num]['valid_mask']=False\n",
    "    g = dgl.from_networkx(G, node_attrs=['feature','label','train_mask','valid_mask'])\n",
    "    return g"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1556b5a5",
   "metadata": {},
   "source": [
    "## Graphsage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "7f827a3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dgl.nn import SAGEConv\n",
    "\n",
    "# ----------- 2. create model -------------- #\n",
    "# build a two-layer GraphSAGE model\n",
    "class GraphSAGE(nn.Module):\n",
    "    def __init__(self,g, in_feats, hid_feats,out_feats):\n",
    "        super(GraphSAGE, self).__init__()\n",
    "        self.g = g\n",
    "        self.conv1 = SAGEConv(in_feats, hid_feats, 'mean')\n",
    "        self.conv2 = SAGEConv(hid_feats, out_feats, 'mean')\n",
    "\n",
    "    def forward(self, g, in_feats):\n",
    "        h = self.conv1(g, in_feats)\n",
    "        h = F.relu(h)\n",
    "        h = self.conv2(g, h)\n",
    "        return h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "cf70bd42",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, g, features, labels, mask):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        logits = model(g,features)\n",
    "        logits = logits[mask]\n",
    "        labels = labels[mask]\n",
    "        _, indices = torch.max(logits, dim=1)\n",
    "        correct = torch.sum(indices == labels)\n",
    "        return correct.item() * 1.0 / len(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "4ca3d404",
   "metadata": {},
   "outputs": [],
   "source": [
    "class atten_Net(nn.Module):\n",
    "    def __init__(self,g, in_feats, hid_feats, out_feats,n_node):\n",
    "        super(atten_Net, self).__init__()\n",
    "        self.layer1 = SAGEConv(in_feats, hid_feats, 'mean') \n",
    "        self.layer2 = SAGEConv(hid_feats, out_feats, 'mean')\n",
    "        self.att_mlp_1 = nn.Linear(n_node, hid_feats)\n",
    "        self.att_mlp_2 = nn.Linear(hid_feats, 2)\n",
    "        self.layer3 = SAGEConv(in_feats*2, hid_feats, 'mean')\n",
    "        self.layer4 = SAGEConv(hid_feats, out_feats, 'mean')\n",
    "\n",
    "    def forward(self, g, features,dag):\n",
    "        ##use mlp to get attention weights\n",
    "        node_att = F.relu(self.att_mlp_1(dag))\n",
    "        node_att = F.softmax(self.att_mlp_2(node_att), dim=-1)\n",
    "        node_weight_c = node_att[:, 0]\n",
    "        node_weight_o = node_att[:, 1]\n",
    "        ##attention on the causal/trival part\n",
    "        feature_c = node_weight_c.view(1, -1) * features\n",
    "        feature_o = node_weight_o.view(1, -1) * features\n",
    "        ## apply the mask on the features\n",
    "        xc = F.relu(self.layer1(g,feature_c))\n",
    "        xc = self.layer2(g,xc)\n",
    "        xc=F.log_softmax(xc, dim=-1)\n",
    "        \n",
    "        xo = F.relu(self.layer1(g,feature_o))\n",
    "        xo = self.layer2(g,xo)\n",
    "        xo=F.log_softmax(xo, dim=-1)\n",
    "        ##xco        \n",
    "        num = xc.shape[0]\n",
    "        l = [i for i in range(num)]\n",
    "        random.shuffle(l)\n",
    "        random_idx = torch.tensor(l)\n",
    "        xco = torch.cat((feature_c[random_idx], feature_o), dim=1)\n",
    "        xco = F.relu(self.layer3(g,xco))\n",
    "        xco = self.layer4(g,xco)\n",
    "        xco=F.log_softmax(xco, dim=-1)\n",
    "        \n",
    "        return xc,xo,xco"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "7db3a7bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_new(model, g, features, labels, mask,dag):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        logits_c,logits_o,logits_co = model(g, features,dag)\n",
    "        logits = logits_o[mask]\n",
    "        labels = labels[mask]\n",
    "        _, indices = torch.max(logits, dim=1)\n",
    "        correct = torch.sum(indices == labels)\n",
    "        return correct.item() * 1.0 / len(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "a08dbdd6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------the 0 iteration------------------\n",
      "finish data!\n",
      "finish fit graph!\n",
      "Early stopped training at epoch 51\n",
      "Graphsage:train 0.6666666666666666 valid 0.7 test 0.35\n",
      "Early stopped training at epoch 287\n",
      "proposed:train 0.8333333333333334 valid 0.65 test 0.55 n_suprious 2.0\n",
      "-------------------the 1 iteration------------------\n",
      "finish data!\n",
      "finish fit graph!\n",
      "Early stopped training at epoch 87\n",
      "Graphsage:train 0.7 valid 0.45 test 0.45\n",
      "Early stopped training at epoch 76\n",
      "proposed:train 0.6333333333333333 valid 0.55 test 0.5 n_suprious 1.0\n",
      "-------------------the 2 iteration------------------\n",
      "finish data!\n",
      "finish fit graph!\n",
      "Early stopped training at epoch 161\n",
      "Graphsage:train 0.9 valid 0.75 test 0.45\n",
      "Early stopped training at epoch 40\n",
      "proposed:train 0.5666666666666667 valid 0.4 test 0.7 n_suprious 3.0\n",
      "-------------------the 3 iteration------------------\n",
      "finish data!\n",
      "finish fit graph!\n",
      "Early stopped training at epoch 255\n",
      "Graphsage:train 0.8 valid 0.5 test 0.45\n",
      "proposed:train 0.9 valid 0.6 test 0.55 n_suprious 1.0\n",
      "-------------------the 4 iteration------------------\n",
      "finish data!\n",
      "finish fit graph!\n",
      "Graphsage:train 0.7666666666666667 valid 0.6 test 0.6\n",
      "Early stopped training at epoch 51\n",
      "proposed:train 0.6 valid 0.65 test 0.55 n_suprious 1.0\n",
      "-------------------the 5 iteration------------------\n",
      "-------------------the 5 iteration------------------\n",
      "finish data!\n",
      "finish fit graph!\n",
      "Early stopped training at epoch 110\n",
      "Graphsage:train 0.9 valid 0.3 test 0.45\n",
      "Early stopped training at epoch 95\n",
      "proposed:train 0.8 valid 0.6 test 0.4 n_suprious 2.0\n",
      "-------------------the 6 iteration------------------\n",
      "-------------------the 6 iteration------------------\n",
      "finish data!\n",
      "finish fit graph!\n",
      "Early stopped training at epoch 195\n",
      "Graphsage:train 0.9 valid 0.55 test 0.4\n",
      "Early stopped training at epoch 83\n",
      "proposed:train 0.8 valid 0.5 test 0.5 n_suprious 3.0\n",
      "-------------------the 7 iteration------------------\n",
      "finish data!\n",
      "finish fit graph!\n",
      "Early stopped training at epoch 189\n",
      "Graphsage:train 0.9666666666666667 valid 0.6 test 0.5\n",
      "Early stopped training at epoch 95\n",
      "proposed:train 0.7666666666666667 valid 0.75 test 0.55 n_suprious 2.0\n",
      "-------------------the 8 iteration------------------\n",
      "finish data!\n",
      "finish fit graph!\n",
      "Early stopped training at epoch 244\n",
      "Graphsage:train 0.9 valid 0.5 test 0.55\n",
      "Early stopped training at epoch 43\n",
      "proposed:train 0.6333333333333333 valid 0.45 test 0.55 n_suprious 1.0\n",
      "-------------------the 9 iteration------------------\n",
      "-------------------the 9 iteration------------------\n",
      "finish data!\n",
      "finish fit graph!\n",
      "Early stopped training at epoch 106\n",
      "Graphsage:train 0.7333333333333333 valid 0.7 test 0.25\n",
      "Early stopped training at epoch 87\n",
      "proposed:train 0.7 valid 0.55 test 0.55 n_suprious 3.0\n",
      "           train_acc  valid_acc  test_acc  n_suprious\n",
      "model                                                \n",
      "Graphsage   0.823333      0.565     0.445         1.9\n",
      "proposed    0.723333      0.570     0.540         1.9\n",
      "-------------------the 10 iteration------------------\n",
      "-------------------the 10 iteration------------------\n",
      "finish data!\n",
      "finish fit graph!\n",
      "Early stopped training at epoch 125\n",
      "Graphsage:train 0.8 valid 0.7 test 0.6\n",
      "Early stopped training at epoch 134\n",
      "proposed:train 0.7666666666666667 valid 0.6 test 0.55 n_suprious 1.0\n",
      "-------------------the 11 iteration------------------\n",
      "-------------------the 11 iteration------------------\n",
      "finish data!\n",
      "finish fit graph!\n",
      "Early stopped training at epoch 76\n",
      "Graphsage:train 0.6 valid 0.4 test 0.45\n",
      "Early stopped training at epoch 110\n",
      "proposed:train 0.8 valid 0.6 test 0.55 n_suprious 3.0\n",
      "-------------------the 12 iteration------------------\n",
      "finish data!\n",
      "finish fit graph!\n",
      "Early stopped training at epoch 212\n",
      "Graphsage:train 0.7333333333333333 valid 0.7 test 0.45\n",
      "Early stopped training at epoch 56\n",
      "proposed:train 0.7666666666666667 valid 0.9 test 0.65 n_suprious 2.0\n",
      "-------------------the 13 iteration------------------\n",
      "finish data!\n",
      "finish fit graph!\n",
      "Early stopped training at epoch 149\n",
      "Graphsage:train 0.5666666666666667 valid 0.4 test 0.85\n",
      "Early stopped training at epoch 144\n",
      "proposed:train 0.8333333333333334 valid 0.8 test 0.8 n_suprious 2.0\n",
      "-------------------the 14 iteration------------------\n",
      "-------------------the 14 iteration------------------\n",
      "finish data!\n",
      "finish fit graph!\n",
      "Early stopped training at epoch 71\n",
      "Graphsage:train 0.8333333333333334 valid 0.5 test 0.7\n",
      "Early stopped training at epoch 243\n",
      "proposed:train 0.8666666666666667 valid 0.85 test 0.6 n_suprious 3.0\n",
      "-------------------the 15 iteration------------------\n",
      "-------------------the 15 iteration------------------\n",
      "-------------------the 15 iteration------------------\n",
      "finish data!\n",
      "finish fit graph!\n",
      "Early stopped training at epoch 81\n",
      "Graphsage:train 0.7333333333333333 valid 0.5 test 0.55\n",
      "Early stopped training at epoch 135\n",
      "proposed:train 0.9333333333333333 valid 0.85 test 0.5 n_suprious 3.0\n",
      "-------------------the 16 iteration------------------\n",
      "-------------------the 16 iteration------------------\n",
      "finish data!\n",
      "finish fit graph!\n",
      "Early stopped training at epoch 284\n",
      "Graphsage:train 0.9 valid 0.65 test 0.6\n",
      "Early stopped training at epoch 66\n",
      "proposed:train 0.7333333333333333 valid 0.65 test 0.55 n_suprious 3.0\n",
      "-------------------the 17 iteration------------------\n",
      "-------------------the 17 iteration------------------\n",
      "-------------------the 17 iteration------------------\n",
      "-------------------the 17 iteration------------------\n",
      "finish data!\n",
      "finish fit graph!\n",
      "Early stopped training at epoch 87\n",
      "Graphsage:train 0.8 valid 0.6 test 0.45\n",
      "Early stopped training at epoch 175\n",
      "proposed:train 0.8666666666666667 valid 0.55 test 0.65 n_suprious 2.0\n",
      "-------------------the 18 iteration------------------\n",
      "-------------------the 18 iteration------------------\n",
      "finish data!\n",
      "finish fit graph!\n",
      "Early stopped training at epoch 205\n",
      "Graphsage:train 0.6333333333333333 valid 0.65 test 0.45\n",
      "Early stopped training at epoch 135\n",
      "proposed:train 0.9666666666666667 valid 0.8 test 0.6 n_suprious 2.0\n",
      "-------------------the 19 iteration------------------\n",
      "finish data!\n",
      "finish fit graph!\n",
      "Early stopped training at epoch 165\n",
      "Graphsage:train 0.8 valid 0.5 test 0.55\n",
      "Early stopped training at epoch 137\n",
      "proposed:train 0.7 valid 0.8 test 0.4 n_suprious 3.0\n",
      "           train_acc  valid_acc  test_acc  n_suprious\n",
      "model                                                \n",
      "Graphsage   0.781667     0.5625    0.5050        2.15\n",
      "proposed    0.773333     0.6550    0.5625        2.15\n",
      "-------------------the 20 iteration------------------\n",
      "finish data!\n",
      "finish fit graph!\n",
      "Early stopped training at epoch 194\n",
      "Graphsage:train 1.0 valid 0.65 test 0.5\n",
      "Early stopped training at epoch 194\n",
      "proposed:train 0.9333333333333333 valid 0.7 test 0.45 n_suprious 2.0\n",
      "-------------------the 21 iteration------------------\n",
      "-------------------the 21 iteration------------------\n",
      "-------------------the 21 iteration------------------\n",
      "finish data!\n",
      "finish fit graph!\n",
      "Early stopped training at epoch 216\n",
      "Graphsage:train 0.7333333333333333 valid 0.5 test 0.7\n",
      "Early stopped training at epoch 186\n",
      "proposed:train 0.9666666666666667 valid 0.7 test 0.4 n_suprious 2.0\n",
      "-------------------the 22 iteration------------------\n",
      "finish data!\n",
      "finish fit graph!\n",
      "Early stopped training at epoch 43\n",
      "Graphsage:train 0.7666666666666667 valid 0.5 test 0.45\n",
      "Early stopped training at epoch 47\n",
      "proposed:train 0.8333333333333334 valid 0.4 test 0.5 n_suprious 3.0\n",
      "-------------------the 23 iteration------------------\n",
      "finish data!\n",
      "finish fit graph!\n",
      "Early stopped training at epoch 71\n",
      "Graphsage:train 0.9 valid 0.5 test 0.65\n",
      "Early stopped training at epoch 33\n",
      "proposed:train 0.6 valid 0.35 test 0.35 n_suprious 1.0\n",
      "-------------------the 24 iteration------------------\n",
      "finish data!\n",
      "finish fit graph!\n",
      "Early stopped training at epoch 180\n",
      "Graphsage:train 0.6666666666666666 valid 0.6 test 0.7\n",
      "Early stopped training at epoch 75\n",
      "proposed:train 0.5333333333333333 valid 0.65 test 0.25 n_suprious 4.0\n",
      "-------------------the 25 iteration------------------\n",
      "finish data!\n",
      "finish fit graph!\n",
      "Early stopped training at epoch 192\n",
      "Graphsage:train 0.9 valid 0.7 test 0.45\n",
      "Early stopped training at epoch 76\n",
      "proposed:train 0.7 valid 0.6 test 0.6 n_suprious 1.0\n",
      "-------------------the 26 iteration------------------\n",
      "finish data!\n",
      "finish fit graph!\n",
      "Early stopped training at epoch 56\n",
      "Graphsage:train 0.7666666666666667 valid 0.55 test 0.7\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopped training at epoch 74\n",
      "proposed:train 0.7333333333333333 valid 0.45 test 0.65 n_suprious 2.0\n",
      "-------------------the 27 iteration------------------\n",
      "finish data!\n",
      "finish fit graph!\n",
      "Early stopped training at epoch 67\n",
      "Graphsage:train 0.7666666666666667 valid 0.65 test 0.65\n",
      "Early stopped training at epoch 135\n",
      "proposed:train 0.9 valid 0.85 test 0.55 n_suprious 1.0\n",
      "-------------------the 28 iteration------------------\n",
      "-------------------the 28 iteration------------------\n",
      "-------------------the 28 iteration------------------\n",
      "finish data!\n",
      "finish fit graph!\n",
      "Graphsage:train 0.6333333333333333 valid 0.75 test 0.45\n",
      "Early stopped training at epoch 43\n",
      "proposed:train 0.6666666666666666 valid 0.65 test 0.35 n_suprious 1.0\n",
      "-------------------the 29 iteration------------------\n",
      "finish data!\n",
      "finish fit graph!\n",
      "Early stopped training at epoch 70\n",
      "Graphsage:train 0.9333333333333333 valid 0.75 test 0.55\n",
      "Early stopped training at epoch 37\n",
      "proposed:train 0.8666666666666667 valid 0.4 test 0.5 n_suprious 2.0\n",
      "           train_acc  valid_acc  test_acc  n_suprious\n",
      "model                                                \n",
      "Graphsage   0.790000   0.580000  0.530000    2.066667\n",
      "proposed    0.773333   0.628333  0.528333    2.066667\n",
      "-------------------the 30 iteration------------------\n",
      "-------------------the 30 iteration------------------\n",
      "finish data!\n",
      "finish fit graph!\n",
      "Early stopped training at epoch 235\n",
      "Graphsage:train 0.8333333333333334 valid 0.65 test 0.5\n",
      "Early stopped training at epoch 76\n",
      "proposed:train 0.6666666666666666 valid 0.55 test 0.4 n_suprious 2.0\n",
      "-------------------the 31 iteration------------------\n",
      "-------------------the 31 iteration------------------\n",
      "finish data!\n",
      "finish fit graph!\n",
      "Early stopped training at epoch 62\n",
      "Graphsage:train 0.7333333333333333 valid 0.5 test 0.3\n",
      "Early stopped training at epoch 51\n",
      "proposed:train 0.8666666666666667 valid 0.55 test 0.2 n_suprious 3.0\n",
      "-------------------the 32 iteration------------------\n",
      "-------------------the 32 iteration------------------\n",
      "finish data!\n",
      "finish fit graph!\n",
      "Early stopped training at epoch 92\n",
      "Graphsage:train 0.8 valid 0.45 test 0.8\n",
      "Early stopped training at epoch 64\n",
      "proposed:train 0.6 valid 0.5 test 0.55 n_suprious 1.0\n",
      "-------------------the 33 iteration------------------\n",
      "-------------------the 33 iteration------------------\n",
      "-------------------the 33 iteration------------------\n",
      "finish data!\n",
      "finish fit graph!\n",
      "Early stopped training at epoch 102\n",
      "Graphsage:train 0.9333333333333333 valid 0.6 test 0.5\n",
      "Early stopped training at epoch 60\n",
      "proposed:train 0.9 valid 0.5 test 0.45 n_suprious 3.0\n",
      "-------------------the 34 iteration------------------\n",
      "finish data!\n",
      "finish fit graph!\n",
      "Early stopped training at epoch 72\n",
      "Graphsage:train 0.8 valid 0.65 test 0.5\n",
      "Early stopped training at epoch 150\n",
      "proposed:train 0.9666666666666667 valid 0.75 test 0.55 n_suprious 3.0\n",
      "-------------------the 35 iteration------------------\n",
      "finish data!\n",
      "finish fit graph!\n",
      "Early stopped training at epoch 71\n",
      "Graphsage:train 0.7666666666666667 valid 0.55 test 0.75\n",
      "Early stopped training at epoch 93\n",
      "proposed:train 0.9666666666666667 valid 0.5 test 0.25 n_suprious 3.0\n",
      "-------------------the 36 iteration------------------\n",
      "-------------------the 36 iteration------------------\n",
      "finish data!\n",
      "finish fit graph!\n",
      "Early stopped training at epoch 82\n",
      "Graphsage:train 0.8333333333333334 valid 0.55 test 0.4\n",
      "Early stopped training at epoch 31\n",
      "proposed:train 0.8333333333333334 valid 0.55 test 0.5 n_suprious 1.0\n",
      "-------------------the 37 iteration------------------\n",
      "finish data!\n",
      "finish fit graph!\n",
      "Early stopped training at epoch 115\n",
      "Graphsage:train 0.8 valid 0.45 test 0.25\n",
      "Early stopped training at epoch 69\n",
      "proposed:train 0.8 valid 0.6 test 0.65 n_suprious 2.0\n",
      "-------------------the 38 iteration------------------\n",
      "-------------------the 38 iteration------------------\n",
      "-------------------the 38 iteration------------------\n",
      "finish data!\n",
      "finish fit graph!\n",
      "Early stopped training at epoch 200\n",
      "Graphsage:train 0.7666666666666667 valid 0.7 test 0.65\n",
      "Early stopped training at epoch 56\n",
      "proposed:train 0.5333333333333333 valid 0.45 test 0.2 n_suprious 1.0\n",
      "-------------------the 39 iteration------------------\n",
      "-------------------the 39 iteration------------------\n",
      "-------------------the 39 iteration------------------\n",
      "-------------------the 39 iteration------------------\n",
      "finish data!\n",
      "finish fit graph!\n",
      "Early stopped training at epoch 93\n",
      "Graphsage:train 0.9333333333333333 valid 0.65 test 0.6\n",
      "Early stopped training at epoch 133\n",
      "proposed:train 0.9333333333333333 valid 0.75 test 0.55 n_suprious 1.0\n",
      "           train_acc  valid_acc  test_acc  n_suprious\n",
      "model                                                \n",
      "Graphsage   0.797500    0.57875   0.52875        2.05\n",
      "proposed    0.781667    0.61375   0.50375        2.05\n",
      "-------------------the 40 iteration------------------\n",
      "finish data!\n",
      "finish fit graph!\n",
      "Early stopped training at epoch 64\n",
      "Graphsage:train 0.7333333333333333 valid 0.6 test 0.5\n",
      "Early stopped training at epoch 98\n",
      "proposed:train 0.8333333333333334 valid 0.75 test 0.4 n_suprious 3.0\n",
      "-------------------the 41 iteration------------------\n",
      "finish data!\n",
      "finish fit graph!\n",
      "Early stopped training at epoch 143\n",
      "Graphsage:train 0.9666666666666667 valid 0.85 test 0.45\n",
      "Early stopped training at epoch 112\n",
      "proposed:train 0.9333333333333333 valid 0.7 test 0.6 n_suprious 4.0\n",
      "-------------------the 42 iteration------------------\n",
      "finish data!\n",
      "finish fit graph!\n",
      "Early stopped training at epoch 42\n",
      "Graphsage:train 0.9 valid 0.45 test 0.6\n",
      "Early stopped training at epoch 94\n",
      "proposed:train 0.5333333333333333 valid 0.5 test 0.35 n_suprious 2.0\n",
      "-------------------the 43 iteration------------------\n",
      "finish data!\n",
      "finish fit graph!\n",
      "Early stopped training at epoch 61\n",
      "Graphsage:train 0.7 valid 0.4 test 0.75\n",
      "Early stopped training at epoch 86\n",
      "proposed:train 0.8 valid 0.6 test 0.45 n_suprious 1.0\n",
      "-------------------the 44 iteration------------------\n",
      "finish data!\n",
      "finish fit graph!\n",
      "Early stopped training at epoch 100\n",
      "Graphsage:train 0.8333333333333334 valid 0.7 test 0.4\n",
      "Early stopped training at epoch 276\n",
      "proposed:train 0.8 valid 0.55 test 0.6 n_suprious 3.0\n",
      "-------------------the 45 iteration------------------\n",
      "-------------------the 45 iteration------------------\n",
      "finish data!\n",
      "finish fit graph!\n",
      "Early stopped training at epoch 125\n",
      "Graphsage:train 0.8666666666666667 valid 0.65 test 0.55\n",
      "Early stopped training at epoch 175\n",
      "proposed:train 0.9666666666666667 valid 0.5 test 0.5 n_suprious 1.0\n",
      "-------------------the 46 iteration------------------\n",
      "-------------------the 46 iteration------------------\n",
      "-------------------the 46 iteration------------------\n",
      "finish data!\n",
      "finish fit graph!\n",
      "Early stopped training at epoch 105\n",
      "Graphsage:train 0.6333333333333333 valid 0.5 test 0.6\n",
      "Early stopped training at epoch 88\n",
      "proposed:train 0.5333333333333333 valid 0.7 test 0.55 n_suprious 1.0\n",
      "-------------------the 47 iteration------------------\n",
      "-------------------the 47 iteration------------------\n",
      "-------------------the 47 iteration------------------\n",
      "finish data!\n",
      "finish fit graph!\n",
      "Early stopped training at epoch 87\n",
      "Graphsage:train 0.8666666666666667 valid 0.7 test 0.6\n",
      "Early stopped training at epoch 157\n",
      "proposed:train 0.6 valid 0.65 test 0.55 n_suprious 1.0\n",
      "-------------------the 48 iteration------------------\n",
      "-------------------the 48 iteration------------------\n",
      "-------------------the 48 iteration------------------\n",
      "finish data!\n",
      "finish fit graph!\n",
      "Early stopped training at epoch 145\n",
      "Graphsage:train 0.7666666666666667 valid 0.55 test 0.45\n",
      "Early stopped training at epoch 109\n",
      "proposed:train 0.6666666666666666 valid 0.6 test 0.4 n_suprious 3.0\n",
      "-------------------the 49 iteration------------------\n",
      "finish data!\n",
      "finish fit graph!\n",
      "Early stopped training at epoch 46\n",
      "Graphsage:train 0.7 valid 0.55 test 0.35\n",
      "Early stopped training at epoch 89\n",
      "proposed:train 0.8 valid 0.5 test 0.55 n_suprious 1.0\n",
      "           train_acc  valid_acc  test_acc  n_suprious\n",
      "model                                                \n",
      "Graphsage   0.797333      0.582     0.528        2.04\n",
      "proposed    0.774667      0.612     0.502        2.04\n"
     ]
    }
   ],
   "source": [
    "torch.set_default_dtype(torch.double)\n",
    "np.set_printoptions(precision=3)\n",
    "\n",
    "torch.manual_seed(12345)\n",
    "ut.set_random_seed(12345)\n",
    "\n",
    "n = 50 #number of people\n",
    "\n",
    "d = 10 #number of features\n",
    "\n",
    "w_graph_type = 'ER'\n",
    "p_graph_type = 'ER' \n",
    "sem_type = 'exp'\n",
    "s0 =  d\n",
    "#params\n",
    "lr=0.005\n",
    "alpha=0.2\n",
    "beta=1\n",
    "gamma=0.2\n",
    "early_stop_thresh=30\n",
    "n_epoch=300\n",
    "output=pd.DataFrame(columns=[\"train_acc\",\"valid_acc\",\"test_acc\",\"model\",\"n_suprious\"])\n",
    "ith=0\n",
    "replicates=50\n",
    "while ith<2*replicates:\n",
    "    print(\"-------------------the\",ith//2,\"iteration------------------\")\n",
    "    #create data\n",
    "    Xlags,Xlags_test, adj1, w_true,w_mat,w_test_mat,n_suprious = data_pre(n, d, s0, w_graph_type,p_graph_type, sem_type)\n",
    "    if n_suprious<=0:\n",
    "        continue\n",
    "    Xlags_torch = torch.Tensor(np.array(Xlags))\n",
    "    print(\"finish data!\")\n",
    "    #fit the causal graph\n",
    "    adj1_torch = torch.Tensor(adj1)\n",
    "    model_1 = GraphNOTEARS.model_p1_MLP(dims=[d, n, 1], bias=True)\n",
    "    W_est_1, P1_est_1 = GraphNOTEARS.linear_model(model_1, Xlags_torch, adj1_torch,  lambda1 = 0.01, lambda2 = 0.01, lambda3 = 0.01)\n",
    "    print(\"finish fit graph!\")\n",
    "    #g,g_test\n",
    "    valid_list=random.sample(range(n), int(n*0.4))\n",
    "    g = create_graph(valid_list,adj1,Xlags,n)\n",
    "    g_test=create_graph(valid_list,adj1,Xlags_test,n)\n",
    "    #GraphSAGE\n",
    "    net = GraphSAGE(g=g,\n",
    "          in_feats=d-1, \n",
    "          hid_feats=4, \n",
    "          out_feats=2)\n",
    "\n",
    "    features = g.ndata['feature']\n",
    "    labels = g.ndata['label']\n",
    "    train_mask = g.ndata['train_mask']\n",
    "    valid_mask = g.ndata['valid_mask']\n",
    "    ###test\n",
    "    features_test = g_test.ndata['feature']\n",
    "    labels_test = g_test.ndata['label']\n",
    "    #parameters\n",
    "    optimizer = torch.optim.Adam(net.parameters(), lr=lr)\n",
    "\n",
    "    best_loss = 99998\n",
    "    best_epoch = -1\n",
    "    for epoch in range(n_epoch):\n",
    "        net.train()\n",
    "        logits = net(g, in_feats=features)\n",
    "        \n",
    "        logp = F.log_softmax(logits, dim=-1)\n",
    "        loss = F.nll_loss(logp[train_mask], labels[train_mask])\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        ##evaluate\n",
    "        net.eval()\n",
    "        train_acc = evaluate(net, g, features, labels, train_mask)\n",
    "        valid_acc = evaluate(net, g, features, labels, valid_mask)\n",
    "        test_acc = evaluate(net, g_test, features_test, labels_test, valid_mask)\n",
    "        valid_loss = F.nll_loss(logp[valid_mask], labels[valid_mask])\n",
    "        #early stop\n",
    "        if valid_loss < best_loss:\n",
    "            best_loss = valid_loss\n",
    "            best_epoch = epoch\n",
    "            #torch.save(net.state_dict(), \"GCN_demo_large.pth\")\n",
    "        elif epoch - best_epoch > early_stop_thresh:\n",
    "            print(\"Early stopped training at epoch %d\" % epoch)\n",
    "            break  # terminate the training loop\n",
    "    print(\"Graphsage:train\",train_acc,\"valid\",valid_acc,\"test\",test_acc)\n",
    "    output.loc[ith]=[train_acc,valid_acc,test_acc,\"Graphsage\",n_suprious]\n",
    "    ith+=1\n",
    "    ##proposed\n",
    "    model = atten_Net(g,in_feats=d-1, hid_feats=4, out_feats=2,n_node=d)\n",
    "\n",
    "    #params\n",
    "    best_loss = 99998\n",
    "    best_epoch = -1\n",
    "\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "    #scheduler = torch.optim.lr_scheduler.ExponentialLR(optimizer, gamma=0.9)\n",
    "    for epoch in range(n_epoch):\n",
    "        model.train()\n",
    "        xc_logits,xo_logits,xco_logits = model(g, features,torch.tensor(W_est_1[:-1,:]))\n",
    "        ##trivial part\n",
    "        uniform_target = torch.ones_like(xc_logits[train_mask], dtype=torch.float)/2\n",
    "        c_loss = F.kl_div(xc_logits[train_mask], uniform_target, reduction='batchmean')\n",
    "\n",
    "        o_loss = F.nll_loss(xo_logits[train_mask], labels[train_mask])\n",
    "        co_loss= F.nll_loss(xco_logits[train_mask], labels[train_mask])\n",
    "        loss = alpha * c_loss + beta * o_loss +gamma*co_loss\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        #scheduler.step()\n",
    "        ##evaluate\n",
    "        model.eval()\n",
    "        train_acc = evaluate_new(model, g, features, labels, train_mask,torch.tensor(W_est_1[:-1,:]))\n",
    "        valid_acc = evaluate_new(model, g, features, labels, valid_mask,torch.tensor(W_est_1[:-1,:]))\n",
    "        test_acc = evaluate_new(model, g_test, features_test, labels_test, valid_mask,torch.tensor(W_est_1[:-1,:]))\n",
    "        #valid loss\n",
    "        uniform_target = torch.ones_like(xc_logits[valid_mask], dtype=torch.float)/2\n",
    "        valid_c_loss = F.kl_div(xc_logits[valid_mask], uniform_target, reduction='batchmean')\n",
    "        valid_o_loss = F.nll_loss(xo_logits[valid_mask], labels[valid_mask])\n",
    "        valid_co_loss = F.nll_loss(xco_logits[valid_mask], labels[valid_mask])\n",
    "        valid_loss = alpha * valid_c_loss+beta *valid_o_loss+gamma*valid_co_loss\n",
    "        #test loss\n",
    "        test_xc_logits,test_xo_logits,test_xco_logits = model(g_test, features_test,torch.tensor(W_est_1[:-1,:]))\n",
    "        uniform_target = torch.ones_like(test_xo_logits[valid_mask], dtype=torch.float)/2\n",
    "        test_c_loss = F.kl_div(test_xc_logits[valid_mask], uniform_target, reduction='batchmean')\n",
    "        test_o_loss = F.nll_loss(test_xo_logits[valid_mask], labels_test[valid_mask])\n",
    "        test_co_loss = F.nll_loss(test_xco_logits[valid_mask], labels_test[valid_mask])\n",
    "        test_loss = alpha * test_c_loss + beta * test_o_loss+gamma*test_co_loss\n",
    "    #early stop     \n",
    "        if valid_loss < best_loss:\n",
    "            best_loss = valid_loss\n",
    "            best_epoch = epoch\n",
    "            #torch.save(model.state_dict(), \"attention_demo_large.pth\")\n",
    "        elif epoch - best_epoch > early_stop_thresh:\n",
    "            print(\"Early stopped training at epoch %d\" % epoch)\n",
    "            break  # terminate the training loop\n",
    "    print(\"proposed:train\",train_acc,\"valid\",valid_acc,\"test\",test_acc,\"n_suprious\",n_suprious)\n",
    "    output.loc[ith]=[train_acc,valid_acc,test_acc,\"proposed\",n_suprious]\n",
    "    ith+=1\n",
    "    if ith %20==0:\n",
    "        print(output.groupby(\"model\").mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "dbc1fcb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "output.to_csv(\"Graphsage,d=10,lr=0.005,alpha=0.2,beta=1,gamma=0.2,early_stop_thresh=30,n_epoch=300.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "e42908e6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>train_acc</th>\n",
       "      <th>valid_acc</th>\n",
       "      <th>test_acc</th>\n",
       "      <th>n_suprious</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>model</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Graphsage</th>\n",
       "      <td>0.797333</td>\n",
       "      <td>0.582</td>\n",
       "      <td>0.528</td>\n",
       "      <td>2.04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>proposed</th>\n",
       "      <td>0.774667</td>\n",
       "      <td>0.612</td>\n",
       "      <td>0.502</td>\n",
       "      <td>2.04</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           train_acc  valid_acc  test_acc  n_suprious\n",
       "model                                                \n",
       "Graphsage   0.797333      0.582     0.528        2.04\n",
       "proposed    0.774667      0.612     0.502        2.04"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output.groupby(\"model\").mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "16efb753",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>train_acc</th>\n",
       "      <th>valid_acc</th>\n",
       "      <th>test_acc</th>\n",
       "      <th>n_suprious</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>model</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Graphsage</th>\n",
       "      <td>0.102981</td>\n",
       "      <td>0.113281</td>\n",
       "      <td>0.134073</td>\n",
       "      <td>0.924938</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>proposed</th>\n",
       "      <td>0.134107</td>\n",
       "      <td>0.133463</td>\n",
       "      <td>0.123701</td>\n",
       "      <td>0.924938</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           train_acc  valid_acc  test_acc  n_suprious\n",
       "model                                                \n",
       "Graphsage   0.102981   0.113281  0.134073    0.924938\n",
       "proposed    0.134107   0.133463  0.123701    0.924938"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output.groupby(\"model\").std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "fbbbd817",
   "metadata": {},
   "outputs": [],
   "source": [
    "diff_list=[]\n",
    "for i in range(50):\n",
    "    GCN=output.loc[i*2][\"test_acc\"]\n",
    "    proposed=output.loc[i*2+1][\"test_acc\"]\n",
    "    diff=proposed-GCN\n",
    "    diff_list.append(diff)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "f930a3a9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.01949153984476342"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "0.137826/np.sqrt(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "407efe8f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
