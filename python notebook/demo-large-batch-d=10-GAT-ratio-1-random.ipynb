{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2761e554",
   "metadata": {},
   "source": [
    "## data generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cacb334b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\lib\\site-packages\\numpy\\_distributor_init.py:32: UserWarning: loaded more than 1 DLL from .libs:\n",
      "D:\\Anaconda\\lib\\site-packages\\numpy\\.libs\\libopenblas.TXA6YQSD3GCQQC22GEQ54J2UDCXDXHWN.gfortran-win_amd64.dll\n",
      "D:\\Anaconda\\lib\\site-packages\\numpy\\.libs\\libopenblas.WCDJNK7YVMPZQ2ME2ZZHJJRJ3JIKNDB7.gfortran-win_amd64.dll\n",
      "  stacklevel=1)\n",
      "\n",
      "Bad key \"text.kerning_factor\" on line 4 in\n",
      "D:\\Anaconda\\lib\\site-packages\\matplotlib\\mpl-data\\stylelib\\_classic_test_patch.mplstyle.\n",
      "You probably need to get an updated matplotlibrc file from\n",
      "https://github.com/matplotlib/matplotlib/blob/v3.1.3/matplotlibrc.template\n",
      "or from the matplotlib source distribution\n",
      "Using backend: pytorch\n"
     ]
    }
   ],
   "source": [
    "from locally_connected import LocallyConnected\n",
    "from lbfgsb_scipy import LBFGSBScipy\n",
    "from trace_expm import trace_expm\n",
    "from sklearn.metrics import f1_score\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import scipy.sparse\n",
    "import GraphNOTEARS\n",
    "import notears_torch_version\n",
    "import lasso\n",
    "import dynotears\n",
    "import utils as ut\n",
    "import matplotlib.pyplot as plt\n",
    "import networkx as nx\n",
    "import dgl\n",
    "import random\n",
    "import utils as ut\n",
    "import dgl.function as fn\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from dgl import DGLGraph\n",
    "import pandas as pd\n",
    "#device = torch.device(\"cuda:0\")\n",
    "device = torch.device(\"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e45970cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_pre_new(n, d, s0, w_graph_type, p_graph_type, sem_type,ratio):\n",
    "    #binary W\n",
    "    w_true = ut.simulate_dag(d, s0, w_graph_type)\n",
    "    #weighted W\n",
    "    w_mat = ut.simulate_parameter(w_true)\n",
    "    w_test_mat=w_mat.copy()\n",
    "    #A\n",
    "    adj1 = ut.generate_adj(n) \n",
    "    #node to target\n",
    "    num_target=np.nonzero(w_mat[:,-1])[0]#4,14\n",
    "    n_suprious=-1.0\n",
    "    suprious_dict={}\n",
    "    #if no suprious variable existed\n",
    "    if len(num_target)==0:\n",
    "        return w_mat,w_mat, w_mat, w_mat,w_mat,w_mat,n_suprious,w_mat\n",
    "    else:\n",
    "        #create the spurious variable\n",
    "        for i in range(len(num_target)):\n",
    "            suprious_list=np.nonzero(w_mat[num_target[i],:])[0]#12\n",
    "\n",
    "            for j in range(len(suprious_list)): \n",
    "                suprious=suprious_list[j]\n",
    "                #count the number of suprious variable\n",
    "                if suprious not in suprious_dict:\n",
    "                    suprious_dict[suprious]=1\n",
    "                    n_suprious+=1\n",
    "                    #remove other outgoing link\n",
    "                    w_mat[suprious,:]=0 #12,0\n",
    "                    w_test_mat[suprious,:]=0\n",
    "                    #print(suprious)\n",
    "                    #revert the link in the test\n",
    "                    if suprious!=d-1:\n",
    "                        w_test_mat[num_target[i],suprious]=ratio*w_test_mat[num_target[i],suprious]\n",
    "                \n",
    "                \n",
    "    num_step = 5 #cannot work if num_step=1\n",
    "    #initial X0=X0W+B\n",
    "    Xbase = []\n",
    "    Xbase1 = ut.simulate_linear_sem(w_mat, n, sem_type, noise_scale=0.5)\n",
    "    #X1=X1W+AX0W+B\n",
    "    for i in range(num_step):\n",
    "        Xbase1 = ut.simulate_linear_sem_with_P(w_mat, w_mat, adj1@Xbase1, n, sem_type, noise_scale=1)\n",
    "        Xbase.append(Xbase1)\n",
    "        \n",
    "    #test data\n",
    "    Xbase_test = []\n",
    "    Xbase1_test = ut.simulate_linear_sem(w_test_mat, n, sem_type, noise_scale=0.5)\n",
    "    for i in range(num_step):\n",
    "        Xbase1_test = ut.simulate_linear_sem_with_P(w_test_mat, w_test_mat, adj1@Xbase1_test, n, sem_type, noise_scale=1)\n",
    "        Xbase_test.append(Xbase1_test)\n",
    "    \n",
    "    w_random = ut.simulate_dag(d, s0, w_graph_type)\n",
    "    return Xbase,Xbase_test, adj1, w_true,w_mat,w_test_mat,n_suprious,w_random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "610eebc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.set_default_dtype(torch.double)\n",
    "np.set_printoptions(precision=3)\n",
    "\n",
    "torch.manual_seed(12345)\n",
    "ut.set_random_seed(12345)\n",
    "\n",
    "n = 50 #number of people\n",
    "\n",
    "d = 10 #number of features\n",
    "\n",
    "w_graph_type = 'ER'\n",
    "p_graph_type = 'ER' \n",
    "sem_type = 'exp'\n",
    "s0 =  d\n",
    "output=pd.DataFrame(columns=[\"train_acc\",\"valid_acc\",\"test_acc\",\"model\",\"n_suprious\"])\n",
    "ith=0\n",
    "replicates=100\n",
    "ratio=-0.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e93cb6b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "Xlags,Xlags_test, adj1, w_true,w_mat,w_test_mat,n_suprious,w_random = data_pre_new(n, d, s0, w_graph_type,p_graph_type, sem_type,ratio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d37d79d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "adj1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bf5d655",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.shape(torch.Tensor(np.array(Xlags))[:-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c7e13e9d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.0"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_suprious"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "6c51ad81",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5, 50, 5)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.shape(Xlags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "611bb851",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "matrix([[0.143, 0.134, 0.   , ..., 0.   , 0.   , 0.   ],\n",
       "        [0.134, 0.125, 0.204, ..., 0.   , 0.125, 0.   ],\n",
       "        [0.   , 0.204, 0.333, ..., 0.   , 0.   , 0.   ],\n",
       "        ...,\n",
       "        [0.   , 0.   , 0.   , ..., 0.167, 0.   , 0.   ],\n",
       "        [0.   , 0.125, 0.   , ..., 0.   , 0.125, 0.204],\n",
       "        [0.   , 0.   , 0.   , ..., 0.   , 0.204, 0.333]])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adj1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "c8626720",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 288x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "##True W\n",
    "import matplotlib.pyplot as plt\n",
    "plt.matshow(w_mat,cmap = 'bwr', vmin = -1, vmax = 1)\n",
    "plt.colorbar()\n",
    "plt.savefig(\"train_graph.pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "fec25326",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 288x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "##True W\n",
    "import matplotlib.pyplot as plt\n",
    "plt.matshow(w_test_mat,cmap = 'bwr', vmin = -1, vmax = 1)\n",
    "plt.colorbar()\n",
    "plt.savefig(\"test_graph.pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8433d8f1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 288x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "##W_random\n",
    "import matplotlib.pyplot as plt\n",
    "plt.matshow(w_random,cmap = 'bwr', vmin = -1, vmax = 1)\n",
    "plt.colorbar()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "798aed9d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finish fit graph!\n"
     ]
    }
   ],
   "source": [
    "Xlags_torch = torch.Tensor(np.array(Xlags))\n",
    "\n",
    "adj1_torch = torch.Tensor(adj1)\n",
    "model_1 = GraphNOTEARS.model_p1_MLP(dims=[d, n, 1], bias=True)\n",
    "W_est_1, P1_est_1 = GraphNOTEARS.linear_model(model_1, Xlags_torch, adj1_torch,  lambda1 = 0.01, lambda2 = 0.01, lambda3 = 0.01)\n",
    "print(\"finish fit graph!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "126bd8cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "W_est_1[abs(W_est_1)<0.2]=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "cd8c01ac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 288x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "##estimate W\n",
    "import matplotlib.pyplot as plt\n",
    "plt.matshow(W_est_1,cmap = 'bwr', vmin = -1, vmax = 1)\n",
    "plt.colorbar()\n",
    "plt.savefig(\"estimated_graph.pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "a11f2675",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.2204410486384874"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Xlags[-1][:,-1].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "138579a0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.202, 0.981, 1.061, 0.768, 0.22 ])"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Xlags[-1].mean(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "d4685911",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.2204410486384874"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Xlags[-1][:].mean(axis=0)[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e865265d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_node_feature(Xlags,node_num):\n",
    "#     for num_lags in range(1):\n",
    "#         if num_lags==0:\n",
    "#             X_feature=Xlags[num_lags][node_num]\n",
    "#         else:\n",
    "#             X_feature=np.append(X_feature,Xlags[num_lags][node_num])##shape num_lags*5 (250)\n",
    "    X_feature=Xlags[-1][node_num]\n",
    "    return(X_feature)\n",
    "def to_binary(x):\n",
    "    if x>Xlags[-1][:,-1].mean():\n",
    "        return 1\n",
    "    else:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ab86e196",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_graph(valid_list,adj1,Xlags,n):\n",
    " ##node list for validation\n",
    "    labels=[]\n",
    "    G = nx.from_numpy_array(adj1)\n",
    "    for node_num in range(n):\n",
    "        G.nodes[node_num]['feature']=get_node_feature(Xlags,node_num)[:-1]\n",
    "\n",
    "        G.nodes[node_num]['label']=to_binary(get_node_feature(Xlags,node_num)[-1])\n",
    "\n",
    "        labels.append(G.nodes[node_num]['label'])\n",
    "        if node_num in valid_list:\n",
    "            G.nodes[node_num]['train_mask']=False\n",
    "            G.nodes[node_num]['valid_mask']=True\n",
    "        else:\n",
    "            G.nodes[node_num]['train_mask']=True\n",
    "            G.nodes[node_num]['valid_mask']=False\n",
    "    g = dgl.from_networkx(G, node_attrs=['feature','label','train_mask','valid_mask'])\n",
    "    return g"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1556b5a5",
   "metadata": {},
   "source": [
    "## GAT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "26c9a388",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GATLayer(nn.Module):\n",
    "    def __init__(self, g, in_dim, out_dim):\n",
    "        super(GATLayer, self).__init__()\n",
    "        self.g = g\n",
    "        # equation (1)\n",
    "        self.fc = nn.Linear(in_dim, out_dim, bias=False)\n",
    "        # equation (2)\n",
    "        self.attn_fc = nn.Linear(2 * out_dim, 1, bias=False)\n",
    "    \n",
    "    def edge_attention(self, edges):\n",
    "        # edge UDF for equation (2)\n",
    "        z2 = torch.cat([edges.src['z'], edges.dst['z']], dim=1)\n",
    "        a = self.attn_fc(z2)\n",
    "        return {'e' : F.leaky_relu(a)}\n",
    "    \n",
    "    def message_func(self, edges):\n",
    "        # message UDF for equation (3) & (4)\n",
    "        return {'z' : edges.src['z'], 'e' : edges.data['e']}\n",
    "    \n",
    "    def reduce_func(self, nodes):\n",
    "        # reduce UDF for equation (3) & (4)\n",
    "        # equation (3)\n",
    "        alpha = F.softmax(nodes.mailbox['e'], dim=1)\n",
    "        # equation (4)\n",
    "        h = torch.sum(alpha * nodes.mailbox['z'], dim=1)\n",
    "        return {'h' : h}\n",
    "    \n",
    "    def forward(self, h):\n",
    "        # equation (1)\n",
    "        z = self.fc(h)\n",
    "        self.g.ndata['z'] = z\n",
    "        # equation (2)\n",
    "        self.g.apply_edges(self.edge_attention)\n",
    "        # equation (3) & (4)\n",
    "        self.g.update_all(self.message_func, self.reduce_func)\n",
    "        return self.g.ndata.pop('h')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c0f7691c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiHeadGATLayer(nn.Module):\n",
    "    def __init__(self, g, in_dim, out_dim, num_heads, merge='cat'):\n",
    "        super(MultiHeadGATLayer, self).__init__()\n",
    "        self.heads = nn.ModuleList()\n",
    "        for i in range(num_heads):\n",
    "            self.heads.append(GATLayer(g, in_dim, out_dim))\n",
    "        self.merge = merge\n",
    "    \n",
    "    def forward(self, h):\n",
    "        head_outs = [attn_head(h) for attn_head in self.heads]\n",
    "        if self.merge == 'cat':\n",
    "            # concat on the output feature dimension (dim=1)\n",
    "            return torch.cat(head_outs, dim=1)\n",
    "        else:\n",
    "            # merge using average\n",
    "            return torch.mean(torch.stack(head_outs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d77925e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GAT(nn.Module):\n",
    "    def __init__(self, g, in_dim, hidden_dim, out_dim, num_heads):\n",
    "        super(GAT, self).__init__()\n",
    "        self.layer1 = MultiHeadGATLayer(g, in_dim, hidden_dim, num_heads)\n",
    "        # Be aware that the input dimension is hidden_dim*num_heads since\n",
    "        #   multiple head outputs are concatenated together. Also, only\n",
    "        #   one attention head in the output layer.\n",
    "        self.layer2 = MultiHeadGATLayer(g, hidden_dim * num_heads, out_dim, 1)\n",
    "    \n",
    "    def forward(self, h):\n",
    "        h = self.layer1(h)\n",
    "        h = F.elu(h)\n",
    "        h = self.layer2(h)\n",
    "        return h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "cf70bd42",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, g, features, labels, mask):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        logits = model(features)\n",
    "        logits = logits[mask]\n",
    "        labels = labels[mask]\n",
    "        _, indices = torch.max(logits, dim=1)\n",
    "        correct = torch.sum(indices == labels)\n",
    "        return correct.item() * 1.0 / len(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4ca3d404",
   "metadata": {},
   "outputs": [],
   "source": [
    "class atten_Net(nn.Module):\n",
    "    def __init__(self,g, in_feats, hid_feats, out_feats,n_node,num_heads):\n",
    "        super(atten_Net, self).__init__()\n",
    "        self.layer1 = MultiHeadGATLayer(g, in_feats, hid_feats, num_heads)\n",
    "        self.layer2 = MultiHeadGATLayer(g, hid_feats * num_heads, out_feats, 1)\n",
    "        self.att_mlp_1 = nn.Linear(n_node, hid_feats)\n",
    "        self.att_mlp_2 = nn.Linear(hid_feats, 2)\n",
    "        self.layer3 = MultiHeadGATLayer(g, in_feats*2, hid_feats, num_heads)\n",
    "        self.layer4 = MultiHeadGATLayer(g, hid_feats * num_heads, out_feats, 1)\n",
    "\n",
    "    def forward(self, g, features,dag):\n",
    "        ##use mlp to get attention weights\n",
    "        node_att = F.relu(self.att_mlp_1(dag))\n",
    "        node_att = F.softmax(self.att_mlp_2(node_att), dim=-1)\n",
    "        node_weight_c = node_att[:, 0]\n",
    "        node_weight_o = node_att[:, 1]\n",
    "        ##attention on the causal/trival part\n",
    "        feature_c = node_weight_c.view(1, -1) * features\n",
    "        feature_o = node_weight_o.view(1, -1) * features\n",
    "        ## apply the mask on the features\n",
    "        xc = F.relu(self.layer1(feature_c))\n",
    "        xc = self.layer2(xc)\n",
    "        xc=F.log_softmax(xc, dim=-1)\n",
    "        \n",
    "        xo = F.relu(self.layer1(feature_o))\n",
    "        xo = self.layer2(xo)\n",
    "        xo=F.log_softmax(xo, dim=-1)\n",
    "        ##xco        \n",
    "        num = xc.shape[0]\n",
    "        l = [i for i in range(num)]\n",
    "        random.shuffle(l)\n",
    "        random_idx = torch.tensor(l)\n",
    "        xco = torch.cat((feature_c[random_idx], feature_o), dim=1)\n",
    "        xco = F.relu(self.layer3(xco))\n",
    "        xco = self.layer4(xco)\n",
    "        xco=F.log_softmax(xco, dim=-1)\n",
    "        \n",
    "        return xc,xo,xco"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7db3a7bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_new(model, g, features, labels, mask,dag):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        logits_c,logits_o,logits_co = model(g, features,dag)\n",
    "        logits = logits_o[mask]\n",
    "        labels = labels[mask]\n",
    "        _, indices = torch.max(logits, dim=1)\n",
    "        correct = torch.sum(indices == labels)\n",
    "        return correct.item() * 1.0 / len(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a08dbdd6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------the 0 iteration------------------\n",
      "finish data!\n",
      "Early stopped training at epoch 101\n",
      "proposed:train 0.8 valid 0.7 test 0.6 n_suprious 2.0\n",
      "-------------------the 1 iteration------------------\n",
      "finish data!\n",
      "Early stopped training at epoch 73\n",
      "proposed:train 0.8333333333333334 valid 0.55 test 0.3 n_suprious 4.0\n",
      "-------------------the 2 iteration------------------\n",
      "finish data!\n",
      "Early stopped training at epoch 74\n",
      "proposed:train 0.9333333333333333 valid 0.35 test 0.55 n_suprious 1.0\n",
      "-------------------the 3 iteration------------------\n",
      "finish data!\n",
      "Early stopped training at epoch 120\n",
      "proposed:train 0.6666666666666666 valid 0.5 test 0.6 n_suprious 3.0\n",
      "-------------------the 4 iteration------------------\n",
      "-------------------the 4 iteration------------------\n",
      "-------------------the 4 iteration------------------\n",
      "-------------------the 4 iteration------------------\n",
      "finish data!\n",
      "Early stopped training at epoch 55\n",
      "proposed:train 0.7 valid 0.65 test 0.65 n_suprious 2.0\n",
      "-------------------the 5 iteration------------------\n",
      "-------------------the 5 iteration------------------\n",
      "-------------------the 5 iteration------------------\n",
      "-------------------the 5 iteration------------------\n",
      "finish data!\n",
      "Early stopped training at epoch 73\n",
      "proposed:train 0.8666666666666667 valid 0.65 test 0.4 n_suprious 1.0\n",
      "-------------------the 6 iteration------------------\n",
      "finish data!\n",
      "Early stopped training at epoch 89\n",
      "proposed:train 0.9 valid 0.75 test 0.4 n_suprious 1.0\n",
      "-------------------the 7 iteration------------------\n",
      "-------------------the 7 iteration------------------\n",
      "-------------------the 7 iteration------------------\n",
      "finish data!\n",
      "Early stopped training at epoch 31\n",
      "proposed:train 0.6666666666666666 valid 0.45 test 0.2 n_suprious 2.0\n",
      "-------------------the 8 iteration------------------\n",
      "finish data!\n",
      "Early stopped training at epoch 69\n",
      "proposed:train 0.7666666666666667 valid 0.5 test 0.75 n_suprious 1.0\n",
      "-------------------the 9 iteration------------------\n",
      "-------------------the 9 iteration------------------\n",
      "-------------------the 9 iteration------------------\n",
      "finish data!\n",
      "Early stopped training at epoch 93\n",
      "proposed:train 0.8333333333333334 valid 0.65 test 0.4 n_suprious 1.0\n",
      "          train_acc  valid_acc  test_acc  n_suprious\n",
      "model                                               \n",
      "proposed   0.796667      0.575     0.485         1.8\n",
      "-------------------the 10 iteration------------------\n",
      "finish data!\n",
      "Early stopped training at epoch 39\n",
      "proposed:train 0.6333333333333333 valid 0.35 test 0.45 n_suprious 1.0\n",
      "-------------------the 11 iteration------------------\n",
      "-------------------the 11 iteration------------------\n",
      "finish data!\n",
      "Early stopped training at epoch 43\n",
      "proposed:train 0.5333333333333333 valid 0.35 test 0.55 n_suprious 4.0\n",
      "-------------------the 12 iteration------------------\n",
      "finish data!\n",
      "Early stopped training at epoch 31\n",
      "proposed:train 0.6666666666666666 valid 0.35 test 0.35 n_suprious 3.0\n",
      "-------------------the 13 iteration------------------\n",
      "finish data!\n",
      "Early stopped training at epoch 43\n",
      "proposed:train 0.6666666666666666 valid 0.55 test 0.8 n_suprious 2.0\n",
      "-------------------the 14 iteration------------------\n",
      "finish data!\n",
      "Early stopped training at epoch 77\n",
      "proposed:train 0.8 valid 0.65 test 0.85 n_suprious 2.0\n",
      "-------------------the 15 iteration------------------\n",
      "-------------------the 15 iteration------------------\n",
      "finish data!\n",
      "Early stopped training at epoch 38\n",
      "proposed:train 0.6 valid 0.55 test 0.45 n_suprious 2.0\n",
      "-------------------the 16 iteration------------------\n",
      "-------------------the 16 iteration------------------\n",
      "-------------------the 16 iteration------------------\n",
      "finish data!\n",
      "Early stopped training at epoch 57\n",
      "proposed:train 0.8 valid 0.6 test 0.75 n_suprious 1.0\n",
      "-------------------the 17 iteration------------------\n",
      "finish data!\n",
      "Early stopped training at epoch 88\n",
      "proposed:train 0.9 valid 0.4 test 0.5 n_suprious 2.0\n",
      "-------------------the 18 iteration------------------\n",
      "-------------------the 18 iteration------------------\n",
      "finish data!\n",
      "Early stopped training at epoch 90\n",
      "proposed:train 0.8333333333333334 valid 0.75 test 0.5 n_suprious 4.0\n",
      "-------------------the 19 iteration------------------\n",
      "-------------------the 19 iteration------------------\n",
      "-------------------the 19 iteration------------------\n",
      "-------------------the 19 iteration------------------\n",
      "-------------------the 19 iteration------------------\n",
      "finish data!\n",
      "Early stopped training at epoch 31\n",
      "proposed:train 0.6333333333333333 valid 0.4 test 0.55 n_suprious 2.0\n",
      "          train_acc  valid_acc  test_acc  n_suprious\n",
      "model                                               \n",
      "proposed   0.751667      0.535      0.53        2.05\n",
      "-------------------the 20 iteration------------------\n",
      "finish data!\n",
      "Early stopped training at epoch 91\n",
      "proposed:train 0.8333333333333334 valid 0.65 test 0.8 n_suprious 1.0\n",
      "-------------------the 21 iteration------------------\n",
      "-------------------the 21 iteration------------------\n",
      "-------------------the 21 iteration------------------\n",
      "-------------------the 21 iteration------------------\n",
      "-------------------the 21 iteration------------------\n",
      "-------------------the 21 iteration------------------\n",
      "finish data!\n",
      "Early stopped training at epoch 77\n",
      "proposed:train 0.7666666666666667 valid 0.5 test 0.45 n_suprious 2.0\n",
      "-------------------the 22 iteration------------------\n",
      "finish data!\n",
      "Early stopped training at epoch 42\n",
      "proposed:train 0.6666666666666666 valid 0.4 test 0.3 n_suprious 4.0\n",
      "-------------------the 23 iteration------------------\n",
      "finish data!\n",
      "Early stopped training at epoch 31\n",
      "proposed:train 0.6 valid 0.5 test 0.35 n_suprious 1.0\n",
      "-------------------the 24 iteration------------------\n",
      "finish data!\n",
      "Early stopped training at epoch 108\n",
      "proposed:train 0.8666666666666667 valid 0.45 test 0.65 n_suprious 2.0\n",
      "-------------------the 25 iteration------------------\n",
      "finish data!\n",
      "Early stopped training at epoch 34\n",
      "proposed:train 0.6 valid 0.45 test 0.4 n_suprious 2.0\n",
      "-------------------the 26 iteration------------------\n",
      "-------------------the 26 iteration------------------\n",
      "-------------------the 26 iteration------------------\n",
      "finish data!\n",
      "Early stopped training at epoch 94\n",
      "proposed:train 0.7 valid 0.45 test 0.75 n_suprious 3.0\n",
      "-------------------the 27 iteration------------------\n",
      "finish data!\n",
      "Early stopped training at epoch 113\n",
      "proposed:train 0.8666666666666667 valid 0.55 test 0.65 n_suprious 3.0\n",
      "-------------------the 28 iteration------------------\n",
      "finish data!\n",
      "Early stopped training at epoch 31\n",
      "proposed:train 0.7 valid 0.55 test 0.6 n_suprious 1.0\n",
      "-------------------the 29 iteration------------------\n",
      "finish data!\n",
      "Early stopped training at epoch 31\n",
      "proposed:train 0.6 valid 0.45 test 0.6 n_suprious 1.0\n",
      "          train_acc  valid_acc  test_acc  n_suprious\n",
      "model                                               \n",
      "proposed   0.741111   0.521667  0.538333    2.033333\n",
      "-------------------the 30 iteration------------------\n",
      "-------------------the 30 iteration------------------\n",
      "finish data!\n",
      "Early stopped training at epoch 31\n",
      "proposed:train 0.6333333333333333 valid 0.5 test 0.55 n_suprious 1.0\n",
      "-------------------the 31 iteration------------------\n",
      "-------------------the 31 iteration------------------\n",
      "finish data!\n",
      "Early stopped training at epoch 53\n",
      "proposed:train 0.6333333333333333 valid 0.45 test 0.65 n_suprious 1.0\n",
      "-------------------the 32 iteration------------------\n",
      "finish data!\n",
      "Early stopped training at epoch 38\n",
      "proposed:train 0.5666666666666667 valid 0.45 test 0.35 n_suprious 2.0\n",
      "-------------------the 33 iteration------------------\n",
      "finish data!\n",
      "Early stopped training at epoch 95\n",
      "proposed:train 0.8 valid 0.7 test 0.7 n_suprious 2.0\n",
      "-------------------the 34 iteration------------------\n",
      "finish data!\n",
      "Early stopped training at epoch 120\n",
      "proposed:train 0.8 valid 0.65 test 0.7 n_suprious 2.0\n",
      "-------------------the 35 iteration------------------\n",
      "finish data!\n",
      "Early stopped training at epoch 31\n",
      "proposed:train 0.6333333333333333 valid 0.4 test 0.55 n_suprious 3.0\n",
      "-------------------the 36 iteration------------------\n",
      "finish data!\n",
      "Early stopped training at epoch 31\n",
      "proposed:train 0.6 valid 0.25 test 0.75 n_suprious 4.0\n",
      "-------------------the 37 iteration------------------\n",
      "-------------------the 37 iteration------------------\n",
      "-------------------the 37 iteration------------------\n",
      "-------------------the 37 iteration------------------\n",
      "-------------------the 37 iteration------------------\n",
      "finish data!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopped training at epoch 35\n",
      "proposed:train 0.6 valid 0.5 test 0.5 n_suprious 2.0\n",
      "-------------------the 38 iteration------------------\n",
      "-------------------the 38 iteration------------------\n",
      "-------------------the 38 iteration------------------\n",
      "-------------------the 38 iteration------------------\n",
      "-------------------the 38 iteration------------------\n",
      "-------------------the 38 iteration------------------\n",
      "-------------------the 38 iteration------------------\n",
      "finish data!\n",
      "Early stopped training at epoch 74\n",
      "proposed:train 0.8333333333333334 valid 0.65 test 0.45 n_suprious 3.0\n",
      "-------------------the 39 iteration------------------\n",
      "finish data!\n",
      "Early stopped training at epoch 31\n",
      "proposed:train 0.5666666666666667 valid 0.35 test 0.25 n_suprious 1.0\n",
      "          train_acc  valid_acc  test_acc  n_suprious\n",
      "model                                               \n",
      "proposed     0.7225    0.51375      0.54        2.05\n",
      "-------------------the 40 iteration------------------\n",
      "-------------------the 40 iteration------------------\n",
      "finish data!\n",
      "Early stopped training at epoch 62\n",
      "proposed:train 0.8666666666666667 valid 0.35 test 0.55 n_suprious 1.0\n",
      "-------------------the 41 iteration------------------\n",
      "finish data!\n",
      "Early stopped training at epoch 38\n",
      "proposed:train 0.6 valid 0.6 test 0.35 n_suprious 2.0\n",
      "-------------------the 42 iteration------------------\n",
      "finish data!\n",
      "Early stopped training at epoch 38\n",
      "proposed:train 0.6666666666666666 valid 0.4 test 0.4 n_suprious 1.0\n",
      "-------------------the 43 iteration------------------\n",
      "finish data!\n",
      "Early stopped training at epoch 33\n",
      "proposed:train 0.7666666666666667 valid 0.45 test 0.6 n_suprious 2.0\n",
      "-------------------the 44 iteration------------------\n",
      "-------------------the 44 iteration------------------\n",
      "finish data!\n",
      "Early stopped training at epoch 99\n",
      "proposed:train 0.8333333333333334 valid 0.7 test 0.45 n_suprious 1.0\n",
      "-------------------the 45 iteration------------------\n",
      "finish data!\n",
      "Early stopped training at epoch 99\n",
      "proposed:train 0.8333333333333334 valid 0.65 test 0.5 n_suprious 2.0\n",
      "-------------------the 46 iteration------------------\n",
      "-------------------the 46 iteration------------------\n",
      "-------------------the 46 iteration------------------\n",
      "finish data!\n",
      "Early stopped training at epoch 31\n",
      "proposed:train 0.6333333333333333 valid 0.5 test 0.85 n_suprious 2.0\n",
      "-------------------the 47 iteration------------------\n",
      "-------------------the 47 iteration------------------\n",
      "-------------------the 47 iteration------------------\n",
      "finish data!\n",
      "Early stopped training at epoch 36\n",
      "proposed:train 0.5666666666666667 valid 0.55 test 0.55 n_suprious 2.0\n",
      "-------------------the 48 iteration------------------\n",
      "-------------------the 48 iteration------------------\n",
      "-------------------the 48 iteration------------------\n",
      "-------------------the 48 iteration------------------\n",
      "finish data!\n",
      "Early stopped training at epoch 74\n",
      "proposed:train 0.9333333333333333 valid 0.6 test 0.6 n_suprious 1.0\n",
      "-------------------the 49 iteration------------------\n",
      "-------------------the 49 iteration------------------\n",
      "-------------------the 49 iteration------------------\n",
      "-------------------the 49 iteration------------------\n",
      "-------------------the 49 iteration------------------\n",
      "finish data!\n",
      "Early stopped training at epoch 31\n",
      "proposed:train 0.5666666666666667 valid 0.45 test 0.2 n_suprious 2.0\n",
      "          train_acc  valid_acc  test_acc  n_suprious\n",
      "model                                               \n",
      "proposed   0.723333      0.516     0.533        1.96\n"
     ]
    }
   ],
   "source": [
    "torch.set_default_dtype(torch.double)\n",
    "np.set_printoptions(precision=3)\n",
    "\n",
    "torch.manual_seed(12345)\n",
    "ut.set_random_seed(12345)\n",
    "\n",
    "n = 50 #number of people\n",
    "\n",
    "d = 10 #number of features\n",
    "\n",
    "\n",
    "w_graph_type = 'ER'\n",
    "p_graph_type = 'ER' \n",
    "sem_type = 'exp'\n",
    "s0 =  d\n",
    "#params\n",
    "ratio=-1\n",
    "lr=0.005\n",
    "alpha=0.2\n",
    "beta=1\n",
    "gamma=0.2\n",
    "early_stop_thresh=30\n",
    "n_epoch=300\n",
    "output=pd.DataFrame(columns=[\"train_acc\",\"valid_acc\",\"test_acc\",\"model\",\"n_suprious\"])\n",
    "ith=0\n",
    "replicates=50\n",
    "while ith<2*replicates:\n",
    "    print(\"-------------------the\",ith//2,\"iteration------------------\")\n",
    "    #create data\n",
    "    Xlags,Xlags_test, adj1, w_true,w_mat,w_test_mat,n_suprious,w_random = data_pre_new(n, d, s0, w_graph_type,p_graph_type, sem_type,ratio)\n",
    "    if n_suprious<=0:\n",
    "        continue\n",
    "    Xlags_torch = torch.Tensor(np.array(Xlags))\n",
    "    print(\"finish data!\")\n",
    "    #fit the causal graph\n",
    "#     adj1_torch = torch.Tensor(adj1)\n",
    "#     model_1 = GraphNOTEARS.model_p1_MLP(dims=[d, n, 1], bias=True)\n",
    "#     W_est_1, P1_est_1 = GraphNOTEARS.linear_model(model_1, Xlags_torch, adj1_torch,  lambda1 = 0.01, lambda2 = 0.01, lambda3 = 0.01)\n",
    "#     print(\"finish fit graph!\")\n",
    "    #g,g_test\n",
    "    valid_list=random.sample(range(n), int(n*0.4))\n",
    "    g = create_graph(valid_list,adj1,Xlags,n)\n",
    "    g_test=create_graph(valid_list,adj1,Xlags_test,n)\n",
    "#     #GAT\n",
    "#     net = GAT(g, \n",
    "#           in_dim=d-1, \n",
    "#           hidden_dim=4, \n",
    "#           out_dim=2, \n",
    "#           num_heads=2)\n",
    "\n",
    "    features = g.ndata['feature']\n",
    "    labels = g.ndata['label']\n",
    "    train_mask = g.ndata['train_mask']\n",
    "    valid_mask = g.ndata['valid_mask']\n",
    "#     ###test\n",
    "    features_test = g_test.ndata['feature']\n",
    "    labels_test = g_test.ndata['label']\n",
    "#     #parameters\n",
    "#     optimizer = torch.optim.Adam(net.parameters(), lr=lr)\n",
    "\n",
    "#     best_loss = 99998\n",
    "#     best_epoch = -1\n",
    "#     for epoch in range(n_epoch):\n",
    "#         net.train()\n",
    "#         logits = net(features)\n",
    "        \n",
    "#         logp = F.log_softmax(logits, dim=-1)\n",
    "#         loss = F.nll_loss(logp[train_mask], labels[train_mask])\n",
    "\n",
    "#         optimizer.zero_grad()\n",
    "#         loss.backward()\n",
    "#         optimizer.step()\n",
    "#         ##evaluate\n",
    "#         net.eval()\n",
    "#         train_acc = evaluate(net, g, features, labels, train_mask)\n",
    "#         valid_acc = evaluate(net, g, features, labels, valid_mask)\n",
    "#         test_acc = evaluate(net, g_test, features_test, labels_test, valid_mask)\n",
    "#         valid_loss = F.nll_loss(logp[valid_mask], labels[valid_mask])\n",
    "#         #early stop\n",
    "#         if valid_loss < best_loss:\n",
    "#             best_loss = valid_loss\n",
    "#             best_epoch = epoch\n",
    "#             #torch.save(net.state_dict(), \"GCN_demo_large.pth\")\n",
    "#         elif epoch - best_epoch > early_stop_thresh:\n",
    "#             print(\"Early stopped training at epoch %d\" % epoch)\n",
    "#             break  # terminate the training loop\n",
    "#     print(\"GCN:train\",train_acc,\"valid\",valid_acc,\"test\",test_acc)\n",
    "#     output.loc[ith]=[train_acc,valid_acc,test_acc,\"GCN\",n_suprious]\n",
    "    ith+=1\n",
    "    ##proposed\n",
    "    model = atten_Net(g,num_heads=2,in_feats=d-1, hid_feats=4, out_feats=2,n_node=d)\n",
    "\n",
    "    #params\n",
    "    best_loss = 99998\n",
    "    best_epoch = -1\n",
    "\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "    #scheduler = torch.optim.lr_scheduler.ExponentialLR(optimizer, gamma=0.9)\n",
    "    for epoch in range(n_epoch):\n",
    "        model.train()\n",
    "        xc_logits,xo_logits,xco_logits = model(g, features,torch.tensor(w_random[:-1,:]))\n",
    "        ##trivial part\n",
    "        uniform_target = torch.ones_like(xc_logits[train_mask], dtype=torch.double)/2\n",
    "        c_loss = F.kl_div(xc_logits[train_mask], uniform_target, reduction='batchmean')\n",
    "\n",
    "        o_loss = F.nll_loss(xo_logits[train_mask], labels[train_mask])\n",
    "        co_loss= F.nll_loss(xco_logits[train_mask], labels[train_mask])\n",
    "        loss = alpha * c_loss + beta * o_loss +gamma*co_loss\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        #scheduler.step()\n",
    "        ##evaluate\n",
    "        model.eval()\n",
    "        train_acc = evaluate_new(model, g, features, labels, train_mask,torch.tensor(w_random[:-1,:]))\n",
    "        valid_acc = evaluate_new(model, g, features, labels, valid_mask,torch.tensor(w_random[:-1,:]))\n",
    "        test_acc = evaluate_new(model, g_test, features_test, labels_test, valid_mask,torch.tensor(w_random[:-1,:]))\n",
    "        #valid loss\n",
    "        uniform_target = torch.ones_like(xc_logits[valid_mask], dtype=torch.double)/2\n",
    "        valid_c_loss = F.kl_div(xc_logits[valid_mask], uniform_target, reduction='batchmean')\n",
    "        valid_o_loss = F.nll_loss(xo_logits[valid_mask], labels[valid_mask])\n",
    "        valid_co_loss = F.nll_loss(xco_logits[valid_mask], labels[valid_mask])\n",
    "        valid_loss = alpha * valid_c_loss+beta *valid_o_loss+gamma*valid_co_loss\n",
    "        #test loss\n",
    "        test_xc_logits,test_xo_logits,test_xco_logits = model(g_test, features_test,torch.tensor(w_random[:-1,:]))\n",
    "        uniform_target = torch.ones_like(test_xo_logits[valid_mask], dtype=torch.double)/2\n",
    "        test_c_loss = F.kl_div(test_xc_logits[valid_mask], uniform_target, reduction='batchmean')\n",
    "        test_o_loss = F.nll_loss(test_xo_logits[valid_mask], labels_test[valid_mask])\n",
    "        test_co_loss = F.nll_loss(test_xco_logits[valid_mask], labels_test[valid_mask])\n",
    "        test_loss = alpha * test_c_loss + beta * test_o_loss+gamma*test_co_loss\n",
    "    #early stop     \n",
    "        if valid_loss < best_loss:\n",
    "            best_loss = valid_loss\n",
    "            best_epoch = epoch\n",
    "            #torch.save(model.state_dict(), \"attention_demo_large.pth\")\n",
    "        elif epoch - best_epoch > early_stop_thresh:\n",
    "            print(\"Early stopped training at epoch %d\" % epoch)\n",
    "            break  # terminate the training loop\n",
    "    print(\"proposed:train\",train_acc,\"valid\",valid_acc,\"test\",test_acc,\"n_suprious\",n_suprious)\n",
    "    output.loc[ith]=[train_acc,valid_acc,test_acc,\"proposed\",n_suprious]\n",
    "    ith+=1\n",
    "    if ith %20==0:\n",
    "        print(output.groupby(\"model\").mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "dbc1fcb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "output.to_csv(\"random,gat,d=10,lr=0.005,alpha=0.2,beta=1,gamma=0.2,early_stop_thresh=30,n_epoch=300,ratio=-1.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e42908e6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>train_acc</th>\n",
       "      <th>valid_acc</th>\n",
       "      <th>test_acc</th>\n",
       "      <th>n_suprious</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>model</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>proposed</th>\n",
       "      <td>0.723333</td>\n",
       "      <td>0.516</td>\n",
       "      <td>0.533</td>\n",
       "      <td>1.96</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          train_acc  valid_acc  test_acc  n_suprious\n",
       "model                                               \n",
       "proposed   0.723333      0.516     0.533        1.96"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output.groupby(\"model\").mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "16efb753",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>train_acc</th>\n",
       "      <th>valid_acc</th>\n",
       "      <th>test_acc</th>\n",
       "      <th>n_suprious</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>model</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>proposed</th>\n",
       "      <td>0.016448</td>\n",
       "      <td>0.017228</td>\n",
       "      <td>0.023413</td>\n",
       "      <td>0.13389</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          train_acc  valid_acc  test_acc  n_suprious\n",
       "model                                               \n",
       "proposed   0.016448   0.017228  0.023413     0.13389"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output.groupby(\"model\").std()/np.sqrt(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "fbbbd817",
   "metadata": {},
   "outputs": [],
   "source": [
    "diff_list=[]\n",
    "for i in range(50):\n",
    "    GCN=output.loc[i*2][\"test_acc\"]\n",
    "    proposed=output.loc[i*2+1][\"test_acc\"]\n",
    "    diff=proposed-GCN\n",
    "    diff_list.append(diff)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f930a3a9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.01584103037620975"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "0.112013/np.sqrt(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71a1e9e8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
